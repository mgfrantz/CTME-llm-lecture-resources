{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Yet3D9hI3ZN8o1GdF0hQAfh8WGdPGw7g",
      "authorship_tag": "ABX9TyOE+YI7Rx4Et/jvOunNXqwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgfrantz/CTME-llm-lecture-resources/blob/main/labs/rag_and_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents and RAG\n",
        "\n",
        "In this lab, we're going to create a customer service bot.\n",
        "We will use LLM fundamentals and create modules in a step-by-step approach and by the end of the day we'll have a basic customer service chatbot.\n",
        "\n",
        "The chatbot will have several capabilities - it will be able to look up and update customer info, look up and update customer orders, and answer questions about product offerings.\n",
        "\n",
        "Tomorrow, we're going to train a *much* smaller LLM on the same task.\n",
        "But as of now, we don't have any training data!\n",
        "To do this, we're going to - you guessed it - use LLMs as fake customers to generate data that we can use to fine-tune an LLM tomorrow."
      ],
      "metadata": {
        "id": "pYIERZma-1es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "0p1UDkkI_8Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs\n",
        "!pip install -Uqqqq \\\n",
        "    \"llama-index>=0.11.17\" \\\n",
        "    \"llama-index-core>=0.10.43\" \\\n",
        "    \"openinference-instrumentation-llama-index>=2\" \\\n",
        "    \"opentelemetry-proto>=1.12.0\" \\\n",
        "    arize-phoenix-otel \\\n",
        "    fastembed \\\n",
        "    nest-asyncio \\\n",
        "    llama-index-callbacks-arize-phoenix \\\n",
        "    llama-index-readers-database \\\n",
        "    llama-index-llms-openai \\\n",
        "    google-generativeai \\\n",
        "    llama-index-embeddings-fastembed \\\n",
        "    llama-index-readers-database \\\n",
        "    llama-index-agent-openai \\\n",
        "    --progress-bar off"
      ],
      "metadata": {
        "id": "NjtoFKCs9DdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment variables\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "W_17Q_Jo9IW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you did not run the previous notebook, use the data from the repo\n",
        "!git clone https://github.com/mgfrantz/CTME-llm-lecture-resources\n",
        "!cp CTME-llm-lecture-resources/data/ecommerce.db ."
      ],
      "metadata": {
        "id": "jANiwLkL5QYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the data we generated yesterday to the current working directory\n",
        "if not os.path.exists('drive/MyDrive/CTME-LLM-labs/ecommerce.db'):\n",
        "    print(\"The ecommerce.db database does not exist. Please make sure you're connected to Google Drive or upload it to the Colab notebook or re-run lesson 1.\")\n",
        "!cp drive/MyDrive/CTME-LLM-labs/ecommerce.db ."
      ],
      "metadata": {
        "id": "KEkQAuMaXKQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsOTfbPsnXhk"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from rich import print\n",
        "from typing import Literal, List, Dict\n",
        "from pydantic import BaseModel, Field\n",
        "from time import sleep\n",
        "from sqlalchemy import create_engine\n",
        "import json\n",
        "import phoenix as px\n",
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "from openinference.instrumentation import using_metadata\n",
        "from phoenix.otel import register\n",
        "from enum import Enum\n",
        "from tqdm.auto import tqdm\n",
        "from llama_index.core import VectorStoreIndex, Document\n",
        "from llama_index.core.tools import FunctionTool, QueryEngineTool, RetrieverTool\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core import PromptTemplate\n",
        "from llama_index.readers.database import DatabaseReader\n",
        "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.llms.openai import OpenAI\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "# nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility functions\n",
        "\n",
        "Here we define some utility functions - `query` and `execute` - that help us interact with our SQL database."
      ],
      "metadata": {
        "id": "upgIVmrTNcy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query(q:str, db:str='ecommerce.db') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Executes a SQL query against the SQLite database and returns the result as a pandas DataFrame.\n",
        "    Use this function when you want to query a database and return results.\n",
        "\n",
        "    Args:\n",
        "        q (str): The SQL query to execute.\n",
        "        db (str, optional): The path to the SQLite database file. Defaults to 'ecommerce.db'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The result of the SQL query as a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    connection = sqlite3.connect(db)\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(q)\n",
        "    result = cursor.fetchall()\n",
        "    df = pd.DataFrame(result)\n",
        "    df.columns = [i[0] for i in cursor.description]\n",
        "    connection.close()\n",
        "    return df\n",
        "\n",
        "def execute(q:str, db:str='ecommerce.db') -> None:\n",
        "    \"\"\"\n",
        "    Executes an SQL query against the SQLite database.\n",
        "    Use this when you want to run commands like updates, inserts, or deletes that don't return results.\n",
        "\n",
        "    Args:\n",
        "        q (str): The SQL query to execute.\n",
        "        db (str, optional): The path to the SQLite database file. Defaults to 'ecommerce.db'.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    connection = sqlite3.connect(db)\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(q)\n",
        "    connection.commit()\n",
        "    connection.close()"
      ],
      "metadata": {
        "id": "7tJudWvXntdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for table in ['customers', 'items', 'orders']:\n",
        "    print(f'Table: {table}')\n",
        "    display(query(f'SELECT * FROM {table} ORDER BY random() LIMIT 3;'))"
      ],
      "metadata": {
        "id": "erBLYPEpaltE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def instrument():\n",
        "    \"\"\"\n",
        "    Starts a poenix session.\n",
        "\n",
        "    Returns:\n",
        "        session: The phoenix session object.\n",
        "    \"\"\"\n",
        "    session = px.launch_app()\n",
        "    tracer_provider = register(endpoint=\"http://127.0.0.1:6006/v1/traces\")\n",
        "    LlamaIndexInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)\n",
        "    return session\n",
        "\n",
        "def end_session(session):\n",
        "    \"\"\"\n",
        "    Ends a phoenix session.\n",
        "\n",
        "    Args:\n",
        "        session: The phoenix session object.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    !rm {session.database_url.replace('sqlite:///', '')}\n",
        "    session.end()"
      ],
      "metadata": {
        "id": "iyy0VeiuqwF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem statement\n",
        "\n",
        "We are building a chatbot to automate simple customer interactions.\n",
        "We can assume that the customers are already logged in, so we can provide the customer's identity to the LLM to be able to retrieve relevant information.\n",
        "Here are the actions we will support:\n",
        "\n",
        "- Update customer info\n",
        "  - Update email\n",
        "  - Update phone number\n",
        "  - Update address\n",
        "  - Change pin\n",
        "  - Close account\n",
        "- Order information\n",
        "    - Check order information\n",
        "    - Cancel order\n",
        "    - Update order address\n",
        "- Ask question about a product"
      ],
      "metadata": {
        "id": "CnJ5FOnZROUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting started with ReAct: Customer infrmation\n",
        "\n",
        "In today's lab, we'll be useing the ReAct method.\n",
        "In this method, we run an LLM in a loop to try and determine what the best action is at each time step until an instruction can be answered without any additional steps.\n",
        "These steps include tool calls.\n",
        "\n",
        "Let's start with a simple use case - we want the LLM to be able to look up information about the customer given the customer's ID.\n",
        "Below, we define and document a function that queries our SQLite DB for all the information about a given customer.\n",
        "\n",
        "We then use `llama-index`'s `FunctionTool` class to turn this into a tool that we can provide to the agent later."
      ],
      "metadata": {
        "id": "lErrr5NUjq02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_customer_information_tool(customer_id:int):\n",
        "    def get_customer_information(*args, **kwargs) -> dict:\n",
        "        \"\"\"Use when you want to information about the customer.\n",
        "\n",
        "        Does not require any arguments.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the customer's information.\n",
        "        \"\"\"\n",
        "        data = query(f\"SELECT name, email, phone, street_address, city, state, zip_code, country FROM customers WHERE customer_id = {customer_id}\")\n",
        "        if len(data) == 0:\n",
        "            return {'error': 'Customer information not found on file.'}\n",
        "        else:\n",
        "            return data.to_dict(orient='records')[0]\n",
        "\n",
        "    return FunctionTool.from_defaults(fn=get_customer_information)"
      ],
      "metadata": {
        "id": "UR4DWxlqr3rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During testing, it's useful to just grab a random customer ID.\n",
        "We shouldn't use this function as an LLM tool, but it can help us test our functions.\n",
        "Remember, these are all synthetic customers so we're not actually revealing any sensitive customer information."
      ],
      "metadata": {
        "id": "YBFbrYQDOK2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_id():\n",
        "    return query(\"SELECT customer_id FROM customers ORDER BY random() LIMIT 1;\").iloc[0,0]"
      ],
      "metadata": {
        "id": "oLerE16msaAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we create our ReAct agent, let's actually take a look at the default system prompts.\n",
        "One caveat with high-level frameworks is that functionality often come with pre-packaged prompts that work decently out-of-the-box, but work much better with some slight tweaking."
      ],
      "metadata": {
        "id": "uzode8B4OqpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model='gpt-4o-mini')\n",
        "def get_base_tools(customer_id=get_random_id()):\n",
        "    return [get_customer_information_tool(customer_id)]"
      ],
      "metadata": {
        "id": "1Zym60sNs0gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the default system prompt\n",
        "print(ReActAgent.from_tools(tools=get_base_tools(), llm=llm).get_prompts()['agent_worker:system_prompt'].template)"
      ],
      "metadata": {
        "id": "aVYZYndnOyLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After reading the prompt, we can make some tweaks.\n",
        "Here are some tweaks I made that helped with the agent's behavior:\n",
        "\n",
        "- Give the agent more context as to how to behave. It knew nothing about the context in which it was operating, types of problems it should solve, and what to do in edge cases.\n",
        "- Give it the customer's ID. In this case, let's just make the assumption that the customer has already logged in, so there's an ID we can just make available to the LLM for function calls.\n",
        "\n",
        "Feel free to make any additional adjustments you want to the prompt.\n",
        "This is the default prompt we will use for all agent behavior in the rest of the lesson."
      ],
      "metadata": {
        "id": "ncoqfzzzP1je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AGENT_SYSTEM_PROMPT = PromptTemplate(\"\"\"\\\n",
        "You are a helpul customer service assistant for MikeCorp, an ecommerce company selling electronics. \\\n",
        "You are designed to help with a variety of problems a customer may have, including account management, order management, and product-related queries. \\\n",
        "If you are ever unsure what to do, please escalate.\n",
        "\n",
        "## Tools\n",
        "\n",
        "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem\n",
        "appropriate to complete the task at hand.\n",
        "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
        "\n",
        "You have access to the following tools:\n",
        "{tool_desc}\n",
        "\n",
        "\n",
        "## Output Format\n",
        "\n",
        "Please answer in English using the following format:\n",
        "\n",
        "```\n",
        "Thought: I need to use a tool to help me answer the question.\n",
        "Action: tool name (one of {tool_names}) if using a tool.\n",
        "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
        "```\n",
        "\n",
        "Please ALWAYS start with a Thought.\n",
        "\n",
        "NEVER surround your response with markdown code markers. \\\n",
        "You may use code markers within your response if you need to.\n",
        "\n",
        "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
        "\n",
        "If this format is used, the user will respond in the following format:\n",
        "\n",
        "```\n",
        "Observation: tool response\n",
        "```\n",
        "\n",
        "You should keep repeating the above format till you have enough information \\\n",
        "to answer the question without using any more tools. \\\n",
        "At that point, you MUST respond in the one of the following two formats:\n",
        "\n",
        "```\n",
        "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
        "Answer:\n",
        "```\n",
        "\n",
        "```\n",
        "Thought: I cannot answer the question with the provided tools.\n",
        "Answer:\n",
        "```\n",
        "\n",
        "## Current Conversation\n",
        "\n",
        "Below is the current conversation consisting of interleaving human and assistant messages. \\\n",
        "Conversation:\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "p9KZiWAsTx99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's create a function that completes the default system prompt with the customer's ID, sets it as the ReAct agent's prompt, and returns the agent.\n",
        "This is how we will be creating agents in the rest of the lab."
      ],
      "metadata": {
        "id": "Mw1vM0HWReSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agent(llm, tools, system_prompt=AGENT_SYSTEM_PROMPT, verbose=False):\n",
        "    agent = ReActAgent.from_tools(tools, llm=llm, verbose=verbose)\n",
        "    prompt_dict = agent.get_prompts()\n",
        "    prompt_dict['agent_worker:system_prompt'] = system_prompt\n",
        "    agent.update_prompts(prompt_dict)\n",
        "    return agent"
      ],
      "metadata": {
        "id": "sjPqXW9oYmNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracing\n",
        "\n",
        "It's always a good idea to keep track of the inputs and outputs for your LLM calls.\n",
        "In this case, we need it for training data.\n",
        "It can also really help us debug when we're not getting what we expect from our LLM apps.\n",
        "\n",
        "In this case, we will set up `phoenix`, a UI that ***traces*** all of our retrievals, function calls, and LLM calls.\n",
        "It also allows us to create and annotate datasets and download the inputs and outputs in a format we can adapt for fine tuning tomorrow.\n",
        "\n",
        "We've created several utility functions for the open source tracing utility `phoenix`.\n",
        "For now, we will use it for observability, but later on we will use it to export LLM fine-tuning data for tomorrow's lab.\n",
        "The usage is demonstrated below:\n",
        "\n",
        "```python\n",
        "session = istrument()\n",
        "# ... your LLM/agent calls ...\n",
        "end_session(session) # clears all traces\n",
        "```\n",
        "\n",
        "We added the ability to end the session and clear all traces because this makes it easier to start over when we want to log LLM traces for fine-tuning without including any of our development work."
      ],
      "metadata": {
        "id": "gxmbHF4Zst1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create our first agent and ask it a question!\n",
        "We can see that the agent can correctly use the tool we provided."
      ],
      "metadata": {
        "id": "z4FxsX50R05t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = get_base_tools()\n",
        "agent = create_agent(llm, tools, AGENT_SYSTEM_PROMPT, verbose=True)"
      ],
      "metadata": {
        "id": "L1QKBkoOZPg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = instrument()"
      ],
      "metadata": {
        "id": "EIDiABttsfB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.chat(f\"What is the address you have on file for me?\")"
      ],
      "metadata": {
        "id": "sX-9QqB5XBsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: User management tools\n",
        "\n",
        "Now that we've gone over the basics of how to create a working agent, the bulk of our work is to create the tools.\n",
        "In this section, your task is to create several user management tools.\n",
        "Make sure to create detailed docstrings, use type hints, and return text that describes the outcome of the action."
      ],
      "metadata": {
        "id": "uDYmdvsSaY9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_update_pin(customer_id:int):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "_DbNl1HYXJaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_update_address(customer_id:int):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "5e_SDmsviFcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_update_phone_number(customer_id:int):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "VVYqqd1oienn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_management_tools(customer_id=get_random_id()):\n",
        "    return [\n",
        "        get_update_pin(customer_id),\n",
        "        get_update_address(customer_id),\n",
        "        get_update_phone_number(customer_id)\n",
        "    ]"
      ],
      "metadata": {
        "id": "Ym738gUQiidy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Order Management\n",
        "\n",
        "In this section, your task is to create several order management tools.\n",
        "Make sure to create detailed docstrings, use type hints, and return text that describes the outcome of the action or returns appropriate information for the LLM."
      ],
      "metadata": {
        "id": "86QiSdTZi1Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_orders(customer_id:int):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "BVydt9l9jIse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cancel_order(customer_id:int):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "HJili3ZyjoGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_update_order_address(customer_id:int):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "Y_Ewh9JWkdfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_order_tools(customer_id=get_random_id()):\n",
        "    return [\n",
        "        get_list_orders(customer_id),\n",
        "        get_cancel_order(customer_id),\n",
        "        get_update_order_address(customer_id)\n",
        "    ]"
      ],
      "metadata": {
        "id": "hwo2bo8Mkl0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inventory tools with RAG\n",
        "\n",
        "For other operations, we saw that simple function calling gives most of the context we need.\n",
        "But for inventory, we can't load all the items into the LLM context at once.\n",
        "So we're going to use RAG to solve this.\n",
        "\n",
        "`llama-index` has a really great out-of-the-box RAG framework.\n",
        "It centers around creating vector store indices, which can be used as retrievers or objects called `QueryEngine`s, that answer questions about the data.\n",
        "In this case, let's create one or more retrievers to use to look up items for the agent in order to answer customer responses."
      ],
      "metadata": {
        "id": "TZ3_0xCBlVNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents\n",
        "engine = create_engine('sqlite:///ecommerce.db')\n",
        "docs = DatabaseReader(engine=engine).load_data(query=\"SELECT item_id, description, price, quantity, name AS text FROM items\")"
      ],
      "metadata": {
        "id": "PlZvY3illuEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = FastEmbedEmbedding(model_name='mixedbread-ai/mxbai-embed-large-v1')"
      ],
      "metadata": {
        "id": "SqKOli3kl0Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(docs, embed_model=embed_model, show_progress=True)"
      ],
      "metadata": {
        "id": "TcciJQynmOjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = index.as_retriever(similarity_top_k=5)\n",
        "print(retriever.retrieve(\"headphones\"))"
      ],
      "metadata": {
        "id": "J-fFnMyOSpaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our vector store indices, we can actually use the retrievers as tools.\n",
        "When we ask questions answerable via product names or descriptions,"
      ],
      "metadata": {
        "id": "W5MVmFEkTf3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inventory_tools = [\n",
        "    RetrieverTool.from_defaults(index.as_retriever(), description=\"Useful when you need to answer a question by searching items.\", name='search_items'),\n",
        "]"
      ],
      "metadata": {
        "id": "ML1Db6nPoH4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Simulating and evaluating conversations\n",
        "\n",
        "Now we need to generate some data.\n",
        "One option would be to spend hours or days chatting with our agent.\n",
        "If we have actual chats from support represntatives, we could test how the LLM responds to those same user queries.\n",
        "But since our data is synthetic, we don't have that.\n",
        "\n",
        "What we *can* do is simulate customers with particular goals and see if they can chat with our agent.\n",
        "Your goal is to create a function that interacts with our agent to accomplish a particular goal like updating their phone number or canceling an order.\n",
        "\n",
        "We also designed this agent so it is fairly limited in what it can do; otherwise it escalates.\n",
        "So we can actually measure when the desired task was completed or not by seeing if the correct function was called.\n",
        "Let's return a score of 1 for each trace where the correct function was called, and 0 when the incorrect function is called.\n",
        "This way, we can 1) evaluate how well our model works for each function type, and 2) filter out bad traces from our fine tuning data.\n",
        "\n",
        "To record metadata for an LLM or agent call, use the context manager as shown here:\n",
        "```python\n",
        "with using_metadata(metadata={'attribute_1':'value_1', ..., 'attribute_n': 'value_n'}):\n",
        "    response = await agent.achat(...)\n",
        "```\n",
        "You can use this context manager to track things like whether the LLM call was the customer or agent, the tool call we expect, or any other information useful for evaluation.\n",
        "\n",
        "Hints:\n",
        "\n",
        "- have the \"customer LLM\" output a special word (I used `'<|DONE|>'`) when their task is complete\n",
        "- use a loop and alternate between customer llm and agent llm\n",
        "- set a max number of messages per test - tests that go more than 3 or 4 turns probably are looping into some bad behavior\n",
        "- try to be extremely procedural in your instructions to the LLM\n",
        "- you will be making a lot of LLM calls - use `achat` or other asynchronous functionality to speed things up a bit.\n"
      ],
      "metadata": {
        "id": "ZRUXGd0B-V8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_tools(customer_id=get_random_id()):\n",
        "    return (\n",
        "        get_base_tools(customer_id)\n",
        "        + get_user_management_tools(customer_id)\n",
        "        + get_order_tools(customer_id)\n",
        "        + inventory_tools\n",
        "    )"
      ],
      "metadata": {
        "id": "qPbJNDNErZr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tool in get_all_tools():\n",
        "    print(tool.metadata.name)"
      ],
      "metadata": {
        "id": "RJ2g5L_Xaa9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_called_tool_names(agent):\n",
        "    \"\"\"\n",
        "    Returns a list of all the tool names called by the agent.\n",
        "    \"\"\"\n",
        "    tool_calls = []\n",
        "    for v in agent.state.task_dict.values():\n",
        "        for source in v.task.extra_state.get('sources', []):\n",
        "            tool_calls.append(source.tool_name)\n",
        "    return tool_calls\n",
        "\n",
        "async def complete_one_task(task, target_fn, customer_id, max_iter=4):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "async def complete_all_tasks(customer_id, session=None, verbose=False, max_iter=4, pbar=None):\n",
        "    raise NotImplementedError()"
      ],
      "metadata": {
        "id": "5F87zUbpWSOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulate customer interactions\n",
        "\n",
        "Now that our LLM calls are being traced, let's run our simulation.\n",
        "Let's select several customers at random and run our customer LLM against our agent.\n",
        "This will generate lots of traces - one input and one output for every LLM call!"
      ],
      "metadata": {
        "id": "YlU5kalO35HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train_customers = 8\n",
        "n_eval_customers = 2\n",
        "customer_ids = query(f\"SELECT customer_id FROM customers ORDER BY random() LIMIT {n_train_customers + n_eval_customers};\").customer_id.to_list()\n",
        "train_customers = customer_ids[:n_train_customers]\n",
        "eval_customers = customer_ids[n_train_customers:]\n",
        "assert len(set(train_customers).intersection(set(eval_customers))) == 0\n",
        "assert len(train_customers) == n_train_customers\n",
        "assert len(eval_customers) == n_eval_customers"
      ],
      "metadata": {
        "id": "SC-JBWNp38N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = []\n",
        "for customer_id in tqdm(train_customers):\n",
        "    _df = await complete_all_tasks(customer_id)\n",
        "    train_results.append(_df)\n",
        "    sleep(60) # add this because my token rate limit is low and I need to slow request rate\n",
        "train_df = pd.concat(train_results)"
      ],
      "metadata": {
        "id": "yGbwdsfG4IFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = []\n",
        "for customer_id in tqdm(eval_customers):\n",
        "    _df = await complete_all_tasks(customer_id)\n",
        "    eval_results.append(_df)\n",
        "    sleep(60) # add this because my token rate limit is low and I need to slow request rate\n",
        "eval_df = pd.concat(eval_results)"
      ],
      "metadata": {
        "id": "thzLClD75A53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "z2i7sl1maFMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df.head()"
      ],
      "metadata": {
        "id": "HuWpkeiqi3R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export spans for fine tuning\n",
        "\n",
        "Then, we will run the code to export it to Google Drive.\n",
        "Tomorrow, we will tokenize and fine tune on this dataset."
      ],
      "metadata": {
        "id": "rbZ9CbZ-30ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map conversation to the format expected by the sharegpt format\n",
        "key_mapping = {\n",
        "    'message.content': 'value',\n",
        "    'message.role': 'from'\n",
        "}\n",
        "def process_keys(l):\n",
        "    return [{key_mapping[k]: v for k, v in d.items()} for d in l]\n",
        "\n",
        "from_value_mapping = {\n",
        "    'user': 'human',\n",
        "    'assistant': 'gpt',\n",
        "    'system': 'system'\n",
        "}\n",
        "\n",
        "# Add the role key to the conversations - helps with input masking\n",
        "def apply_value_mapping(l, role):\n",
        "    to_return = []\n",
        "    for d in l:\n",
        "        d['from'] = from_value_mapping[d['from']]\n",
        "        to_return.append(d)\n",
        "    return to_return\n",
        "\n",
        "def to_conversations(row):\n",
        "    messages = row.input + row.output\n",
        "\n",
        "    return {'conversations': messages}\n",
        "\n",
        "\n",
        "def process_span_df(df, path, remove_failed_tasks_from_json=True):\n",
        "    input_output = df[['attributes.llm.input_messages', 'attributes.llm.output_messages', 'customer_id', 'target_fn', 'task_score']]\n",
        "    input_output = input_output.rename(columns={'attributes.llm.input_messages': 'input', 'attributes.llm.output_messages': 'output'})\n",
        "    input_output.loc[:, ['input', 'output']] = input_output.loc[:, ['input', 'output']].map(process_keys)\n",
        "    input_output.input = input_output.input.map(lambda x: apply_value_mapping(x, 'input'))\n",
        "    input_output.output = input_output.output.map(lambda x: apply_value_mapping(x, 'output'))\n",
        "    input_output['conversations'] = input_output.apply(to_conversations, axis=1)\n",
        "    with open(path, 'w') as f:\n",
        "        _input_output = input_output.copy()\n",
        "        if remove_failed_tasks_from_json:\n",
        "            _input_output = _input_output[_input_output.task_score == 1]\n",
        "        f.write(_input_output.conversations.to_json(orient='records', lines=True))\n",
        "    return input_output"
      ],
      "metadata": {
        "id": "GcH3NaijWBv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = process_span_df(train_df, 'train.jsonl')\n",
        "e = process_span_df(eval_df, 'eval.jsonl')"
      ],
      "metadata": {
        "id": "uJFSor-vsG9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 1 train.jsonl | python -m json.tool"
      ],
      "metadata": {
        "id": "DmoaGd3RsMbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/drive/MyDrive/CTME-LLM-labs/*.jsonl"
      ],
      "metadata": {
        "id": "7nO2gi8jefO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the data to where we can find it\n",
        "!cp *.jsonl /content/drive/MyDrive/CTME-LLM-labs/\n",
        "t.to_parquet('/content/drive/MyDrive/CTME-LLM-labs/train.parquet')\n",
        "e.to_parquet('/content/drive/MyDrive/CTME-LLM-labs/eval.parquet')"
      ],
      "metadata": {
        "id": "6mhjE1-LWBRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al /content/drive/MyDrive/CTME-LLM-labs/"
      ],
      "metadata": {
        "id": "RNyjCaUzu43-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TuXH3zZv87kj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}