{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgfrantz/CTME-llm-lecture-resources/blob/main/aramco/fine_tuning_and_inference_with_axolotl_2024_10_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning and inference\n",
        "\n",
        "In this lab, we're going to demonstrate the process of fine tuning.\n",
        "Note that this **does not mean we will have a better, cheaper, or faster model than API providers.**\n",
        "Given the small amnount of data we have and the time/resource constraints of this lab setting, we can't shoot for a highly performant model.\n",
        "But we will have a **general design pattern for fine tuning**, and we will see that the fine tuned model is not as bad as the base model for fine tuning.\n",
        "\n",
        "[Axolotl](https://github.com/axolotl-ai-cloud/axolotl) is a convenient library that helps fine tune text generation models.\n",
        "In this notebook, we will use `axolotl` to fine tune a small LLM on a dataset we've created.\n",
        "\n",
        "We will be using the small and open Llama 3.2 1b. model today.\n",
        "Here's are agenda:\n",
        "\n",
        "- Run the model in the notebook to demonstrate that it cannot do anything we want it to do out of the box.\n",
        "- Load the conversations we generated yesterday and prepare them for training by converting them into the ChatML format and tokenizing them.\n",
        "- Fine-tune the llama model using QLoRA\n",
        "- Export the model to .gguf so we can run it anywhere with `ollama` or `llama.cpp`\n",
        "- Test our model in our agent to demonstrate that it is better than the base model\n",
        "- Push our model artifacts to Huggingface so they can be run anywhere"
      ],
      "metadata": {
        "id": "KCr4O0fXR_rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Nnjlha4NSwDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ollama\n",
        "\n",
        "We will be using ollama for local inference.\n",
        "To set it up, open the Colab terminal â†™.\n",
        "Then, run the following commands:\n",
        "\n",
        "```\n",
        "curl -fsSL https://ollama.com/install.sh | sh # install ollama\n",
        "ollama serve &                                # start the ollama server and return the terminal\n",
        "ollama pull llama3.2:3b                       # pull llama3.2:1b (the model we'll be fine-tuning)\n",
        "```\n",
        "\n",
        "This will pull the model we'll be testing against."
      ],
      "metadata": {
        "id": "412bg_zxSfm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "Eet-v8uMdQuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqqq \\\n",
        "    huggingface_hub \\\n",
        "    bitsandbytes \\\n",
        "    accelerate \\\n",
        "    \"transformers[torch]\" \\\n",
        "    llama-cpp-python \\\n",
        "    vllm \\\n",
        "    \"llama-index>=0.11.17\" \\\n",
        "    \"llama-index-core>=0.10.43\" \\\n",
        "    \"openinference-instrumentation-llama-index>=2\" \\\n",
        "    \"opentelemetry-proto>=1.12.0\" \\\n",
        "    arize-phoenix-otel \\\n",
        "    nest-asyncio \\\n",
        "    llama-index-callbacks-arize-phoenix \\\n",
        "    llama-index-readers-database \\\n",
        "    llama-index-llms-openai \\\n",
        "    llama-index-embeddings-fastembed \\\n",
        "    llama-index-readers-database \\\n",
        "    fastembed-gpu \\\n",
        "    llama-index-llms-ollama \\\n",
        "    llama-index-agent-openai \\\n",
        "    --progress-bar off\n",
        "\n",
        "# Clone llama.cpp for conversion to gguf\n",
        "!git clone https://github.com/ggerganov/llama.cpp.git"
      ],
      "metadata": {
        "id": "eO4yVPCjs3Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d1df49-447f-440a-aa0c-57ebe74550ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "axolotl 0.4.1 requires pydantic==2.6.3, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mfatal: destination path 'llama.cpp' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "UPDY2usLePC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pydantic>=2.7.0,<3.0.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K93s-LAnZl42",
        "outputId": "e882b77b-0fef-4f2e-f2b5-73fd6182470d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from rich import print\n",
        "from typing import Literal, List\n",
        "from pydantic import BaseModel, Field\n",
        "from time import sleep\n",
        "from sqlalchemy import create_engine\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import os\n",
        "import phoenix as px\n",
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "from openinference.instrumentation import using_metadata\n",
        "from phoenix.otel import register\n",
        "from enum import Enum\n",
        "from tqdm.auto import tqdm\n",
        "from llama_index.core import VectorStoreIndex, Document\n",
        "from llama_index.core.tools import FunctionTool, QueryEngineTool, RetrieverTool\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core import PromptTemplate\n",
        "from llama_index.readers.database import DatabaseReader\n",
        "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.llms.ollama import Ollama\n",
        "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "# from llama_index.llms.llama_cpp import LlamaCPP\n",
        "# from llama_index.llms.vllm import Vllm\n",
        "from transformers import BitsAndBytesConfig\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = token"
      ],
      "metadata": {
        "id": "JQIM4p7FdPl_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you did not run the previous notebook, use the data from the repo\n",
        "if not os.path.exists('CTME-llm-lecture-resources'):\n",
        "    !git clone https://github.com/mgfrantz/CTME-llm-lecture-resources\n",
        "    !cp CTME-llm-lecture-resources/data/ecommerce.db .\n",
        "if os.path.exists('data'):\n",
        "    !rm -rf data\n",
        "!mkdir data\n",
        "!cp CTME-llm-lecture-resources/data/*.jsonl data/"
      ],
      "metadata": {
        "id": "LxxbjpDxdhln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838ce5d0-aef4-4524-bffa-f7c045eb44c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CTME-llm-lecture-resources'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 129 (delta 65), reused 41 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (129/129), 5.20 MiB | 4.57 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All the code to set up our agent ðŸ‘‡\n",
        "\n",
        "Since we have all the code we used to run our agent yesterday, let's bring that over so we can use it in this notebook.\n",
        "Here is the solution code, but if your code differs feel free to replace it with your own."
      ],
      "metadata": {
        "id": "bsyhE9pt0I2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if not os.path.exists('drive/MyDrive/CTME-LLM-labs/ecommerce.db'):\n",
        "#     print(\"The ecommerce.db database does not exist. Please make sure you're connected to Google Drive or upload it to the Colab notebook or re-run lesson 1.\")\n",
        "# !cp drive/MyDrive/CTME-LLM-labs/ecommerce.db ."
      ],
      "metadata": {
        "id": "loBqq6IZz80c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query(q:str, db:str='ecommerce.db') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Executes a SQL query against the SQLite database and returns the result as a pandas DataFrame.\n",
        "    Use this function when you want to query a database and return results.\n",
        "\n",
        "    Args:\n",
        "        q (str): The SQL query to execute.\n",
        "        db (str, optional): The path to the SQLite database file. Defaults to 'ecommerce.db'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The result of the SQL query as a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    connection = sqlite3.connect(db)\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(q)\n",
        "    result = cursor.fetchall()\n",
        "    df = pd.DataFrame(result)\n",
        "    df.columns = [i[0] for i in cursor.description]\n",
        "    connection.close()\n",
        "    return df\n",
        "\n",
        "def execute(q:str, db:str='ecommerce.db') -> None:\n",
        "    \"\"\"\n",
        "    Executes an SQL query against the SQLite database.\n",
        "    Use this when you want to run commands like updates, inserts, or deletes that don't return results.\n",
        "\n",
        "    Args:\n",
        "        q (str): The SQL query to execute.\n",
        "        db (str, optional): The path to the SQLite database file. Defaults to 'ecommerce.db'.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    connection = sqlite3.connect(db)\n",
        "    cursor = connection.cursor()\n",
        "    cursor.execute(q)\n",
        "    connection.commit()\n",
        "    connection.close()\n",
        "\n",
        "def instrument():\n",
        "    \"\"\"\n",
        "    Starts a poenix session.\n",
        "\n",
        "    Returns:\n",
        "        session: The phoenix session object.\n",
        "    \"\"\"\n",
        "    session = px.launch_app()\n",
        "    tracer_provider = register(endpoint=\"http://127.0.0.1:6006/v1/traces\")\n",
        "    LlamaIndexInstrumentor().instrument(skip_dep_check=True, tracer_provider=tracer_provider)\n",
        "    return session\n",
        "\n",
        "def end_session(session):\n",
        "    \"\"\"\n",
        "    Ends a phoenix session.\n",
        "\n",
        "    Args:\n",
        "        session: The phoenix session object.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    !rm {session.database_url.replace('sqlite:///', '')}\n",
        "    session.end()"
      ],
      "metadata": {
        "id": "F77zrrgjypDN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AGENT_SYSTEM_PROMPT = PromptTemplate(\"\"\"\\\n",
        "You are a helpul customer service assistant for MikeCorp, an ecommerce company selling electronics. \\\n",
        "You are designed to help with a variety of problems a customer may have, including account management, order management, and product-related queries. \\\n",
        "If you are ever unsure what to do, please escalate.\n",
        "\n",
        "## Tools\n",
        "\n",
        "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem\n",
        "appropriate to complete the task at hand.\n",
        "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
        "\n",
        "You have access to the following tools:\n",
        "{tool_desc}\n",
        "\n",
        "\n",
        "## Output Format\n",
        "\n",
        "Please answer in English using the following format:\n",
        "\n",
        "```\n",
        "Thought: I need to use a tool to help me answer the question.\n",
        "Action: tool name (one of {tool_names}) if using a tool.\n",
        "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
        "```\n",
        "\n",
        "Please ALWAYS start with a Thought.\n",
        "\n",
        "NEVER surround your response with markdown code markers. \\\n",
        "You may use code markers within your response if you need to.\n",
        "\n",
        "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
        "\n",
        "If this format is used, the user will respond in the following format:\n",
        "\n",
        "```\n",
        "Observation: tool response\n",
        "```\n",
        "\n",
        "You should keep repeating the above format till you have enough information \\\n",
        "to answer the question without using any more tools. \\\n",
        "At that point, you MUST respond in the one of the following two formats:\n",
        "\n",
        "```\n",
        "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
        "Answer:\n",
        "```\n",
        "\n",
        "```\n",
        "Thought: I cannot answer the question with the provided tools.\n",
        "Answer:\n",
        "```\n",
        "\n",
        "## Current Conversation\n",
        "\n",
        "Below is the current conversation consisting of interleaving human and assistant messages. \\\n",
        "Conversation:\n",
        "\"\"\")\n",
        "\n",
        "def get_random_id():\n",
        "    return query(\"SELECT customer_id FROM customers ORDER BY random() LIMIT 1;\").iloc[0,0]\n",
        "\n",
        "def create_agent(llm, tools, system_prompt=AGENT_SYSTEM_PROMPT, verbose=False):\n",
        "    agent = ReActAgent.from_tools(tools, llm=llm, verbose=verbose)\n",
        "    prompt_dict = agent.get_prompts()\n",
        "    prompt_dict['agent_worker:system_prompt'] = system_prompt\n",
        "    agent.update_prompts(prompt_dict)\n",
        "    return agent"
      ],
      "metadata": {
        "id": "IZiV5U_7zAgH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_customer_information_tool(customer_id:int):\n",
        "    def get_customer_information(*args, **kwargs) -> dict:\n",
        "        \"\"\"Use when you want to information about the customer.\n",
        "\n",
        "        Does not require any arguments.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the customer's information.\n",
        "        \"\"\"\n",
        "        data = query(f\"SELECT name, email, phone, street_address, city, state, zip_code, country FROM customers WHERE customer_id = {customer_id}\")\n",
        "        if len(data) == 0:\n",
        "            return {'error': 'Customer information not found on file.'}\n",
        "        else:\n",
        "            return data.to_dict(orient='records')[0]\n",
        "\n",
        "    return FunctionTool.from_defaults(fn=get_customer_information)\n",
        "\n",
        "def get_base_tools(customer_id=get_random_id()):\n",
        "    return [get_customer_information_tool(customer_id)]\n",
        "\n",
        "def does_id_exist(id:int)-> bool:\n",
        "    df = query(f\"SELECT customer_id FROM customers WHERE customer_id = {id}\")\n",
        "    if len(df) == 0:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def get_update_pin(customer_id:int) -> str:\n",
        "    if not does_id_exist(customer_id):\n",
        "        raise ValueError(\"Customer id not found on file.\")\n",
        "    def update_pin(new_pin:str) -> str:\n",
        "        \"\"\"Use when you want to update the customer's pin.\n",
        "\n",
        "        Args:\n",
        "            new_pin (str): The new pin.\n",
        "\n",
        "        Returns:\n",
        "            str: A message indicating the success or failure of the update.\n",
        "        \"\"\"\n",
        "        execute(f\"UPDATE customers SET pin = '{new_pin}' WHERE customer_id = {customer_id}\")\n",
        "        return \"Pin updated successfully.\"\n",
        "\n",
        "    return FunctionTool.from_defaults(update_pin)\n",
        "\n",
        "def get_update_address(customer_id:int):\n",
        "    if not does_id_exist(customer_id):\n",
        "        raise ValueError(\"Customer id not found on file.\")\n",
        "    def update_address(street:str, city:str, state:str, zip:str, country:str) -> str:\n",
        "        \"\"\"Use when you want to update the customer's address.\n",
        "\n",
        "        Args:\n",
        "            street (str): The street address.\n",
        "            city (str): The city.\n",
        "            state (str): The state.\n",
        "            zip (str): The zip code.\n",
        "            country (str): The country.\n",
        "\n",
        "        Returns:\n",
        "            str: A message indicating the success or failure of the update.\n",
        "        \"\"\"\n",
        "        execute(f\"UPDATE customers SET street_address = '{street}', city = '{city}', state = '{state}', zip_code = '{zip}', country = '{country}' WHERE customer_id = {customer_id}\")\n",
        "        return \"Address updated successfully.\"\n",
        "\n",
        "    return FunctionTool.from_defaults(update_address)\n",
        "\n",
        "def get_update_phone_number(customer_id:int):\n",
        "    if not does_id_exist(customer_id):\n",
        "        raise ValueError(\"Customer id not found on file.\")\n",
        "    def update_phone_number(phone:str) -> str:\n",
        "        \"\"\"Use when you want to update the customer's phone number.\n",
        "\n",
        "        Args:\n",
        "            customer_id (int): The customer ID.\n",
        "            phone (str): The new phone number.\n",
        "\n",
        "        Returns:\n",
        "            str: A message indicating the success or failure of the update.\n",
        "        \"\"\"\n",
        "        execute(f\"UPDATE customers SET phone = '{phone}' WHERE customer_id = {customer_id}\")\n",
        "        return \"Phone number updated successfully.\"\n",
        "\n",
        "    return FunctionTool.from_defaults(update_phone_number)\n",
        "\n",
        "def get_user_management_tools(customer_id=get_random_id()):\n",
        "    return [\n",
        "        get_update_pin(customer_id),\n",
        "        get_update_address(customer_id),\n",
        "        get_update_phone_number(customer_id)\n",
        "    ]\n",
        "\n",
        "def get_list_orders(customer_id:int):\n",
        "    if not does_id_exist(customer_id):\n",
        "        raise ValueError(\"Customer id not found on file.\")\n",
        "    def list_orders() -> List[dict]:\n",
        "        \"\"\"Use when you want to list all order data for a customer.\n",
        "\n",
        "        Args:\n",
        "            customer_id (int): The customer ID.\n",
        "\n",
        "        Returns:\n",
        "            List[dict]: A list of dictionaries containing the order data.\n",
        "        \"\"\"\n",
        "        df = query(f\"\"\"\n",
        "        SELECT o.order_id, i.name, o.ordered_date, o.status, o.estimated_delivery, o.shipping_carrier, o.tracking_number, o.shipping_address\n",
        "        FROM orders o\n",
        "        INNER JOIN customers c ON c.customer_id = o.customer_id\n",
        "        INNER JOIN items i ON i.item_id = o.item_id\n",
        "        WHERE c.customer_id = {customer_id}\n",
        "        \"\"\")\n",
        "        return df.to_dict(orient='records')\n",
        "    return FunctionTool.from_defaults(list_orders)\n",
        "\n",
        "def does_customer_have_order_id(customer_id, order_id):\n",
        "    df = query(f\"\"\"\n",
        "    SELECT order_id\n",
        "    FROM orders\n",
        "    WHERE customer_id = {customer_id} AND order_id = {order_id}\n",
        "    \"\"\")\n",
        "    if len(df) == 0:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def get_cancel_order(customer_id:int):\n",
        "    if not does_id_exist(customer_id):\n",
        "        raise ValueError(\"Customer id not found on file.\")\n",
        "    def cancel_order(order_id:int) -> str:\n",
        "        \"\"\"Use when you want to cancel an order.\n",
        "\n",
        "        Args:\n",
        "            order_id (int): the order ID.\n",
        "\n",
        "        Returns:\n",
        "            str\n",
        "        \"\"\"\n",
        "        if not does_customer_have_order_id(customer_id, order_id):\n",
        "            return \"Order does not belong to this customer.\"\n",
        "        execute(f\"UPDATE orders SET status = 'cancelled' WHERE order_id = '{order_id}'\")\n",
        "        return \"Order cancelled successfully.\"\n",
        "    return FunctionTool.from_defaults(cancel_order)\n",
        "\n",
        "def get_update_order_address(customer_id:int):\n",
        "    if not does_id_exist(customer_id):\n",
        "        raise ValueError(\"Customer id not found on file.\")\n",
        "    def update_order_address(order_id:int, new_street:str, new_city:str, new_zip:str, new_state:str, new_country:str) -> str:\n",
        "        \"\"\"Use when you want to update the shipping address of an order.\n",
        "\n",
        "        Args:\n",
        "            order_id (int): The order ID.\n",
        "            new_street (str): The new street address.\n",
        "            new_city (str): The new city.\n",
        "            new_zip (str): The new zip code.\n",
        "            new_state (str): The new state.\n",
        "            new_country (str): The new country.\n",
        "\n",
        "        Returns:\n",
        "            str: A message indicating the success or failure of the update.\n",
        "        \"\"\"\n",
        "        if not does_customer_have_order_id(customer_id, order_id):\n",
        "            return \"Order does not belong to this customer.\"\n",
        "        new_address = f\"{new_street}, {new_city}, {new_state}, {new_zip}, {new_country}\"\n",
        "        execute(f\"UPDATE orders SET shipping_address = '{new_address}' WHERE order_id = '{order_id}'\")\n",
        "        return \"Shipping address updated successfully.\"\n",
        "    return FunctionTool.from_defaults(update_order_address)\n",
        "\n",
        "def get_order_tools(customer_id=get_random_id()):\n",
        "    return [\n",
        "        get_list_orders(customer_id),\n",
        "        get_cancel_order(customer_id),\n",
        "        get_update_order_address(customer_id)\n",
        "    ]\n",
        "\n",
        "# Load documents\n",
        "engine = create_engine('sqlite:///ecommerce.db')\n",
        "docs = DatabaseReader(engine=engine).load_data(query=\"SELECT item_id, description, price, quantity, name AS text FROM items\")\n",
        "embed_model = FastEmbedEmbedding(model_name='mixedbread-ai/mxbai-embed-large-v1')\n",
        "index = VectorStoreIndex.from_documents(docs, embed_model=embed_model, show_progress=True)\n",
        "inventory_tools = [\n",
        "    RetrieverTool.from_defaults(index.as_retriever(), description=\"Useful when you need to answer a question by searching items.\", name='search_items'),\n",
        "]\n",
        "\n",
        "def get_all_tools(customer_id=get_random_id()):\n",
        "    return (\n",
        "        get_base_tools(customer_id)\n",
        "        + get_user_management_tools(customer_id)\n",
        "        + get_order_tools(customer_id)\n",
        "        + inventory_tools\n",
        "    )"
      ],
      "metadata": {
        "id": "SdJlJnpTy7Iz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "722f1cc4b4484b23aa85f650366bb4b4",
            "a90936afbc8146f88d023f733cddc787",
            "60535ee429be46e0b847466e549c1f5f",
            "dd00a145fee54b6b89dc588ce45501c6",
            "03962cafd4ce48be970bc16a77074489",
            "f8221fb2f0fd4517a7ebca4f004af489",
            "6e36771a377a4435af25f36b6c17e60c",
            "4468a395dab446ad85e7ad9ea57c8f40",
            "0d6cc91cff9747789837a93c1c2f3f02",
            "1d4b5811a6944ac889c025117061c799",
            "88abaac18fa743b68c11570d3e3e028b",
            "4c35ec348c1a4b06a31567cfa185334a",
            "c08fa4438acf4b7ab86c3982f7a2e5f9",
            "9a8e895650654a1eb0cdc068acb081c6",
            "254f373c2617412195247d891a214ace",
            "80bb527a06ab4dc49767acb270d6b930",
            "2722280362ba428a8f8b93e2da29aee2",
            "176265abb4e749209a9ff4e6d1923bd3",
            "6ee76e2fc87445e5a29088c07e67017d",
            "551265655e6e4196ba9ddd1607fc1d67",
            "8bab2082f94e48f49a116abf5fb5a39a",
            "c9069c85682c4adc913fa8a8c440d591",
            "6aef4e12ad124023aba8bcdcd2c3f18b",
            "03a4ddf72e62497c9162459d9fbb7682",
            "55fcf36f6fc94cbd9ec8c47db5d28319",
            "810f4672f179403c90109395bb6466a9",
            "1a3aef246d424db994ee9eb552961d9d",
            "07a6b69a23744f6d8690bc4049016346",
            "44e69bd2b0e641298cc96a969178773b",
            "2af17ea30ded4faba47dbac2338847e3",
            "d94220d42079473db4817b6fc4f0a3fe",
            "a3f6d7e29ca94e7db689c4c31095d71f",
            "a7713957755642bca5ca3535c1f05642"
          ]
        },
        "outputId": "3fed1dcd-47fb-489c-a65e-9c8d1c8df1d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "722f1cc4b4484b23aa85f650366bb4b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c35ec348c1a4b06a31567cfa185334a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aef4e12ad124023aba8bcdcd2c3f18b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Does our agent work at all with the un finetuned model?\n",
        "\n",
        "Let's use the `Ollama` LLM class to run `llama3.2:3b`.\n",
        "Make sure to run `ollama pull llama3.2:3b` in the Colab terminal before loading the model - otherwise it will give you an error.\n",
        "\n",
        "Once you've loaded the model, let's run a few basic things we'd expect our agent to do.\n",
        "Does it work?"
      ],
      "metadata": {
        "id": "jVsiwscL0Dn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = Ollama('llama3.2:3b') # this is the instruct model, I think\n",
        "# llm = Ollama('hf.co/QuantFactory/Llama-3.2-3B-GGUF:Q8_0')\n",
        "llm = Ollama('hf.co/mgfrantz/cmte-demo')"
      ],
      "metadata": {
        "id": "zeXujn64hqDh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_id = get_random_id()\n",
        "customer_info = get_customer_information_tool(customer_id)()\n",
        "print(customer_info)"
      ],
      "metadata": {
        "id": "H_AaZFIMh6PQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "55799288-fe23-431b-c616-d5fd5207af0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mToolOutput\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mcontent\u001b[0m=\u001b[32m\"\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'name': 'Ava Lewis', 'email': 'ava.lewis@example.com', 'phone': '555-3698', 'street_address': '999 \u001b[0m\n",
              "\u001b[32mRedwood St', 'city': 'Portland', 'state': 'OR', 'zip_code': '97201', 'country': 'US'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\u001b[0m,\n",
              "    \u001b[33mtool_name\u001b[0m=\u001b[32m'get_customer_information'\u001b[0m,\n",
              "    \u001b[33mraw_input\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'args'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[33mraw_output\u001b[0m=\u001b[1m{\u001b[0m\n",
              "        \u001b[32m'name'\u001b[0m: \u001b[32m'Ava Lewis'\u001b[0m,\n",
              "        \u001b[32m'email'\u001b[0m: \u001b[32m'ava.lewis@example.com'\u001b[0m,\n",
              "        \u001b[32m'phone'\u001b[0m: \u001b[32m'555-3698'\u001b[0m,\n",
              "        \u001b[32m'street_address'\u001b[0m: \u001b[32m'999 Redwood St'\u001b[0m,\n",
              "        \u001b[32m'city'\u001b[0m: \u001b[32m'Portland'\u001b[0m,\n",
              "        \u001b[32m'state'\u001b[0m: \u001b[32m'OR'\u001b[0m,\n",
              "        \u001b[32m'zip_code'\u001b[0m: \u001b[32m'97201'\u001b[0m,\n",
              "        \u001b[32m'country'\u001b[0m: \u001b[32m'US'\u001b[0m\n",
              "    \u001b[1m}\u001b[0m,\n",
              "    \u001b[33mis_error\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ToolOutput</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"{'name': 'Ava Lewis', 'email': 'ava.lewis@example.com', 'phone': '555-3698', 'street_address': '999 </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Redwood St', 'city': 'Portland', 'state': 'OR', 'zip_code': '97201', 'country': 'US'}\"</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_customer_information'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">raw_input</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">()</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'kwargs'</span>: <span style=\"font-weight: bold\">{}}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">raw_output</span>=<span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ava Lewis'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'email'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ava.lewis@example.com'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'phone'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'555-3698'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'street_address'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'999 Redwood St'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'city'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Portland'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'OR'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'zip_code'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'97201'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'country'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'US'</span>\n",
              "    <span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">is_error</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_agent(llm, get_all_tools(customer_id), verbose=True)"
      ],
      "metadata": {
        "id": "xPF2NcV-xsB4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.chat(\"What are my orders?\")"
      ],
      "metadata": {
        "id": "L2ITMguN0UTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26fab78-0477-4536-9913-06a3ac4b8fd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step c85262b7-34f5-4f0e-b0b2-494e058313ed. Step input: What are my orders?\n",
            "\u001b[1;3;38;5;200mThought: I need to retrieve the customer's information to access their order history.\n",
            "Action: get_customer_information\n",
            "Action Input: {}\n",
            "\u001b[0m\u001b[1;3;34mObservation: {'name': 'Ava Lewis', 'email': 'ava.lewis@example.com', 'phone': '555-3698', 'street_address': '999 Redwood St', 'city': 'Portland', 'state': 'OR', 'zip_code': '97201', 'country': 'US'}\n",
            "\u001b[0m> Running step 4e3e8410-793a-4b76-b408-a3c664d4e7db. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I have the customer's information. Now, I'll list their orders.\n",
            "Action: list_orders\n",
            "Action Input: {}\n",
            "\u001b[0m\u001b[1;3;34mObservation: [{'order_id': 17, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 18, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '30657', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 19, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 20, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '10640', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 21, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 22, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '93339', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 23, 'name': 'Smartphone X1', 'ordered_date': '2024-10-21', 'status': 'shipped', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 24, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-21', 'status': 'pending', 'estimated_delivery': '2024-10-30', 'shipping_carrier': 'Carrier B', 'tracking_number': '49153', 'shipping_address': '456 Elm St, City, Country'}, {'order_id': 25, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 26, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '97260', 'shipping_address': '456 Elm St, City, Country'}, {'order_id': 27, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '123 Main St, City, Country'}, {'order_id': 28, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '28589', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}]\n",
            "\u001b[0m> Running step f8c0adf7-0bc2-437c-9d02-9624779a1a88. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Here are your orders:\n",
            "\n",
            "1. **Order ID:** 17\n",
            "   - Product Name: Smartphone X1\n",
            "   - Ordered Date: October 1, 2024\n",
            "   - Status: Delivered\n",
            "   - Estimated Delivery: October 5, 2024\n",
            "   - Shipping Carrier: Carrier A\n",
            "   - Tracking Number: TRACK123\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "2. **Order ID:** 18\n",
            "   - Product Name: Smart Light Bulbs\n",
            "   - Ordered Date: October 20, 2024\n",
            "   - Status: Pending\n",
            "   - Estimated Delivery: October 25, 2024\n",
            "   - Shipping Carrier: Carrier B\n",
            "   - Tracking Number: 30657\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "3. **Order ID:** 19\n",
            "   - Product Name: Smartphone X1\n",
            "   - Ordered Date: October 1, 2024\n",
            "   - Status: Delivered\n",
            "   - Estimated Delivery: October 5, 2024\n",
            "   - Shipping Carrier: Carrier A\n",
            "   - Tracking Number: TRACK123\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "4. **Order ID:** 20\n",
            "   - Product Name: Smart Light Bulbs\n",
            "   - Ordered Date: October 20, 2024\n",
            "   - Status: Pending\n",
            "   - Estimated Delivery: October 25, 2024\n",
            "   - Shipping Carrier: Carrier B\n",
            "   - Tracking Number: 10640\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "5. **Order ID:** 21\n",
            "   - Product Name: Smartphone X1\n",
            "   - Ordered Date: October 1, 2024\n",
            "   - Status: Delivered\n",
            "   - Estimated Delivery: October 5, 2024\n",
            "   - Shipping Carrier: Carrier A\n",
            "   - Tracking Number: TRACK123\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "6. **Order ID:** 22\n",
            "   - Product Name: Smart Light Bulbs\n",
            "   - Ordered Date: October 20, 2024\n",
            "   - Status: Pending\n",
            "   - Estimated Delivery: October 25, 2024\n",
            "   - Shipping Carrier: Carrier B\n",
            "   - Tracking Number: 93339\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "7. **Order ID:** 23\n",
            "   - Product Name: Smartphone X1\n",
            "   - Ordered Date: October 21, 2024\n",
            "   - Status: Shipped\n",
            "   - Estimated Delivery: October 25, 2024\n",
            "   - Shipping Carrier: Carrier A\n",
            "   - Tracking Number: TRACK123\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "8. **Order ID:** 24\n",
            "   - Product Name: Smart Light Bulbs\n",
            "   - Ordered Date: October 21, 2024\n",
            "   - Status: Pending\n",
            "   - Estimated Delivery: October 30, 2024\n",
            "   - Shipping Carrier: Carrier B\n",
            "   - Tracking Number: 49153\n",
            "   - Shipping Address: 456 Elm St, City, Country\n",
            "\n",
            "9. **Order ID:** 25\n",
            "   - Product Name: Smartphone X1\n",
            "   - Ordered Date: October 1, 2024\n",
            "   - Status: Delivered\n",
            "   - Estimated Delivery: October 5, 2024\n",
            "   - Shipping Carrier: Carrier A\n",
            "   - Tracking Number: TRACK123\n",
            "   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "10. **Order ID:** 26\n",
            "    - Product Name: Smart Light Bulbs\n",
            "    - Ordered Date: October 20, 2024\n",
            "    - Status: Pending\n",
            "    - Estimated Delivery: October 25, 2024\n",
            "    - Shipping Carrier: Carrier B\n",
            "    - Tracking Number: 97260\n",
            "    - Shipping Address: 456 Elm St, City, Country\n",
            "\n",
            "11. **Order ID:** 27\n",
            "    - Product Name: Smartphone X1\n",
            "    - Ordered Date: October 1, 2024\n",
            "    - Status: Delivered\n",
            "    - Estimated Delivery: October 5, 2024\n",
            "    - Shipping Carrier: Carrier A\n",
            "    - Tracking Number: TRACK123\n",
            "    - Shipping Address: 123 Main St, City, Country\n",
            "\n",
            "12. **Order ID:** 28\n",
            "    - Product Name: Smart Light Bulbs\n",
            "    - Ordered Date: October 20, 2024\n",
            "    - Status: Pending\n",
            "    - Estimated Delivery: October 25, 2024\n",
            "    - Shipping Carrier: Carrier B\n",
            "    - Tracking Number: 28589\n",
            "    - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\n",
            "\n",
            "If you need any further assistance with these orders, feel free to ask!\n",
            "\n",
            "Let me know if I can help with anything else.\n",
            "\n",
            "Here's a helpful tip for future reference:\n",
            "\n",
            "1. You can access the customer's information at any time by typing `get_customer_information` in the chatbox.\n",
            "2. To update the customer's pin, you can use the command `update_pin`. Simply type the new pin after this command and it will be updated successfully.\n",
            "\n",
            "Have a great day!\n",
            "\n",
            "Thought: I cannot answer the question with the provided tools.\n",
            "Answer:\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentChatResponse(response=\"Here are your orders:\\n\\n1. **Order ID:** 17\\n   - Product Name: Smartphone X1\\n   - Ordered Date: October 1, 2024\\n   - Status: Delivered\\n   - Estimated Delivery: October 5, 2024\\n   - Shipping Carrier: Carrier A\\n   - Tracking Number: TRACK123\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n2. **Order ID:** 18\\n   - Product Name: Smart Light Bulbs\\n   - Ordered Date: October 20, 2024\\n   - Status: Pending\\n   - Estimated Delivery: October 25, 2024\\n   - Shipping Carrier: Carrier B\\n   - Tracking Number: 30657\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n3. **Order ID:** 19\\n   - Product Name: Smartphone X1\\n   - Ordered Date: October 1, 2024\\n   - Status: Delivered\\n   - Estimated Delivery: October 5, 2024\\n   - Shipping Carrier: Carrier A\\n   - Tracking Number: TRACK123\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n4. **Order ID:** 20\\n   - Product Name: Smart Light Bulbs\\n   - Ordered Date: October 20, 2024\\n   - Status: Pending\\n   - Estimated Delivery: October 25, 2024\\n   - Shipping Carrier: Carrier B\\n   - Tracking Number: 10640\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n5. **Order ID:** 21\\n   - Product Name: Smartphone X1\\n   - Ordered Date: October 1, 2024\\n   - Status: Delivered\\n   - Estimated Delivery: October 5, 2024\\n   - Shipping Carrier: Carrier A\\n   - Tracking Number: TRACK123\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n6. **Order ID:** 22\\n   - Product Name: Smart Light Bulbs\\n   - Ordered Date: October 20, 2024\\n   - Status: Pending\\n   - Estimated Delivery: October 25, 2024\\n   - Shipping Carrier: Carrier B\\n   - Tracking Number: 93339\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n7. **Order ID:** 23\\n   - Product Name: Smartphone X1\\n   - Ordered Date: October 21, 2024\\n   - Status: Shipped\\n   - Estimated Delivery: October 25, 2024\\n   - Shipping Carrier: Carrier A\\n   - Tracking Number: TRACK123\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n8. **Order ID:** 24\\n   - Product Name: Smart Light Bulbs\\n   - Ordered Date: October 21, 2024\\n   - Status: Pending\\n   - Estimated Delivery: October 30, 2024\\n   - Shipping Carrier: Carrier B\\n   - Tracking Number: 49153\\n   - Shipping Address: 456 Elm St, City, Country\\n\\n9. **Order ID:** 25\\n   - Product Name: Smartphone X1\\n   - Ordered Date: October 1, 2024\\n   - Status: Delivered\\n   - Estimated Delivery: October 5, 2024\\n   - Shipping Carrier: Carrier A\\n   - Tracking Number: TRACK123\\n   - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\n10. **Order ID:** 26\\n    - Product Name: Smart Light Bulbs\\n    - Ordered Date: October 20, 2024\\n    - Status: Pending\\n    - Estimated Delivery: October 25, 2024\\n    - Shipping Carrier: Carrier B\\n    - Tracking Number: 97260\\n    - Shipping Address: 456 Elm St, City, Country\\n\\n11. **Order ID:** 27\\n    - Product Name: Smartphone X1\\n    - Ordered Date: October 1, 2024\\n    - Status: Delivered\\n    - Estimated Delivery: October 5, 2024\\n    - Shipping Carrier: Carrier A\\n    - Tracking Number: TRACK123\\n    - Shipping Address: 123 Main St, City, Country\\n\\n12. **Order ID:** 28\\n    - Product Name: Smart Light Bulbs\\n    - Ordered Date: October 20, 2024\\n    - Status: Pending\\n    - Estimated Delivery: October 25, 2024\\n    - Shipping Carrier: Carrier B\\n    - Tracking Number: 28589\\n    - Shipping Address: 999 Redwood St, Portland, OR, 97201, US\\n\\nIf you need any further assistance with these orders, feel free to ask!\\n\\nLet me know if I can help with anything else.\\n\\nHere's a helpful tip for future reference:\\n\\n1. You can access the customer's information at any time by typing `get_customer_information` in the chatbox.\\n2. To update the customer's pin, you can use the command `update_pin`. Simply type the new pin after this command and it will be updated successfully.\\n\\nHave a great day!\\n\\nThought: I cannot answer the question with the provided tools.\\nAnswer:\", sources=[ToolOutput(content=\"{'name': 'Ava Lewis', 'email': 'ava.lewis@example.com', 'phone': '555-3698', 'street_address': '999 Redwood St', 'city': 'Portland', 'state': 'OR', 'zip_code': '97201', 'country': 'US'}\", tool_name='get_customer_information', raw_input={'args': (), 'kwargs': {}}, raw_output={'name': 'Ava Lewis', 'email': 'ava.lewis@example.com', 'phone': '555-3698', 'street_address': '999 Redwood St', 'city': 'Portland', 'state': 'OR', 'zip_code': '97201', 'country': 'US'}, is_error=False), ToolOutput(content=\"[{'order_id': 17, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 18, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '30657', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 19, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 20, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '10640', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 21, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 22, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '93339', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 23, 'name': 'Smartphone X1', 'ordered_date': '2024-10-21', 'status': 'shipped', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 24, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-21', 'status': 'pending', 'estimated_delivery': '2024-10-30', 'shipping_carrier': 'Carrier B', 'tracking_number': '49153', 'shipping_address': '456 Elm St, City, Country'}, {'order_id': 25, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 26, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '97260', 'shipping_address': '456 Elm St, City, Country'}, {'order_id': 27, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '123 Main St, City, Country'}, {'order_id': 28, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '28589', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}]\", tool_name='list_orders', raw_input={'args': (), 'kwargs': {}}, raw_output=[{'order_id': 17, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 18, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '30657', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 19, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 20, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '10640', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 21, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 22, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '93339', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 23, 'name': 'Smartphone X1', 'ordered_date': '2024-10-21', 'status': 'shipped', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 24, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-21', 'status': 'pending', 'estimated_delivery': '2024-10-30', 'shipping_carrier': 'Carrier B', 'tracking_number': '49153', 'shipping_address': '456 Elm St, City, Country'}, {'order_id': 25, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}, {'order_id': 26, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '97260', 'shipping_address': '456 Elm St, City, Country'}, {'order_id': 27, 'name': 'Smartphone X1', 'ordered_date': '2024-10-01', 'status': 'delivered', 'estimated_delivery': '2024-10-05', 'shipping_carrier': 'Carrier A', 'tracking_number': 'TRACK123', 'shipping_address': '123 Main St, City, Country'}, {'order_id': 28, 'name': 'Smart Light Bulbs', 'ordered_date': '2024-10-20', 'status': 'pending', 'estimated_delivery': '2024-10-25', 'shipping_carrier': 'Carrier B', 'tracking_number': '28589', 'shipping_address': '999 Redwood St, Portland, OR, 97201, US'}], is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion:\n",
        "\n",
        "* Based on the model's outputs, what do you think the training process was?\n",
        "* Did it give any of the right information?\n",
        "* Did it call any functions? Why/why not do you think this happened?\n",
        "* Do you think the model learning our previous conversations might help?"
      ],
      "metadata": {
        "id": "1o-I-eEbVo_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning: Environment setup and imports\n",
        "\n",
        "In this section, we install and set up `axolotl`, the framework we will use to configure our fine tuning.\n",
        "We will also configure our `HF_TOKEN` here, so we can upload our model to ðŸ¤— once we're done fine-tuning."
      ],
      "metadata": {
        "id": "YSBVexvhTeoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install axolotl\n",
        "import os\n",
        "if os.path.exists(\"axolotl\"):\n",
        "  !rm -rf axolotl\n",
        "!git clone https://github.com/axolotl-ai-cloud/axolotl\n",
        "# This handles a mismatch between xformers torch requirements and that of other dependencies\n",
        "with open('/content/axolotl/requirements.txt', 'r') as file:\n",
        "    requirements = file.read()\n",
        "    # replace xformers==0.0.27 with xformers\n",
        "    requirements = requirements.replace('xformers==0.0.27', 'xformers')\n",
        "with open('/content/axolotl/requirements.txt', 'w') as file:\n",
        "    file.write(requirements)\n",
        "!pip install -qqqq ninja packaging mlflow==\"2.13.0\" --progress-bar off\n",
        "!cd axolotl && pip install -qqqq -e \".[flash-attn,deepspeed]\" --progress-bar off"
      ],
      "metadata": {
        "id": "liriqWCjtFfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b384cab-c3e8-4323-b7f6-24e494ff3dfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'axolotl'...\n",
            "remote: Enumerating objects: 17246, done.\u001b[K\n",
            "remote: Counting objects: 100% (964/964), done.\u001b[K\n",
            "remote: Compressing objects: 100% (324/324), done.\u001b[K\n",
            "remote: Total 17246 (delta 578), reused 884 (delta 533), pack-reused 16282 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17246/17246), 6.33 MiB | 6.41 MiB/s, done.\n",
            "Resolving deltas: 100% (11209/11209), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fschat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.15 requires pydantic>=2.7.0, but you have pydantic 2.6.3 which is incompatible.\n",
            "llama-index-core 0.11.19 requires pydantic<3.0.0,>=2.7.0, but you have pydantic 2.6.3 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.4.0 which is incompatible.\n",
            "vllm 0.6.1.post2 requires pydantic>=2.9, but you have pydantic 2.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jSYMsvJR214f"
      },
      "outputs": [],
      "source": [
        "# Set the `HF_TOKEN` env variable\n",
        "from google.colab import userdata\n",
        "import os\n",
        "token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pull in our train.jsonl and eval.jsonl from Google drive\n",
        "# if not os.path.exists(\"/content/drive/MyDrive/CTME-LLM-labs/train.jsonl\"):\n",
        "#     raise ValueError(\"data.jsonl does not exist. Please make sure you've connected to google drive and run the first two lab notebooks.\")\n",
        "# else:\n",
        "#     try:\n",
        "#         !rm -r data\n",
        "#     except:\n",
        "#         pass\n",
        "#     !mkdir data\n",
        "#     !cp /content/drive/MyDrive/CTME-LLM-labs/*.jsonl data/"
      ],
      "metadata": {
        "id": "U9S0gnK4XQUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe 1 row from the training data.\n",
        "!head data/train.jsonl -n 1 | python -m json.tool"
      ],
      "metadata": {
        "id": "mJjI_NJ_k-3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c33cdb-8a9d-4c96-8672-7a48cd231073"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"conversations\": [\n",
            "        {\n",
            "            \"value\": \"You are a helpul customer service assistant for MikeCorp, an ecommerce company selling electronics. You are designed to help with a variety of problems a customer may have, including account management, order management, and product-related queries. If you are ever unsure what to do, please escalate.\\n\\n## Tools\\n\\nYou have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem\\nappropriate to complete the task at hand.\\nThis may require breaking the task into subtasks and using different tools to complete each subtask.\\n\\nYou have access to the following tools:\\n> Tool Name: get_customer_information\\nTool Description: get_customer_information(*args, **kwargs) -> dict\\nUse when you want to information about the customer.\\n\\n        Does not require any arguments.\\n\\n        Returns:\\n            dict: A dictionary containing the customer's information.\\n        \\nTool Args: {\\\"properties\\\": {\\\"args\\\": {\\\"title\\\": \\\"Args\\\"}, \\\"kwargs\\\": {\\\"title\\\": \\\"Kwargs\\\"}}, \\\"required\\\": [\\\"args\\\", \\\"kwargs\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: update_pin\\nTool Description: update_pin(new_pin: str) -> str\\nUse when you want to update the customer's pin.\\n\\n        Args:\\n            new_pin (str): The new pin.\\n\\n        Returns:\\n            str: A message indicating the success or failure of the update.\\n        \\nTool Args: {\\\"properties\\\": {\\\"new_pin\\\": {\\\"title\\\": \\\"New Pin\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"new_pin\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: update_address\\nTool Description: update_address(street: str, city: str, state: str, zip: str, country: str) -> str\\nUse when you want to update the customer's address.\\n\\n        Args:\\n            street (str): The street address.\\n            city (str): The city.\\n            state (str): The state.\\n            zip (str): The zip code.\\n            country (str): The country.\\n\\n        Returns:\\n            str: A message indicating the success or failure of the update.\\n        \\nTool Args: {\\\"properties\\\": {\\\"street\\\": {\\\"title\\\": \\\"Street\\\", \\\"type\\\": \\\"string\\\"}, \\\"city\\\": {\\\"title\\\": \\\"City\\\", \\\"type\\\": \\\"string\\\"}, \\\"state\\\": {\\\"title\\\": \\\"State\\\", \\\"type\\\": \\\"string\\\"}, \\\"zip\\\": {\\\"title\\\": \\\"Zip\\\", \\\"type\\\": \\\"string\\\"}, \\\"country\\\": {\\\"title\\\": \\\"Country\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"street\\\", \\\"city\\\", \\\"state\\\", \\\"zip\\\", \\\"country\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: update_phone_number\\nTool Description: update_phone_number(phone: str) -> str\\nUse when you want to update the customer's phone number.\\n\\n        Args:\\n            customer_id (int): The customer ID.\\n            phone (str): The new phone number.\\n\\n        Returns:\\n            str: A message indicating the success or failure of the update.\\n        \\nTool Args: {\\\"properties\\\": {\\\"phone\\\": {\\\"title\\\": \\\"Phone\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"phone\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: list_orders\\nTool Description: list_orders() -> List[dict]\\nUse when you want to list all order data for a customer.\\n\\n        Args:\\n            customer_id (int): The customer ID.\\n\\n        Returns:\\n            List[dict]: A list of dictionaries containing the order data.\\n        \\nTool Args: {\\\"properties\\\": {}, \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: cancel_order\\nTool Description: cancel_order(order_id: int) -> str\\nUse when you want to cancel an order.\\n\\n        Args:\\n            order_id (int): the order ID.\\n\\n        Returns:\\n            str\\n        \\nTool Args: {\\\"properties\\\": {\\\"order_id\\\": {\\\"title\\\": \\\"Order Id\\\", \\\"type\\\": \\\"integer\\\"}}, \\\"required\\\": [\\\"order_id\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: update_order_address\\nTool Description: update_order_address(order_id: int, new_street: str, new_city: str, new_zip: str, new_state: str, new_country: str) -> str\\nUse when you want to update the shipping address of an order.\\n\\n        Args:\\n            order_id (int): The order ID.\\n            new_street (str): The new street address.\\n            new_city (str): The new city.\\n            new_zip (str): The new zip code.\\n            new_state (str): The new state.\\n            new_country (str): The new country.\\n\\n        Returns:\\n            str: A message indicating the success or failure of the update.\\n        \\nTool Args: {\\\"properties\\\": {\\\"order_id\\\": {\\\"title\\\": \\\"Order Id\\\", \\\"type\\\": \\\"integer\\\"}, \\\"new_street\\\": {\\\"title\\\": \\\"New Street\\\", \\\"type\\\": \\\"string\\\"}, \\\"new_city\\\": {\\\"title\\\": \\\"New City\\\", \\\"type\\\": \\\"string\\\"}, \\\"new_zip\\\": {\\\"title\\\": \\\"New Zip\\\", \\\"type\\\": \\\"string\\\"}, \\\"new_state\\\": {\\\"title\\\": \\\"New State\\\", \\\"type\\\": \\\"string\\\"}, \\\"new_country\\\": {\\\"title\\\": \\\"New Country\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"order_id\\\", \\\"new_street\\\", \\\"new_city\\\", \\\"new_zip\\\", \\\"new_state\\\", \\\"new_country\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n> Tool Name: search_items\\nTool Description: Useful when you need to answer a question by searching items.\\nTool Args: {\\\"properties\\\": {\\\"input\\\": {\\\"title\\\": \\\"Input\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"input\\\"], \\\"type\\\": \\\"object\\\"}\\n\\n\\n\\n## Output Format\\n\\nPlease answer in English using the following format:\\n\\n```\\nThought: I need to use a tool to help me answer the question.\\nAction: tool name (one of get_customer_information, update_pin, update_address, update_phone_number, list_orders, cancel_order, update_order_address, search_items) if using a tool.\\nAction Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\\\"input\\\": \\\"hello world\\\", \\\"num_beams\\\": 5})\\n```\\n\\nPlease ALWAYS start with a Thought.\\n\\nNEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\\n\\nPlease use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\\n\\nIf this format is used, the user will respond in the following format:\\n\\n```\\nObservation: tool response\\n```\\n\\nYou should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\\n\\n```\\nThought: I can answer without using any more tools. I'll use the user's language to answer\\nAnswer:\\n```\\n\\n```\\nThought: I cannot answer the question with the provided tools.\\nAnswer:\\n```\\n\\n## Current Conversation\\n\\nBelow is the current conversation consisting of interleaving human and assistant messages. Conversation:\\n\",\n",
            "            \"from\": \"system\"\n",
            "        },\n",
            "        {\n",
            "            \"value\": \"Hi, I would like to check my current orders. Can you help me with that?\",\n",
            "            \"from\": \"human\"\n",
            "        },\n",
            "        {\n",
            "            \"value\": \"Thought: I need to retrieve the customer's information to access their orders.\\nAction: get_customer_information\\nAction Input: {}\",\n",
            "            \"from\": \"gpt\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Axolotl configuration\n",
        "\n",
        "In this section, we define everything about how we want to fine tune the model, including what model we want to fine tune, where the data is, what template we want to use, and where to export the model.\n",
        "\n",
        "This config was mostly copied from [Axolotl's repositlry of examples](https://github.com/axolotl-ai-cloud/axolotl/tree/main/examples).\n",
        "You can spend a lot of time fiddling aroudn with hyperparameters, but these examples are pretty good and relatively easy to modify for anything you want to do.\n",
        "Your time is *much* better spent curating data and making sure your data is properly formatted rather than messing around with hyperparameters.\n",
        "There are also model-specific quirks that mean it's challenging to apply one fine tuning configuration to another model.\n",
        "For example, the modules targeted for LoRA adaptes may be named differently in different model families (llama, gemma, mistral, etc.).\n",
        "Do yourself a favor and start with something that works!"
      ],
      "metadata": {
        "id": "s7BQ-DosToZW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wWZ4a8_hu9yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c904169b-2763-44f5-ea58-2008fb339c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting axolotl.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile axolotl.yaml\n",
        "base_model: meta-llama/Llama-3.2-3B\n",
        "\n",
        "load_in_8bit: false\n",
        "load_in_4bit: true\n",
        "strict: false\n",
        "adapter: qlora\n",
        "\n",
        "# Data config\n",
        "dataset_prepared_path: data\n",
        "chat_template: llama3\n",
        "datasets:\n",
        "  - path: data/train.jsonl\n",
        "    ds_type: json\n",
        "    data_files:\n",
        "      - data/train.jsonl\n",
        "    type: sharegpt\n",
        "\n",
        "test_datasets:\n",
        "  - path: data/eval.jsonl\n",
        "    ds_type: json\n",
        "    # You need to specify a split. For \"json\" datasets the default split is called \"train\".\n",
        "    split: train\n",
        "    type: sharegpt\n",
        "    data_files:\n",
        "      - data/eval.jsonl\n",
        "\n",
        "sequence_len: 4096\n",
        "sample_packing: true\n",
        "eval_sample_packing: true\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "lora_target_modules:\n",
        "  - gate_proj\n",
        "  - down_proj\n",
        "  - up_proj\n",
        "  - q_proj\n",
        "  - v_proj\n",
        "  - k_proj\n",
        "  - o_proj\n",
        "\n",
        "wandb_project:\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "gradient_accumulation_steps: 8\n",
        "micro_batch_size: 2\n",
        "num_epochs: 2\n",
        "optimizer: adamw_bnb_8bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: auto\n",
        "fp16:\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention: true\n",
        "\n",
        "loss_watchdog_threshold: 5.0\n",
        "loss_watchdog_patience: 3\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch: 4\n",
        "eval_table_size:\n",
        "eval_max_new_tokens: 128\n",
        "saves_per_epoch: 1\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "  pad_token: <|finetune_right_pad_id|>\n",
        "  eos_token: <|eot_id|>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "\n",
        "Currently, our data is in the `sharegpt` format, we have an array of conversations with a `from` and a `value` field that can't directly be used to fine-tune the model.\n",
        "We also want to convey important information to the model for each message, such as the role, whether it's a tool call/structured output, etc.\n",
        "We will be useing the `llama3` template today (docs [here](https://www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-3/#special-tokens-used-with-llama-3)).\n",
        "\n",
        "We also need to tokenize our data - turn it into tensrs of integers that the model can read and learn from.\n",
        "`axolotl` will also help us tokenize the data and perfom several optimizations such as sample packing (putting multiple smaller samples in the same training example to reduce the number of padding tokens) and creating masks so we don't train on system prompts and user messages.\n",
        "\n",
        "Thankfully, `axolotl` handles all these complex configs!"
      ],
      "metadata": {
        "id": "KudCtoIsYngV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the data\n",
        "!python -m axolotl.cli.preprocess /content/axolotl.yaml"
      ],
      "metadata": {
        "id": "Vu_Zf2PUYphn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35a27ed-a616-4ced-f9ef-3a3819c5b519"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-23 21:04:08.428029: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-23 21:04:08.962386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-23 21:04:09.211983: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-23 21:04:09.282463: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-23 21:04:09.718764: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-23 21:04:11.192195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, forward_function, hidden_states, *args):\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:40: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dY):\n",
            "[2024-10-23 21:04:15,775] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-10-23 21:04:15,855] [INFO] [root.spawn:60] [PID:9597] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpvhwi5m3r/test.c -o /tmp/tmpvhwi5m3r/test.o\n",
            "[2024-10-23 21:04:15,873] [INFO] [root.spawn:60] [PID:9597] x86_64-linux-gnu-gcc /tmp/tmpvhwi5m3r/test.o -laio -o /tmp/tmpvhwi5m3r/a.out\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "[2024-10-23 21:04:21,506] [DEBUG] [axolotl.normalize_config:83] [PID:9597] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "config.json: 100% 844/844 [00:00<00:00, 4.35MB/s]\n",
            "[2024-10-23 21:04:22,002] [INFO] [axolotl.normalize_config:207] [PID:9597] [RANK:0] GPU memory usage baseline: 0.000GB (+0.331GB misc)\u001b[39m\n",
            "[2024-10-23 21:04:22,002] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:9597] [RANK:0] updating dataset data/train.jsonl with `conversation: llama3` to match your chat_template\u001b[39m\n",
            "tokenizer_config.json: 100% 50.5k/50.5k [00:00<00:00, 57.8MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 14.9MB/s]\n",
            "special_tokens_map.json: 100% 301/301 [00:00<00:00, 1.97MB/s]\n",
            "[2024-10-23 21:04:25,570] [DEBUG] [axolotl.load_tokenizer:290] [PID:9597] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-23 21:04:25,570] [DEBUG] [axolotl.load_tokenizer:291] [PID:9597] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-23 21:04:25,570] [DEBUG] [axolotl.load_tokenizer:292] [PID:9597] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-23 21:04:25,570] [DEBUG] [axolotl.load_tokenizer:293] [PID:9597] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-23 21:04:25,570] [INFO] [axolotl.load_tokenized_prepared_datasets:206] [PID:9597] [RANK:0] Skipping prepared dataset in data/1a30e7233b3444192cecdbec92ab7aeb for pre-processing...\u001b[39m\n",
            "[2024-10-23 21:04:25,571] [INFO] [axolotl.load_tokenized_prepared_datasets:211] [PID:9597] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "[2024-10-23 21:04:25,571] [INFO] [axolotl.load_tokenized_prepared_datasets:220] [PID:9597] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Generating train split: 460 examples [00:00, 30091.08 examples/s]\n",
            "[2024-10-23 21:04:26,526] [INFO] [axolotl.get_dataset_wrapper:588] [PID:9597] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
            "\u001b[33m[2024-10-23 21:04:26,526] [WARNING] [axolotl._load:64] [PID:9597] [RANK:0] sharegpt type support will be deprecated in the next release of Axolotl. Please use chat_template instead.\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12):   5% 25/460 [00:01<00:20, 21.02 examples/s]\u001b[33m[2024-10-23 21:04:28,544] [WARNING] [axolotl._build_result:366] [PID:9786] [RANK:0] Role did not alternate between turns (gpt and human). Please check your data.: {'from': 'human', 'value': 'Observation: Error: Could not parse output. Please follow the thought-action-input format. Try again.', 'weight': 1}\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 460/460 [00:04<00:00, 113.90 examples/s]\n",
            "[2024-10-23 21:04:31,121] [DEBUG] [axolotl.process_datasets_for_packing:189] [PID:9597] [RANK:0] min_input_len: 1488\u001b[39m\n",
            "[2024-10-23 21:04:31,122] [DEBUG] [axolotl.process_datasets_for_packing:191] [PID:9597] [RANK:0] max_input_len: 4823\u001b[39m\n",
            "Dropping Long Sequences (num_proc=12): 100% 460/460 [00:00<00:00, 1221.93 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=12): 100% 458/458 [00:00<00:00, 1052.40 examples/s]\n",
            "Add position_id column (Sample Packing) (num_proc=12): 100% 458/458 [00:00<00:00, 1454.94 examples/s]\n",
            "[2024-10-23 21:04:35,032] [INFO] [axolotl.load_tokenized_prepared_datasets:467] [PID:9597] [RANK:0] Saving merged prepared dataset to disk... data/1a30e7233b3444192cecdbec92ab7aeb\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 458/458 [00:00<00:00, 13664.85 examples/s]\n",
            "[2024-10-23 21:04:35,069] [INFO] [axolotl.load_tokenized_prepared_datasets:206] [PID:9597] [RANK:0] Skipping prepared dataset in data/7881ad52902f690d2de1df7a65e475e3 for pre-processing...\u001b[39m\n",
            "[2024-10-23 21:04:35,069] [INFO] [axolotl.load_tokenized_prepared_datasets:211] [PID:9597] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "[2024-10-23 21:04:35,069] [INFO] [axolotl.load_tokenized_prepared_datasets:220] [PID:9597] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Generating train split: 156 examples [00:00, 24439.23 examples/s]\n",
            "[2024-10-23 21:04:35,989] [INFO] [axolotl.get_dataset_wrapper:588] [PID:9597] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
            "\u001b[33m[2024-10-23 21:04:35,989] [WARNING] [axolotl._load:64] [PID:9597] [RANK:0] sharegpt type support will be deprecated in the next release of Axolotl. Please use chat_template instead.\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 156/156 [00:04<00:00, 36.11 examples/s]\n",
            "[2024-10-23 21:04:40,904] [DEBUG] [axolotl.process_datasets_for_packing:189] [PID:9597] [RANK:0] min_input_len: 1486\u001b[39m\n",
            "[2024-10-23 21:04:40,904] [DEBUG] [axolotl.process_datasets_for_packing:191] [PID:9597] [RANK:0] max_input_len: 3075\u001b[39m\n",
            "Dropping Long Sequences (num_proc=12): 100% 156/156 [00:00<00:00, 620.42 examples/s]\n",
            "Drop Samples with Zero Trainable Tokens (num_proc=12): 100% 156/156 [00:00<00:00, 548.38 examples/s]\n",
            "Add position_id column (Sample Packing) (num_proc=12): 100% 156/156 [00:00<00:00, 650.75 examples/s]\n",
            "[2024-10-23 21:04:44,531] [INFO] [axolotl.load_tokenized_prepared_datasets:467] [PID:9597] [RANK:0] Saving merged prepared dataset to disk... data/7881ad52902f690d2de1df7a65e475e3\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 156/156 [00:00<00:00, 9083.37 examples/s]\n",
            "[2024-10-23 21:04:44,557] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:9597] [RANK:0] total_num_tokens: 281_304\u001b[39m\n",
            "[2024-10-23 21:04:44,561] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:9597] [RANK:0] `total_supervised_tokens: 37_701`\u001b[39m\n",
            "[2024-10-23 21:04:51,414] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:9597] [RANK:0] gather_len_batches: [9]\u001b[39m\n",
            "[2024-10-23 21:04:51,415] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:9597] [RANK:0] data_loader_len: 4\u001b[39m\n",
            "[2024-10-23 21:04:51,415] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:9597] [RANK:0] sample_packing_eff_est across ranks: [0.953857421875]\u001b[39m\n",
            "[2024-10-23 21:04:51,415] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:9597] [RANK:0] sample_packing_eff_est: None\u001b[39m\n",
            "[2024-10-23 21:04:51,415] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:9597] [RANK:0] total_num_steps: 8\u001b[39m\n",
            "[2024-10-23 21:04:51,419] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:9597] [RANK:0] total_num_tokens: 825_623\u001b[39m\n",
            "[2024-10-23 21:04:51,430] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:9597] [RANK:0] `total_supervised_tokens: 106_188`\u001b[39m\n",
            "[2024-10-23 21:04:51,437] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:9597] [RANK:0] gather_len_batches: [27]\u001b[39m\n",
            "[2024-10-23 21:04:51,437] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:9597] [RANK:0] data_loader_len: 13\u001b[39m\n",
            "[2024-10-23 21:04:51,437] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:9597] [RANK:0] sample_packing_eff_est across ranks: [0.9331857186776621]\u001b[39m\n",
            "[2024-10-23 21:04:51,437] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:9597] [RANK:0] sample_packing_eff_est: 0.94\u001b[39m\n",
            "[2024-10-23 21:04:51,437] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:9597] [RANK:0] total_num_steps: 26\u001b[39m\n",
            "[2024-10-23 21:04:51,437] [INFO] [axolotl.scripts.load_datasets:471] [PID:9597] [RANK:0] check_dataset_labels...\u001b[39m\n",
            "[2024-10-23 21:04:51,491] [INFO] [axolotl.check_example_labels:45] [PID:9597] [RANK:0] \u001b[31m<|begin_of_text|>\u001b[0m\u001b[97m(-100, 128000)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31msystem\u001b[0m\u001b[97m(-100, 9125)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m help\u001b[0m\u001b[97m(-100, 1520)\u001b[0m \u001b[31mul\u001b[0m\u001b[97m(-100, 360)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m service\u001b[0m\u001b[97m(-100, 2532)\u001b[0m \u001b[31m assistant\u001b[0m\u001b[97m(-100, 18328)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m Mike\u001b[0m\u001b[97m(-100, 11519)\u001b[0m \u001b[31mCorp\u001b[0m\u001b[97m(-100, 95895)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m ecommerce\u001b[0m\u001b[97m(-100, 85243)\u001b[0m \u001b[31m company\u001b[0m\u001b[97m(-100, 2883)\u001b[0m \u001b[31m selling\u001b[0m\u001b[97m(-100, 11486)\u001b[0m \u001b[31m electronics\u001b[0m\u001b[97m(-100, 31591)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m You\u001b[0m\u001b[97m(-100, 1472)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m designed\u001b[0m\u001b[97m(-100, 6319)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m help\u001b[0m\u001b[97m(-100, 1520)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m variety\u001b[0m\u001b[97m(-100, 8205)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m problems\u001b[0m\u001b[97m(-100, 5435)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m may\u001b[0m\u001b[97m(-100, 1253)\u001b[0m \u001b[31m have\u001b[0m\u001b[97m(-100, 617)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m including\u001b[0m\u001b[97m(-100, 2737)\u001b[0m \u001b[31m account\u001b[0m\u001b[97m(-100, 2759)\u001b[0m \u001b[31m management\u001b[0m\u001b[97m(-100, 6373)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m management\u001b[0m\u001b[97m(-100, 6373)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m and\u001b[0m\u001b[97m(-100, 323)\u001b[0m \u001b[31m product\u001b[0m\u001b[97m(-100, 2027)\u001b[0m \u001b[31m-related\u001b[0m\u001b[97m(-100, 14228)\u001b[0m \u001b[31m queries\u001b[0m\u001b[97m(-100, 20126)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m If\u001b[0m\u001b[97m(-100, 1442)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m ever\u001b[0m\u001b[97m(-100, 3596)\u001b[0m \u001b[31m unsure\u001b[0m\u001b[97m(-100, 44003)\u001b[0m \u001b[31m what\u001b[0m\u001b[97m(-100, 1148)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m do\u001b[0m\u001b[97m(-100, 656)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m please\u001b[0m\u001b[97m(-100, 4587)\u001b[0m \u001b[31m escalate\u001b[0m\u001b[97m(-100, 89690)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m##\u001b[0m\u001b[97m(-100, 567)\u001b[0m \u001b[31m Tools\u001b[0m\u001b[97m(-100, 14173)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m have\u001b[0m\u001b[97m(-100, 617)\u001b[0m \u001b[31m access\u001b[0m\u001b[97m(-100, 2680)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m wide\u001b[0m\u001b[97m(-100, 7029)\u001b[0m \u001b[31m variety\u001b[0m\u001b[97m(-100, 8205)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m You\u001b[0m\u001b[97m(-100, 1472)\u001b[0m \u001b[31m are\u001b[0m\u001b[97m(-100, 527)\u001b[0m \u001b[31m responsible\u001b[0m\u001b[97m(-100, 8647)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m using\u001b[0m\u001b[97m(-100, 1701)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m any\u001b[0m\u001b[97m(-100, 904)\u001b[0m \u001b[31m sequence\u001b[0m\u001b[97m(-100, 8668)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m deem\u001b[0m\u001b[97m(-100, 82577)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mappropriate\u001b[0m\u001b[97m(-100, 29228)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m complete\u001b[0m\u001b[97m(-100, 4686)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m task\u001b[0m\u001b[97m(-100, 3465)\u001b[0m \u001b[31m at\u001b[0m\u001b[97m(-100, 520)\u001b[0m \u001b[31m hand\u001b[0m\u001b[97m(-100, 1450)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mThis\u001b[0m\u001b[97m(-100, 2028)\u001b[0m \u001b[31m may\u001b[0m\u001b[97m(-100, 1253)\u001b[0m \u001b[31m require\u001b[0m\u001b[97m(-100, 1397)\u001b[0m \u001b[31m breaking\u001b[0m\u001b[97m(-100, 15061)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m task\u001b[0m\u001b[97m(-100, 3465)\u001b[0m \u001b[31m into\u001b[0m\u001b[97m(-100, 1139)\u001b[0m \u001b[31m sub\u001b[0m\u001b[97m(-100, 1207)\u001b[0m \u001b[31mtasks\u001b[0m\u001b[97m(-100, 25792)\u001b[0m \u001b[31m and\u001b[0m\u001b[97m(-100, 323)\u001b[0m \u001b[31m using\u001b[0m\u001b[97m(-100, 1701)\u001b[0m \u001b[31m different\u001b[0m\u001b[97m(-100, 2204)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m complete\u001b[0m\u001b[97m(-100, 4686)\u001b[0m \u001b[31m each\u001b[0m\u001b[97m(-100, 1855)\u001b[0m \u001b[31m sub\u001b[0m\u001b[97m(-100, 1207)\u001b[0m \u001b[31mtask\u001b[0m\u001b[97m(-100, 8366)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m have\u001b[0m\u001b[97m(-100, 617)\u001b[0m \u001b[31m access\u001b[0m\u001b[97m(-100, 2680)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m following\u001b[0m\u001b[97m(-100, 2768)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m get\u001b[0m\u001b[97m(-100, 636)\u001b[0m \u001b[31m_customer\u001b[0m\u001b[97m(-100, 29940)\u001b[0m \u001b[31m_information\u001b[0m\u001b[97m(-100, 36312)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m get\u001b[0m\u001b[97m(-100, 636)\u001b[0m \u001b[31m_customer\u001b[0m\u001b[97m(-100, 29940)\u001b[0m \u001b[31m_information\u001b[0m\u001b[97m(-100, 36312)\u001b[0m \u001b[31m(*\u001b[0m\u001b[97m(-100, 4163)\u001b[0m \u001b[31margs\u001b[0m\u001b[97m(-100, 2164)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m **\u001b[0m\u001b[97m(-100, 3146)\u001b[0m \u001b[31mkwargs\u001b[0m\u001b[97m(-100, 9872)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m dict\u001b[0m\u001b[97m(-100, 6587)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m information\u001b[0m\u001b[97m(-100, 2038)\u001b[0m \u001b[31m about\u001b[0m\u001b[97m(-100, 922)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Does\u001b[0m\u001b[97m(-100, 12838)\u001b[0m \u001b[31m not\u001b[0m\u001b[97m(-100, 539)\u001b[0m \u001b[31m require\u001b[0m\u001b[97m(-100, 1397)\u001b[0m \u001b[31m any\u001b[0m\u001b[97m(-100, 904)\u001b[0m \u001b[31m arguments\u001b[0m\u001b[97m(-100, 6105)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m dict\u001b[0m\u001b[97m(-100, 6587)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m A\u001b[0m\u001b[97m(-100, 362)\u001b[0m \u001b[31m dictionary\u001b[0m\u001b[97m(-100, 11240)\u001b[0m \u001b[31m containing\u001b[0m\u001b[97m(-100, 8649)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m's\u001b[0m\u001b[97m(-100, 596)\u001b[0m \u001b[31m information\u001b[0m\u001b[97m(-100, 2038)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m        \n",
            "\u001b[0m\u001b[97m(-100, 1827)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31margs\u001b[0m\u001b[97m(-100, 2164)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mArgs\u001b[0m\u001b[97m(-100, 4209)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mkwargs\u001b[0m\u001b[97m(-100, 9872)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mK\u001b[0m\u001b[97m(-100, 42)\u001b[0m \u001b[31mwargs\u001b[0m\u001b[97m(-100, 6813)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31margs\u001b[0m\u001b[97m(-100, 2164)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mkwargs\u001b[0m\u001b[97m(-100, 9872)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m(new\u001b[0m\u001b[97m(-100, 1792)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m's\u001b[0m\u001b[97m(-100, 596)\u001b[0m \u001b[31m pin\u001b[0m\u001b[97m(-100, 9160)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m pin\u001b[0m\u001b[97m(-100, 9160)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m A\u001b[0m\u001b[97m(-100, 362)\u001b[0m \u001b[31m message\u001b[0m\u001b[97m(-100, 1984)\u001b[0m \u001b[31m indicating\u001b[0m\u001b[97m(-100, 19392)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m success\u001b[0m\u001b[97m(-100, 2450)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m failure\u001b[0m\u001b[97m(-100, 8060)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m        \n",
            "\u001b[0m\u001b[97m(-100, 1827)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mNew\u001b[0m\u001b[97m(-100, 3648)\u001b[0m \u001b[31m Pin\u001b[0m\u001b[97m(-100, 17929)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_address\u001b[0m\u001b[97m(-100, 6886)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_address\u001b[0m\u001b[97m(-100, 6886)\u001b[0m \u001b[31m(st\u001b[0m\u001b[97m(-100, 6019)\u001b[0m \u001b[31mreet\u001b[0m\u001b[97m(-100, 3829)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m city\u001b[0m\u001b[97m(-100, 3363)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m state\u001b[0m\u001b[97m(-100, 1614)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m zip\u001b[0m\u001b[97m(-100, 10521)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m country\u001b[0m\u001b[97m(-100, 3224)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m's\u001b[0m\u001b[97m(-100, 596)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m street\u001b[0m\u001b[97m(-100, 8761)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m street\u001b[0m\u001b[97m(-100, 8761)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m city\u001b[0m\u001b[97m(-100, 3363)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m city\u001b[0m\u001b[97m(-100, 3363)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m state\u001b[0m\u001b[97m(-100, 1614)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m state\u001b[0m\u001b[97m(-100, 1614)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m zip\u001b[0m\u001b[97m(-100, 10521)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m zip\u001b[0m\u001b[97m(-100, 10521)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m country\u001b[0m\u001b[97m(-100, 3224)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m country\u001b[0m\u001b[97m(-100, 3224)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m A\u001b[0m\u001b[97m(-100, 362)\u001b[0m \u001b[31m message\u001b[0m\u001b[97m(-100, 1984)\u001b[0m \u001b[31m indicating\u001b[0m\u001b[97m(-100, 19392)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m success\u001b[0m\u001b[97m(-100, 2450)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m failure\u001b[0m\u001b[97m(-100, 8060)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m        \n",
            "\u001b[0m\u001b[97m(-100, 1827)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mstreet\u001b[0m\u001b[97m(-100, 28451)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mStreet\u001b[0m\u001b[97m(-100, 35647)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mcity\u001b[0m\u001b[97m(-100, 9103)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mCity\u001b[0m\u001b[97m(-100, 13020)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstate\u001b[0m\u001b[97m(-100, 2513)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mState\u001b[0m\u001b[97m(-100, 1423)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mzip\u001b[0m\u001b[97m(-100, 10169)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mZip\u001b[0m\u001b[97m(-100, 32147)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mcountry\u001b[0m\u001b[97m(-100, 11389)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mCountry\u001b[0m\u001b[97m(-100, 16813)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31mstreet\u001b[0m\u001b[97m(-100, 28451)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mcity\u001b[0m\u001b[97m(-100, 9103)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstate\u001b[0m\u001b[97m(-100, 2513)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mzip\u001b[0m\u001b[97m(-100, 10169)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mcountry\u001b[0m\u001b[97m(-100, 11389)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_phone\u001b[0m\u001b[97m(-100, 22942)\u001b[0m \u001b[31m_number\u001b[0m\u001b[97m(-100, 5617)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_phone\u001b[0m\u001b[97m(-100, 22942)\u001b[0m \u001b[31m_number\u001b[0m\u001b[97m(-100, 5617)\u001b[0m \u001b[31m(phone\u001b[0m\u001b[97m(-100, 50255)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m's\u001b[0m\u001b[97m(-100, 596)\u001b[0m \u001b[31m phone\u001b[0m\u001b[97m(-100, 4641)\u001b[0m \u001b[31m number\u001b[0m\u001b[97m(-100, 1396)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mint\u001b[0m\u001b[97m(-100, 396)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m ID\u001b[0m\u001b[97m(-100, 3110)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m phone\u001b[0m\u001b[97m(-100, 4641)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m phone\u001b[0m\u001b[97m(-100, 4641)\u001b[0m \u001b[31m number\u001b[0m\u001b[97m(-100, 1396)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m A\u001b[0m\u001b[97m(-100, 362)\u001b[0m \u001b[31m message\u001b[0m\u001b[97m(-100, 1984)\u001b[0m \u001b[31m indicating\u001b[0m\u001b[97m(-100, 19392)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m success\u001b[0m\u001b[97m(-100, 2450)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m failure\u001b[0m\u001b[97m(-100, 8060)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m        \n",
            "\u001b[0m\u001b[97m(-100, 1827)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mphone\u001b[0m\u001b[97m(-100, 4949)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mPhone\u001b[0m\u001b[97m(-100, 7084)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31mphone\u001b[0m\u001b[97m(-100, 4949)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m list\u001b[0m\u001b[97m(-100, 1160)\u001b[0m \u001b[31m_orders\u001b[0m\u001b[97m(-100, 38229)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m list\u001b[0m\u001b[97m(-100, 1160)\u001b[0m \u001b[31m_orders\u001b[0m\u001b[97m(-100, 38229)\u001b[0m \u001b[31m()\u001b[0m\u001b[97m(-100, 368)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m List\u001b[0m\u001b[97m(-100, 1796)\u001b[0m \u001b[31m[\u001b[0m\u001b[97m(-100, 58)\u001b[0m \u001b[31mdict\u001b[0m\u001b[97m(-100, 8644)\u001b[0m \u001b[31m]\n",
            "\u001b[0m\u001b[97m(-100, 933)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m list\u001b[0m\u001b[97m(-100, 1160)\u001b[0m \u001b[31m all\u001b[0m\u001b[97m(-100, 682)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m data\u001b[0m\u001b[97m(-100, 828)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mint\u001b[0m\u001b[97m(-100, 396)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m customer\u001b[0m\u001b[97m(-100, 6130)\u001b[0m \u001b[31m ID\u001b[0m\u001b[97m(-100, 3110)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m List\u001b[0m\u001b[97m(-100, 1796)\u001b[0m \u001b[31m[\u001b[0m\u001b[97m(-100, 58)\u001b[0m \u001b[31mdict\u001b[0m\u001b[97m(-100, 8644)\u001b[0m \u001b[31m]:\u001b[0m\u001b[97m(-100, 5787)\u001b[0m \u001b[31m A\u001b[0m\u001b[97m(-100, 362)\u001b[0m \u001b[31m list\u001b[0m\u001b[97m(-100, 1160)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m dictionaries\u001b[0m\u001b[97m(-100, 58614)\u001b[0m \u001b[31m containing\u001b[0m\u001b[97m(-100, 8649)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m data\u001b[0m\u001b[97m(-100, 828)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m        \n",
            "\u001b[0m\u001b[97m(-100, 1827)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {},\u001b[0m\u001b[97m(-100, 16857)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m cancel\u001b[0m\u001b[97m(-100, 9299)\u001b[0m \u001b[31m_order\u001b[0m\u001b[97m(-100, 8028)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m cancel\u001b[0m\u001b[97m(-100, 9299)\u001b[0m \u001b[31m_order\u001b[0m\u001b[97m(-100, 8028)\u001b[0m \u001b[31m(order\u001b[0m\u001b[97m(-100, 19948)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m int\u001b[0m\u001b[97m(-100, 528)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m cancel\u001b[0m\u001b[97m(-100, 9299)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mint\u001b[0m\u001b[97m(-100, 396)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m ID\u001b[0m\u001b[97m(-100, 3110)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m\n",
            "        \n",
            "\u001b[0m\u001b[97m(-100, 9122)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31morder\u001b[0m\u001b[97m(-100, 1382)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mOrder\u001b[0m\u001b[97m(-100, 4531)\u001b[0m \u001b[31m Id\u001b[0m\u001b[97m(-100, 5336)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31minteger\u001b[0m\u001b[97m(-100, 11924)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31morder\u001b[0m\u001b[97m(-100, 1382)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_order\u001b[0m\u001b[97m(-100, 8028)\u001b[0m \u001b[31m_address\u001b[0m\u001b[97m(-100, 6886)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_order\u001b[0m\u001b[97m(-100, 8028)\u001b[0m \u001b[31m_address\u001b[0m\u001b[97m(-100, 6886)\u001b[0m \u001b[31m(order\u001b[0m\u001b[97m(-100, 19948)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m int\u001b[0m\u001b[97m(-100, 528)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_street\u001b[0m\u001b[97m(-100, 79662)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_city\u001b[0m\u001b[97m(-100, 26019)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_zip\u001b[0m\u001b[97m(-100, 43231)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_state\u001b[0m\u001b[97m(-100, 4486)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_country\u001b[0m\u001b[97m(-100, 29206)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m ->\u001b[0m\u001b[97m(-100, 1492)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mUse\u001b[0m\u001b[97m(-100, 10464)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m want\u001b[0m\u001b[97m(-100, 1390)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m shipping\u001b[0m\u001b[97m(-100, 11862)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m an\u001b[0m\u001b[97m(-100, 459)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mint\u001b[0m\u001b[97m(-100, 396)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m order\u001b[0m\u001b[97m(-100, 2015)\u001b[0m \u001b[31m ID\u001b[0m\u001b[97m(-100, 3110)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_street\u001b[0m\u001b[97m(-100, 79662)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m street\u001b[0m\u001b[97m(-100, 8761)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_city\u001b[0m\u001b[97m(-100, 26019)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m city\u001b[0m\u001b[97m(-100, 3363)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_zip\u001b[0m\u001b[97m(-100, 43231)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m zip\u001b[0m\u001b[97m(-100, 10521)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_state\u001b[0m\u001b[97m(-100, 4486)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m state\u001b[0m\u001b[97m(-100, 1614)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m_country\u001b[0m\u001b[97m(-100, 29206)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mstr\u001b[0m\u001b[97m(-100, 496)\u001b[0m \u001b[31m):\u001b[0m\u001b[97m(-100, 1680)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m country\u001b[0m\u001b[97m(-100, 3224)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31m       \u001b[0m\u001b[97m(-100, 286)\u001b[0m \u001b[31m Returns\u001b[0m\u001b[97m(-100, 5295)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m           \u001b[0m\u001b[97m(-100, 310)\u001b[0m \u001b[31m str\u001b[0m\u001b[97m(-100, 610)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m A\u001b[0m\u001b[97m(-100, 362)\u001b[0m \u001b[31m message\u001b[0m\u001b[97m(-100, 1984)\u001b[0m \u001b[31m indicating\u001b[0m\u001b[97m(-100, 19392)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m success\u001b[0m\u001b[97m(-100, 2450)\u001b[0m \u001b[31m or\u001b[0m\u001b[97m(-100, 477)\u001b[0m \u001b[31m failure\u001b[0m\u001b[97m(-100, 8060)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31m        \n",
            "\u001b[0m\u001b[97m(-100, 1827)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31morder\u001b[0m\u001b[97m(-100, 1382)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mOrder\u001b[0m\u001b[97m(-100, 4531)\u001b[0m \u001b[31m Id\u001b[0m\u001b[97m(-100, 5336)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31minteger\u001b[0m\u001b[97m(-100, 11924)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_street\u001b[0m\u001b[97m(-100, 79662)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mNew\u001b[0m\u001b[97m(-100, 3648)\u001b[0m \u001b[31m Street\u001b[0m\u001b[97m(-100, 6825)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_city\u001b[0m\u001b[97m(-100, 26019)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mNew\u001b[0m\u001b[97m(-100, 3648)\u001b[0m \u001b[31m City\u001b[0m\u001b[97m(-100, 4409)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_zip\u001b[0m\u001b[97m(-100, 43231)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mNew\u001b[0m\u001b[97m(-100, 3648)\u001b[0m \u001b[31m Zip\u001b[0m\u001b[97m(-100, 30332)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_state\u001b[0m\u001b[97m(-100, 4486)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mNew\u001b[0m\u001b[97m(-100, 3648)\u001b[0m \u001b[31m State\u001b[0m\u001b[97m(-100, 3314)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"},\u001b[0m\u001b[97m(-100, 14682)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_country\u001b[0m\u001b[97m(-100, 29206)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mNew\u001b[0m\u001b[97m(-100, 3648)\u001b[0m \u001b[31m Country\u001b[0m\u001b[97m(-100, 14438)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31morder\u001b[0m\u001b[97m(-100, 1382)\u001b[0m \u001b[31m_id\u001b[0m\u001b[97m(-100, 851)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_street\u001b[0m\u001b[97m(-100, 79662)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_city\u001b[0m\u001b[97m(-100, 26019)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_zip\u001b[0m\u001b[97m(-100, 43231)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_state\u001b[0m\u001b[97m(-100, 4486)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnew\u001b[0m\u001b[97m(-100, 943)\u001b[0m \u001b[31m_country\u001b[0m\u001b[97m(-100, 29206)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"}\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 64259)\u001b[0m \u001b[31m>\u001b[0m\u001b[97m(-100, 29)\u001b[0m \u001b[31m Tool\u001b[0m\u001b[97m(-100, 13782)\u001b[0m \u001b[31m Name\u001b[0m\u001b[97m(-100, 4076)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m search\u001b[0m\u001b[97m(-100, 2778)\u001b[0m \u001b[31m_items\u001b[0m\u001b[97m(-100, 12408)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Description\u001b[0m\u001b[97m(-100, 7817)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m Useful\u001b[0m\u001b[97m(-100, 51612)\u001b[0m \u001b[31m when\u001b[0m\u001b[97m(-100, 994)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m need\u001b[0m\u001b[97m(-100, 1205)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m question\u001b[0m\u001b[97m(-100, 3488)\u001b[0m \u001b[31m by\u001b[0m\u001b[97m(-100, 555)\u001b[0m \u001b[31m searching\u001b[0m\u001b[97m(-100, 15389)\u001b[0m \u001b[31m items\u001b[0m\u001b[97m(-100, 3673)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mTool\u001b[0m\u001b[97m(-100, 7896)\u001b[0m \u001b[31m Args\u001b[0m\u001b[97m(-100, 18161)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mproperties\u001b[0m\u001b[97m(-100, 13495)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31minput\u001b[0m\u001b[97m(-100, 1379)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31mtitle\u001b[0m\u001b[97m(-100, 2150)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mInput\u001b[0m\u001b[97m(-100, 2566)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mstring\u001b[0m\u001b[97m(-100, 928)\u001b[0m \u001b[31m\"}\u001b[0m\u001b[97m(-100, 9388)\u001b[0m \u001b[31m},\u001b[0m\u001b[97m(-100, 2186)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mrequired\u001b[0m\u001b[97m(-100, 6413)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m [\"\u001b[0m\u001b[97m(-100, 4482)\u001b[0m \u001b[31minput\u001b[0m\u001b[97m(-100, 1379)\u001b[0m \u001b[31m\"],\u001b[0m\u001b[97m(-100, 8073)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mtype\u001b[0m\u001b[97m(-100, 1337)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mobject\u001b[0m\u001b[97m(-100, 1735)\u001b[0m \u001b[31m\"\u001b[0m\u001b[97m(-100, 1)\u001b[0m \u001b[31m}\n",
            "\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 13549)\u001b[0m \u001b[31m##\u001b[0m\u001b[97m(-100, 567)\u001b[0m \u001b[31m Output\u001b[0m\u001b[97m(-100, 9442)\u001b[0m \u001b[31m Format\u001b[0m\u001b[97m(-100, 15392)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mPlease\u001b[0m\u001b[97m(-100, 5618)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m English\u001b[0m\u001b[97m(-100, 6498)\u001b[0m \u001b[31m using\u001b[0m\u001b[97m(-100, 1701)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m following\u001b[0m\u001b[97m(-100, 2768)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m:\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1473)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\u001b[0m\u001b[97m(-100, 4077)\u001b[0m \u001b[31mThought\u001b[0m\u001b[97m(-100, 85269)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m I\u001b[0m\u001b[97m(-100, 358)\u001b[0m \u001b[31m need\u001b[0m\u001b[97m(-100, 1205)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m tool\u001b[0m\u001b[97m(-100, 5507)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m help\u001b[0m\u001b[97m(-100, 1520)\u001b[0m \u001b[31m me\u001b[0m\u001b[97m(-100, 757)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m question\u001b[0m\u001b[97m(-100, 3488)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mAction\u001b[0m\u001b[97m(-100, 2573)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m tool\u001b[0m\u001b[97m(-100, 5507)\u001b[0m \u001b[31m name\u001b[0m\u001b[97m(-100, 836)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mone\u001b[0m\u001b[97m(-100, 606)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m get\u001b[0m\u001b[97m(-100, 636)\u001b[0m \u001b[31m_customer\u001b[0m\u001b[97m(-100, 29940)\u001b[0m \u001b[31m_information\u001b[0m\u001b[97m(-100, 36312)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_pin\u001b[0m\u001b[97m(-100, 27392)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_address\u001b[0m\u001b[97m(-100, 6886)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_phone\u001b[0m\u001b[97m(-100, 22942)\u001b[0m \u001b[31m_number\u001b[0m\u001b[97m(-100, 5617)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m list\u001b[0m\u001b[97m(-100, 1160)\u001b[0m \u001b[31m_orders\u001b[0m\u001b[97m(-100, 38229)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m cancel\u001b[0m\u001b[97m(-100, 9299)\u001b[0m \u001b[31m_order\u001b[0m\u001b[97m(-100, 8028)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m_order\u001b[0m\u001b[97m(-100, 8028)\u001b[0m \u001b[31m_address\u001b[0m\u001b[97m(-100, 6886)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m search\u001b[0m\u001b[97m(-100, 2778)\u001b[0m \u001b[31m_items\u001b[0m\u001b[97m(-100, 12408)\u001b[0m \u001b[31m)\u001b[0m\u001b[97m(-100, 8)\u001b[0m \u001b[31m if\u001b[0m\u001b[97m(-100, 422)\u001b[0m \u001b[31m using\u001b[0m\u001b[97m(-100, 1701)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m tool\u001b[0m\u001b[97m(-100, 5507)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mAction\u001b[0m\u001b[97m(-100, 2573)\u001b[0m \u001b[31m Input\u001b[0m\u001b[97m(-100, 5688)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m input\u001b[0m\u001b[97m(-100, 1988)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m tool\u001b[0m\u001b[97m(-100, 5507)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m JSON\u001b[0m\u001b[97m(-100, 4823)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m representing\u001b[0m\u001b[97m(-100, 14393)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m kwargs\u001b[0m\u001b[97m(-100, 16901)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31me\u001b[0m\u001b[97m(-100, 68)\u001b[0m \u001b[31m.g\u001b[0m\u001b[97m(-100, 1326)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m {\"\u001b[0m\u001b[97m(-100, 5324)\u001b[0m \u001b[31minput\u001b[0m\u001b[97m(-100, 1379)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mhello\u001b[0m\u001b[97m(-100, 15339)\u001b[0m \u001b[31m world\u001b[0m\u001b[97m(-100, 1917)\u001b[0m \u001b[31m\",\u001b[0m\u001b[97m(-100, 498)\u001b[0m \u001b[31m \"\u001b[0m\u001b[97m(-100, 330)\u001b[0m \u001b[31mnum\u001b[0m\u001b[97m(-100, 2470)\u001b[0m \u001b[31m_be\u001b[0m\u001b[97m(-100, 21960)\u001b[0m \u001b[31mams\u001b[0m\u001b[97m(-100, 4214)\u001b[0m \u001b[31m\":\u001b[0m\u001b[97m(-100, 794)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m})\n",
            "\u001b[0m\u001b[97m(-100, 3602)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 19884)\u001b[0m \u001b[31mPlease\u001b[0m\u001b[97m(-100, 5618)\u001b[0m \u001b[31m ALWAYS\u001b[0m\u001b[97m(-100, 68514)\u001b[0m \u001b[31m start\u001b[0m\u001b[97m(-100, 1212)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m Thought\u001b[0m\u001b[97m(-100, 36287)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31mNE\u001b[0m\u001b[97m(-100, 4031)\u001b[0m \u001b[31mVER\u001b[0m\u001b[97m(-100, 3848)\u001b[0m \u001b[31m surround\u001b[0m\u001b[97m(-100, 9172)\u001b[0m \u001b[31m your\u001b[0m\u001b[97m(-100, 701)\u001b[0m \u001b[31m response\u001b[0m\u001b[97m(-100, 2077)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m markdown\u001b[0m\u001b[97m(-100, 51594)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m markers\u001b[0m\u001b[97m(-100, 24915)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m You\u001b[0m\u001b[97m(-100, 1472)\u001b[0m \u001b[31m may\u001b[0m\u001b[97m(-100, 1253)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m code\u001b[0m\u001b[97m(-100, 2082)\u001b[0m \u001b[31m markers\u001b[0m\u001b[97m(-100, 24915)\u001b[0m \u001b[31m within\u001b[0m\u001b[97m(-100, 2949)\u001b[0m \u001b[31m your\u001b[0m\u001b[97m(-100, 701)\u001b[0m \u001b[31m response\u001b[0m\u001b[97m(-100, 2077)\u001b[0m \u001b[31m if\u001b[0m\u001b[97m(-100, 422)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m need\u001b[0m\u001b[97m(-100, 1205)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31mPlease\u001b[0m\u001b[97m(-100, 5618)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m a\u001b[0m\u001b[97m(-100, 264)\u001b[0m \u001b[31m valid\u001b[0m\u001b[97m(-100, 2764)\u001b[0m \u001b[31m JSON\u001b[0m\u001b[97m(-100, 4823)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m Action\u001b[0m\u001b[97m(-100, 5703)\u001b[0m \u001b[31m Input\u001b[0m\u001b[97m(-100, 5688)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Do\u001b[0m\u001b[97m(-100, 3234)\u001b[0m \u001b[31m NOT\u001b[0m\u001b[97m(-100, 4276)\u001b[0m \u001b[31m do\u001b[0m\u001b[97m(-100, 656)\u001b[0m \u001b[31m this\u001b[0m\u001b[97m(-100, 420)\u001b[0m \u001b[31m {'\u001b[0m\u001b[97m(-100, 5473)\u001b[0m \u001b[31minput\u001b[0m\u001b[97m(-100, 1379)\u001b[0m \u001b[31m':\u001b[0m\u001b[97m(-100, 1232)\u001b[0m \u001b[31m '\u001b[0m\u001b[97m(-100, 364)\u001b[0m \u001b[31mhello\u001b[0m\u001b[97m(-100, 15339)\u001b[0m \u001b[31m world\u001b[0m\u001b[97m(-100, 1917)\u001b[0m \u001b[31m',\u001b[0m\u001b[97m(-100, 518)\u001b[0m \u001b[31m '\u001b[0m\u001b[97m(-100, 364)\u001b[0m \u001b[31mnum\u001b[0m\u001b[97m(-100, 2470)\u001b[0m \u001b[31m_be\u001b[0m\u001b[97m(-100, 21960)\u001b[0m \u001b[31mams\u001b[0m\u001b[97m(-100, 4214)\u001b[0m \u001b[31m':\u001b[0m\u001b[97m(-100, 1232)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m5\u001b[0m\u001b[97m(-100, 20)\u001b[0m \u001b[31m}\u001b[0m\u001b[97m(-100, 92)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31mIf\u001b[0m\u001b[97m(-100, 2746)\u001b[0m \u001b[31m this\u001b[0m\u001b[97m(-100, 420)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m is\u001b[0m\u001b[97m(-100, 374)\u001b[0m \u001b[31m used\u001b[0m\u001b[97m(-100, 1511)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m user\u001b[0m\u001b[97m(-100, 1217)\u001b[0m \u001b[31m will\u001b[0m\u001b[97m(-100, 690)\u001b[0m \u001b[31m respond\u001b[0m\u001b[97m(-100, 6013)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m following\u001b[0m\u001b[97m(-100, 2768)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m:\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1473)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\u001b[0m\u001b[97m(-100, 4077)\u001b[0m \u001b[31mObserv\u001b[0m\u001b[97m(-100, 38863)\u001b[0m \u001b[31mation\u001b[0m\u001b[97m(-100, 367)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m tool\u001b[0m\u001b[97m(-100, 5507)\u001b[0m \u001b[31m response\u001b[0m\u001b[97m(-100, 2077)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 19884)\u001b[0m \u001b[31mYou\u001b[0m\u001b[97m(-100, 2675)\u001b[0m \u001b[31m should\u001b[0m\u001b[97m(-100, 1288)\u001b[0m \u001b[31m keep\u001b[0m\u001b[97m(-100, 2567)\u001b[0m \u001b[31m repeating\u001b[0m\u001b[97m(-100, 40916)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m above\u001b[0m\u001b[97m(-100, 3485)\u001b[0m \u001b[31m format\u001b[0m\u001b[97m(-100, 3645)\u001b[0m \u001b[31m till\u001b[0m\u001b[97m(-100, 12222)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m have\u001b[0m\u001b[97m(-100, 617)\u001b[0m \u001b[31m enough\u001b[0m\u001b[97m(-100, 3403)\u001b[0m \u001b[31m information\u001b[0m\u001b[97m(-100, 2038)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m question\u001b[0m\u001b[97m(-100, 3488)\u001b[0m \u001b[31m without\u001b[0m\u001b[97m(-100, 2085)\u001b[0m \u001b[31m using\u001b[0m\u001b[97m(-100, 1701)\u001b[0m \u001b[31m any\u001b[0m\u001b[97m(-100, 904)\u001b[0m \u001b[31m more\u001b[0m\u001b[97m(-100, 810)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m At\u001b[0m\u001b[97m(-100, 2468)\u001b[0m \u001b[31m that\u001b[0m\u001b[97m(-100, 430)\u001b[0m \u001b[31m point\u001b[0m\u001b[97m(-100, 1486)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m MUST\u001b[0m\u001b[97m(-100, 28832)\u001b[0m \u001b[31m respond\u001b[0m\u001b[97m(-100, 6013)\u001b[0m \u001b[31m in\u001b[0m\u001b[97m(-100, 304)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m one\u001b[0m\u001b[97m(-100, 832)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m following\u001b[0m\u001b[97m(-100, 2768)\u001b[0m \u001b[31m two\u001b[0m\u001b[97m(-100, 1403)\u001b[0m \u001b[31m formats\u001b[0m\u001b[97m(-100, 20447)\u001b[0m \u001b[31m:\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1473)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\u001b[0m\u001b[97m(-100, 4077)\u001b[0m \u001b[31mThought\u001b[0m\u001b[97m(-100, 85269)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m I\u001b[0m\u001b[97m(-100, 358)\u001b[0m \u001b[31m can\u001b[0m\u001b[97m(-100, 649)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m without\u001b[0m\u001b[97m(-100, 2085)\u001b[0m \u001b[31m using\u001b[0m\u001b[97m(-100, 1701)\u001b[0m \u001b[31m any\u001b[0m\u001b[97m(-100, 904)\u001b[0m \u001b[31m more\u001b[0m\u001b[97m(-100, 810)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m I\u001b[0m\u001b[97m(-100, 358)\u001b[0m \u001b[31m'll\u001b[0m\u001b[97m(-100, 3358)\u001b[0m \u001b[31m use\u001b[0m\u001b[97m(-100, 1005)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m user\u001b[0m\u001b[97m(-100, 1217)\u001b[0m \u001b[31m's\u001b[0m\u001b[97m(-100, 596)\u001b[0m \u001b[31m language\u001b[0m\u001b[97m(-100, 4221)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m\n",
            "\u001b[0m\u001b[97m(-100, 198)\u001b[0m \u001b[31mAnswer\u001b[0m\u001b[97m(-100, 16533)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 19884)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\u001b[0m\u001b[97m(-100, 4077)\u001b[0m \u001b[31mThought\u001b[0m\u001b[97m(-100, 85269)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m I\u001b[0m\u001b[97m(-100, 358)\u001b[0m \u001b[31m cannot\u001b[0m\u001b[97m(-100, 4250)\u001b[0m \u001b[31m answer\u001b[0m\u001b[97m(-100, 4320)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m question\u001b[0m\u001b[97m(-100, 3488)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m provided\u001b[0m\u001b[97m(-100, 3984)\u001b[0m \u001b[31m tools\u001b[0m\u001b[97m(-100, 7526)\u001b[0m \u001b[31m.\n",
            "\u001b[0m\u001b[97m(-100, 627)\u001b[0m \u001b[31mAnswer\u001b[0m\u001b[97m(-100, 16533)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m``\u001b[0m\u001b[97m(-100, 14196)\u001b[0m \u001b[31m`\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 19884)\u001b[0m \u001b[31m##\u001b[0m\u001b[97m(-100, 567)\u001b[0m \u001b[31m Current\u001b[0m\u001b[97m(-100, 9303)\u001b[0m \u001b[31m Conversation\u001b[0m\u001b[97m(-100, 51930)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mBelow\u001b[0m\u001b[97m(-100, 39314)\u001b[0m \u001b[31m is\u001b[0m\u001b[97m(-100, 374)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m current\u001b[0m\u001b[97m(-100, 1510)\u001b[0m \u001b[31m conversation\u001b[0m\u001b[97m(-100, 10652)\u001b[0m \u001b[31m consisting\u001b[0m\u001b[97m(-100, 31706)\u001b[0m \u001b[31m of\u001b[0m\u001b[97m(-100, 315)\u001b[0m \u001b[31m interle\u001b[0m\u001b[97m(-100, 96068)\u001b[0m \u001b[31maving\u001b[0m\u001b[97m(-100, 2370)\u001b[0m \u001b[31m human\u001b[0m\u001b[97m(-100, 3823)\u001b[0m \u001b[31m and\u001b[0m\u001b[97m(-100, 323)\u001b[0m \u001b[31m assistant\u001b[0m\u001b[97m(-100, 18328)\u001b[0m \u001b[31m messages\u001b[0m\u001b[97m(-100, 6743)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Conversation\u001b[0m\u001b[97m(-100, 51930)\u001b[0m \u001b[31m:\n",
            "\u001b[0m\u001b[97m(-100, 512)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mHi\u001b[0m\u001b[97m(-100, 13347)\u001b[0m \u001b[31m there\u001b[0m\u001b[97m(-100, 1070)\u001b[0m \u001b[31m!\u001b[0m\u001b[97m(-100, 0)\u001b[0m \u001b[31m I\u001b[0m\u001b[97m(-100, 358)\u001b[0m \u001b[31m would\u001b[0m\u001b[97m(-100, 1053)\u001b[0m \u001b[31m like\u001b[0m\u001b[97m(-100, 1093)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m check\u001b[0m\u001b[97m(-100, 1817)\u001b[0m \u001b[31m on\u001b[0m\u001b[97m(-100, 389)\u001b[0m \u001b[31m my\u001b[0m\u001b[97m(-100, 856)\u001b[0m \u001b[31m orders\u001b[0m\u001b[97m(-100, 10373)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Can\u001b[0m\u001b[97m(-100, 3053)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m help\u001b[0m\u001b[97m(-100, 1520)\u001b[0m \u001b[31m me\u001b[0m\u001b[97m(-100, 757)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m that\u001b[0m\u001b[97m(-100, 430)\u001b[0m \u001b[31m?\u001b[0m\u001b[97m(-100, 30)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32mHere\u001b[0m\u001b[97m(8586, 8586)\u001b[0m \u001b[32m are\u001b[0m\u001b[97m(527, 527)\u001b[0m \u001b[32m your\u001b[0m\u001b[97m(701, 701)\u001b[0m \u001b[32m current\u001b[0m\u001b[97m(1510, 1510)\u001b[0m \u001b[32m orders\u001b[0m\u001b[97m(10373, 10373)\u001b[0m \u001b[32m:\n",
            "\n",
            "\u001b[0m\u001b[97m(1473, 1473)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m **\u001b[0m\u001b[97m(3146, 3146)\u001b[0m \u001b[32mSmart\u001b[0m\u001b[97m(34917, 34917)\u001b[0m \u001b[32m Ther\u001b[0m\u001b[97m(23258, 23258)\u001b[0m \u001b[32mmostat\u001b[0m\u001b[97m(55825, 55825)\u001b[0m \u001b[32m**\n",
            "\u001b[0m\u001b[97m(1035, 1035)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Order\u001b[0m\u001b[97m(7365, 7365)\u001b[0m \u001b[32m ID\u001b[0m\u001b[97m(3110, 3110)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m57\u001b[0m\u001b[97m(3226, 3226)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Ordered\u001b[0m\u001b[97m(40681, 40681)\u001b[0m \u001b[32m Date\u001b[0m\u001b[97m(2696, 2696)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m October\u001b[0m\u001b[97m(6664, 6664)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m1\u001b[0m\u001b[97m(16, 16)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m202\u001b[0m\u001b[97m(2366, 2366)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Status\u001b[0m\u001b[97m(8266, 8266)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m Del\u001b[0m\u001b[97m(7462, 7462)\u001b[0m \u001b[32mivered\u001b[0m\u001b[97m(44156, 44156)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Estimated\u001b[0m\u001b[97m(83086, 83086)\u001b[0m \u001b[32m Delivery\u001b[0m\u001b[97m(27303, 27303)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m October\u001b[0m\u001b[97m(6664, 6664)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m5\u001b[0m\u001b[97m(20, 20)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m202\u001b[0m\u001b[97m(2366, 2366)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Shipping\u001b[0m\u001b[97m(24907, 24907)\u001b[0m \u001b[32m Carrier\u001b[0m\u001b[97m(51961, 51961)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m Carrier\u001b[0m\u001b[97m(51961, 51961)\u001b[0m \u001b[32m A\u001b[0m\u001b[97m(362, 362)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Tracking\u001b[0m\u001b[97m(47170, 47170)\u001b[0m \u001b[32m Number\u001b[0m\u001b[97m(5742, 5742)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m TRACK\u001b[0m\u001b[97m(74602, 74602)\u001b[0m \u001b[32m123\u001b[0m\u001b[97m(4513, 4513)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Shipping\u001b[0m\u001b[97m(24907, 24907)\u001b[0m \u001b[32m Address\u001b[0m\u001b[97m(9356, 9356)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m123\u001b[0m\u001b[97m(4513, 4513)\u001b[0m \u001b[32m Main\u001b[0m\u001b[97m(4802, 4802)\u001b[0m \u001b[32m St\u001b[0m\u001b[97m(800, 800)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m City\u001b[0m\u001b[97m(4409, 4409)\u001b[0m \u001b[32m A\u001b[0m\u001b[97m(362, 362)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32m2\u001b[0m\u001b[97m(17, 17)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m **\u001b[0m\u001b[97m(3146, 3146)\u001b[0m \u001b[32mSmart\u001b[0m\u001b[97m(34917, 34917)\u001b[0m \u001b[32m Refriger\u001b[0m\u001b[97m(75258, 75258)\u001b[0m \u001b[32mator\u001b[0m\u001b[97m(859, 859)\u001b[0m \u001b[32m**\n",
            "\u001b[0m\u001b[97m(1035, 1035)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Order\u001b[0m\u001b[97m(7365, 7365)\u001b[0m \u001b[32m ID\u001b[0m\u001b[97m(3110, 3110)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m58\u001b[0m\u001b[97m(2970, 2970)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Ordered\u001b[0m\u001b[97m(40681, 40681)\u001b[0m \u001b[32m Date\u001b[0m\u001b[97m(2696, 2696)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m October\u001b[0m\u001b[97m(6664, 6664)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m10\u001b[0m\u001b[97m(605, 605)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m202\u001b[0m\u001b[97m(2366, 2366)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Status\u001b[0m\u001b[97m(8266, 8266)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m Sh\u001b[0m\u001b[97m(1443, 1443)\u001b[0m \u001b[32mipped\u001b[0m\u001b[97m(6586, 6586)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Estimated\u001b[0m\u001b[97m(83086, 83086)\u001b[0m \u001b[32m Delivery\u001b[0m\u001b[97m(27303, 27303)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m October\u001b[0m\u001b[97m(6664, 6664)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m15\u001b[0m\u001b[97m(868, 868)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m202\u001b[0m\u001b[97m(2366, 2366)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Shipping\u001b[0m\u001b[97m(24907, 24907)\u001b[0m \u001b[32m Carrier\u001b[0m\u001b[97m(51961, 51961)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m Carrier\u001b[0m\u001b[97m(51961, 51961)\u001b[0m \u001b[32m B\u001b[0m\u001b[97m(426, 426)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Tracking\u001b[0m\u001b[97m(47170, 47170)\u001b[0m \u001b[32m Number\u001b[0m\u001b[97m(5742, 5742)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m TRACK\u001b[0m\u001b[97m(74602, 74602)\u001b[0m \u001b[32m456\u001b[0m\u001b[97m(10961, 10961)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Shipping\u001b[0m\u001b[97m(24907, 24907)\u001b[0m \u001b[32m Address\u001b[0m\u001b[97m(9356, 9356)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m777\u001b[0m\u001b[97m(15831, 15831)\u001b[0m \u001b[32m Pop\u001b[0m\u001b[97m(10466, 10466)\u001b[0m \u001b[32mlar\u001b[0m\u001b[97m(14115, 14115)\u001b[0m \u001b[32m St\u001b[0m\u001b[97m(800, 800)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m Orlando\u001b[0m\u001b[97m(28944, 28944)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m FL\u001b[0m\u001b[97m(13062, 13062)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m328\u001b[0m\u001b[97m(16884, 16884)\u001b[0m \u001b[32m01\u001b[0m\u001b[97m(1721, 1721)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m US\u001b[0m\u001b[97m(2326, 2326)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32m3\u001b[0m\u001b[97m(18, 18)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m **\u001b[0m\u001b[97m(3146, 3146)\u001b[0m \u001b[32mG\u001b[0m\u001b[97m(38, 38)\u001b[0m \u001b[32maming\u001b[0m\u001b[97m(6605, 6605)\u001b[0m \u001b[32m Console\u001b[0m\u001b[97m(5390, 5390)\u001b[0m \u001b[32m X\u001b[0m\u001b[97m(1630, 1630)\u001b[0m \u001b[32m**\n",
            "\u001b[0m\u001b[97m(1035, 1035)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Order\u001b[0m\u001b[97m(7365, 7365)\u001b[0m \u001b[32m ID\u001b[0m\u001b[97m(3110, 3110)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m59\u001b[0m\u001b[97m(2946, 2946)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Ordered\u001b[0m\u001b[97m(40681, 40681)\u001b[0m \u001b[32m Date\u001b[0m\u001b[97m(2696, 2696)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m October\u001b[0m\u001b[97m(6664, 6664)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m20\u001b[0m\u001b[97m(508, 508)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m202\u001b[0m\u001b[97m(2366, 2366)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Status\u001b[0m\u001b[97m(8266, 8266)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m Pending\u001b[0m\u001b[97m(42940, 42940)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Estimated\u001b[0m\u001b[97m(83086, 83086)\u001b[0m \u001b[32m Delivery\u001b[0m\u001b[97m(27303, 27303)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m October\u001b[0m\u001b[97m(6664, 6664)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m25\u001b[0m\u001b[97m(914, 914)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m202\u001b[0m\u001b[97m(2366, 2366)\u001b[0m \u001b[32m4\u001b[0m\u001b[97m(19, 19)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Shipping\u001b[0m\u001b[97m(24907, 24907)\u001b[0m \u001b[32m Carrier\u001b[0m\u001b[97m(51961, 51961)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m Carrier\u001b[0m\u001b[97m(51961, 51961)\u001b[0m \u001b[32m C\u001b[0m\u001b[97m(356, 356)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Tracking\u001b[0m\u001b[97m(47170, 47170)\u001b[0m \u001b[32m Number\u001b[0m\u001b[97m(5742, 5742)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m848\u001b[0m\u001b[97m(24951, 24951)\u001b[0m \u001b[32m2\u001b[0m\u001b[97m(17, 17)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32m  \u001b[0m\u001b[97m(256, 256)\u001b[0m \u001b[32m -\u001b[0m\u001b[97m(482, 482)\u001b[0m \u001b[32m Shipping\u001b[0m\u001b[97m(24907, 24907)\u001b[0m \u001b[32m Address\u001b[0m\u001b[97m(9356, 9356)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m777\u001b[0m\u001b[97m(15831, 15831)\u001b[0m \u001b[32m Pop\u001b[0m\u001b[97m(10466, 10466)\u001b[0m \u001b[32mlar\u001b[0m\u001b[97m(14115, 14115)\u001b[0m \u001b[32m St\u001b[0m\u001b[97m(800, 800)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m Orlando\u001b[0m\u001b[97m(28944, 28944)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m FL\u001b[0m\u001b[97m(13062, 13062)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m328\u001b[0m\u001b[97m(16884, 16884)\u001b[0m \u001b[32m01\u001b[0m\u001b[97m(1721, 1721)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m US\u001b[0m\u001b[97m(2326, 2326)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32mIf\u001b[0m\u001b[97m(2746, 2746)\u001b[0m \u001b[32m you\u001b[0m\u001b[97m(499, 499)\u001b[0m \u001b[32m need\u001b[0m\u001b[97m(1205, 1205)\u001b[0m \u001b[32m any\u001b[0m\u001b[97m(904, 904)\u001b[0m \u001b[32m further\u001b[0m\u001b[97m(4726, 4726)\u001b[0m \u001b[32m assistance\u001b[0m\u001b[97m(13291, 13291)\u001b[0m \u001b[32m with\u001b[0m\u001b[97m(449, 449)\u001b[0m \u001b[32m these\u001b[0m\u001b[97m(1521, 1521)\u001b[0m \u001b[32m orders\u001b[0m\u001b[97m(10373, 10373)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m feel\u001b[0m\u001b[97m(2733, 2733)\u001b[0m \u001b[32m free\u001b[0m\u001b[97m(1949, 1949)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m ask\u001b[0m\u001b[97m(2610, 2610)\u001b[0m \u001b[33m!\u001b[0m\u001b[97m(0, 0)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mThanks\u001b[0m\u001b[97m(-100, 12947)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m providing\u001b[0m\u001b[97m(-100, 8405)\u001b[0m \u001b[31m my\u001b[0m\u001b[97m(-100, 856)\u001b[0m \u001b[31m orders\u001b[0m\u001b[97m(-100, 10373)\u001b[0m \u001b[31m!\u001b[0m\u001b[97m(-100, 0)\u001b[0m \u001b[31m I\u001b[0m\u001b[97m(-100, 358)\u001b[0m \u001b[31m would\u001b[0m\u001b[97m(-100, 1053)\u001b[0m \u001b[31m like\u001b[0m\u001b[97m(-100, 1093)\u001b[0m \u001b[31m to\u001b[0m\u001b[97m(-100, 311)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m shipping\u001b[0m\u001b[97m(-100, 11862)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m for\u001b[0m\u001b[97m(-100, 369)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m **\u001b[0m\u001b[97m(-100, 3146)\u001b[0m \u001b[31mSmart\u001b[0m\u001b[97m(-100, 34917)\u001b[0m \u001b[31m Refriger\u001b[0m\u001b[97m(-100, 75258)\u001b[0m \u001b[31mator\u001b[0m\u001b[97m(-100, 859)\u001b[0m \u001b[31m**\u001b[0m\u001b[97m(-100, 334)\u001b[0m \u001b[31m (\u001b[0m\u001b[97m(-100, 320)\u001b[0m \u001b[31mOrder\u001b[0m\u001b[97m(-100, 4531)\u001b[0m \u001b[31m ID\u001b[0m\u001b[97m(-100, 3110)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m58\u001b[0m\u001b[97m(-100, 2970)\u001b[0m \u001b[31m).\u001b[0m\u001b[97m(-100, 570)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m is\u001b[0m\u001b[97m(-100, 374)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m456\u001b[0m\u001b[97m(-100, 10961)\u001b[0m \u001b[31m Elm\u001b[0m\u001b[97m(-100, 65329)\u001b[0m \u001b[31m St\u001b[0m\u001b[97m(-100, 800)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m City\u001b[0m\u001b[97m(-100, 4409)\u001b[0m \u001b[31m B\u001b[0m\u001b[97m(-100, 426)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m Can\u001b[0m\u001b[97m(-100, 3053)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m help\u001b[0m\u001b[97m(-100, 1520)\u001b[0m \u001b[31m me\u001b[0m\u001b[97m(-100, 757)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m that\u001b[0m\u001b[97m(-100, 430)\u001b[0m \u001b[31m?\u001b[0m\u001b[97m(-100, 30)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32mI\u001b[0m\u001b[97m(40, 40)\u001b[0m \u001b[32m need\u001b[0m\u001b[97m(1205, 1205)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m gather\u001b[0m\u001b[97m(9762, 9762)\u001b[0m \u001b[32m more\u001b[0m\u001b[97m(810, 810)\u001b[0m \u001b[32m information\u001b[0m\u001b[97m(2038, 2038)\u001b[0m \u001b[32m about\u001b[0m\u001b[97m(922, 922)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m new\u001b[0m\u001b[97m(502, 502)\u001b[0m \u001b[32m address\u001b[0m\u001b[97m(2686, 2686)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m including\u001b[0m\u001b[97m(2737, 2737)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m state\u001b[0m\u001b[97m(1614, 1614)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m zip\u001b[0m\u001b[97m(10521, 10521)\u001b[0m \u001b[32m code\u001b[0m\u001b[97m(2082, 2082)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m and\u001b[0m\u001b[97m(323, 323)\u001b[0m \u001b[32m country\u001b[0m\u001b[97m(3224, 3224)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m Could\u001b[0m\u001b[97m(16910, 16910)\u001b[0m \u001b[32m you\u001b[0m\u001b[97m(499, 499)\u001b[0m \u001b[32m please\u001b[0m\u001b[97m(4587, 4587)\u001b[0m \u001b[32m provide\u001b[0m\u001b[97m(3493, 3493)\u001b[0m \u001b[32m those\u001b[0m\u001b[97m(1884, 1884)\u001b[0m \u001b[32m details\u001b[0m\u001b[97m(3649, 3649)\u001b[0m \u001b[32m?\u001b[0m\u001b[97m(30, 30)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mSure\u001b[0m\u001b[97m(-100, 40914)\u001b[0m \u001b[31m!\u001b[0m\u001b[97m(-100, 0)\u001b[0m \u001b[31m The\u001b[0m\u001b[97m(-100, 578)\u001b[0m \u001b[31m new\u001b[0m\u001b[97m(-100, 502)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m is\u001b[0m\u001b[97m(-100, 374)\u001b[0m \u001b[31m:\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 1473)\u001b[0m \u001b[31m456\u001b[0m\u001b[97m(-100, 10961)\u001b[0m \u001b[31m Elm\u001b[0m\u001b[97m(-100, 65329)\u001b[0m \u001b[31m St\u001b[0m\u001b[97m(-100, 800)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m City\u001b[0m\u001b[97m(-100, 4409)\u001b[0m \u001b[31m B\u001b[0m\u001b[97m(-100, 426)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m FL\u001b[0m\u001b[97m(-100, 13062)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m \u001b[0m\u001b[97m(-100, 220)\u001b[0m \u001b[31m328\u001b[0m\u001b[97m(-100, 16884)\u001b[0m \u001b[31m02\u001b[0m\u001b[97m(-100, 2437)\u001b[0m \u001b[31m,\u001b[0m\u001b[97m(-100, 11)\u001b[0m \u001b[31m US\u001b[0m\u001b[97m(-100, 2326)\u001b[0m \u001b[31m.\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 382)\u001b[0m \u001b[31mCan\u001b[0m\u001b[97m(-100, 6854)\u001b[0m \u001b[31m you\u001b[0m\u001b[97m(-100, 499)\u001b[0m \u001b[31m update\u001b[0m\u001b[97m(-100, 2713)\u001b[0m \u001b[31m the\u001b[0m\u001b[97m(-100, 279)\u001b[0m \u001b[31m shipping\u001b[0m\u001b[97m(-100, 11862)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m with\u001b[0m\u001b[97m(-100, 449)\u001b[0m \u001b[31m this\u001b[0m\u001b[97m(-100, 420)\u001b[0m \u001b[31m information\u001b[0m\u001b[97m(-100, 2038)\u001b[0m \u001b[31m?\u001b[0m\u001b[97m(-100, 30)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32mThought\u001b[0m\u001b[97m(85269, 85269)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m I\u001b[0m\u001b[97m(358, 358)\u001b[0m \u001b[32m need\u001b[0m\u001b[97m(1205, 1205)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m use\u001b[0m\u001b[97m(1005, 1005)\u001b[0m \u001b[32m a\u001b[0m\u001b[97m(264, 264)\u001b[0m \u001b[32m tool\u001b[0m\u001b[97m(5507, 5507)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m update\u001b[0m\u001b[97m(2713, 2713)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m shipping\u001b[0m\u001b[97m(11862, 11862)\u001b[0m \u001b[32m address\u001b[0m\u001b[97m(2686, 2686)\u001b[0m \u001b[32m for\u001b[0m\u001b[97m(369, 369)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m order\u001b[0m\u001b[97m(2015, 2015)\u001b[0m \u001b[32m.\n",
            "\u001b[0m\u001b[97m(627, 627)\u001b[0m \u001b[32mAction\u001b[0m\u001b[97m(2573, 2573)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m update\u001b[0m\u001b[97m(2713, 2713)\u001b[0m \u001b[32m_order\u001b[0m\u001b[97m(8028, 8028)\u001b[0m \u001b[32m_address\u001b[0m\u001b[97m(6886, 6886)\u001b[0m \u001b[32m\n",
            "\u001b[0m\u001b[97m(198, 198)\u001b[0m \u001b[32mAction\u001b[0m\u001b[97m(2573, 2573)\u001b[0m \u001b[32m Input\u001b[0m\u001b[97m(5688, 5688)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m {'\u001b[0m\u001b[97m(5473, 5473)\u001b[0m \u001b[32morder\u001b[0m\u001b[97m(1382, 1382)\u001b[0m \u001b[32m_id\u001b[0m\u001b[97m(851, 851)\u001b[0m \u001b[32m':\u001b[0m\u001b[97m(1232, 1232)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m58\u001b[0m\u001b[97m(2970, 2970)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mnew\u001b[0m\u001b[97m(943, 943)\u001b[0m \u001b[32m_street\u001b[0m\u001b[97m(79662, 79662)\u001b[0m \u001b[32m':\u001b[0m\u001b[97m(1232, 1232)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32m456\u001b[0m\u001b[97m(10961, 10961)\u001b[0m \u001b[32m Elm\u001b[0m\u001b[97m(65329, 65329)\u001b[0m \u001b[32m St\u001b[0m\u001b[97m(800, 800)\u001b[0m \u001b[32m',\u001b[0m\u001b[97m(518, 518)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mnew\u001b[0m\u001b[97m(943, 943)\u001b[0m \u001b[32m_city\u001b[0m\u001b[97m(26019, 26019)\u001b[0m \u001b[32m':\u001b[0m\u001b[97m(1232, 1232)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mCity\u001b[0m\u001b[97m(13020, 13020)\u001b[0m \u001b[32m B\u001b[0m\u001b[97m(426, 426)\u001b[0m \u001b[32m',\u001b[0m\u001b[97m(518, 518)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mnew\u001b[0m\u001b[97m(943, 943)\u001b[0m \u001b[32m_zip\u001b[0m\u001b[97m(43231, 43231)\u001b[0m \u001b[32m':\u001b[0m\u001b[97m(1232, 1232)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32m328\u001b[0m\u001b[97m(16884, 16884)\u001b[0m \u001b[32m02\u001b[0m\u001b[97m(2437, 2437)\u001b[0m \u001b[32m',\u001b[0m\u001b[97m(518, 518)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mnew\u001b[0m\u001b[97m(943, 943)\u001b[0m \u001b[32m_state\u001b[0m\u001b[97m(4486, 4486)\u001b[0m \u001b[32m':\u001b[0m\u001b[97m(1232, 1232)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mFL\u001b[0m\u001b[97m(6254, 6254)\u001b[0m \u001b[32m',\u001b[0m\u001b[97m(518, 518)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mnew\u001b[0m\u001b[97m(943, 943)\u001b[0m \u001b[32m_country\u001b[0m\u001b[97m(29206, 29206)\u001b[0m \u001b[32m':\u001b[0m\u001b[97m(1232, 1232)\u001b[0m \u001b[32m '\u001b[0m\u001b[97m(364, 364)\u001b[0m \u001b[32mUS\u001b[0m\u001b[97m(2078, 2078)\u001b[0m \u001b[32m'}\u001b[0m\u001b[97m(8439, 8439)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31muser\u001b[0m\u001b[97m(-100, 882)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[97m(-100, 271)\u001b[0m \u001b[31mObserv\u001b[0m\u001b[97m(-100, 38863)\u001b[0m \u001b[31mation\u001b[0m\u001b[97m(-100, 367)\u001b[0m \u001b[31m:\u001b[0m\u001b[97m(-100, 25)\u001b[0m \u001b[31m Shipping\u001b[0m\u001b[97m(-100, 24907)\u001b[0m \u001b[31m address\u001b[0m\u001b[97m(-100, 2686)\u001b[0m \u001b[31m updated\u001b[0m\u001b[97m(-100, 6177)\u001b[0m \u001b[31m successfully\u001b[0m\u001b[97m(-100, 7946)\u001b[0m \u001b[31m.\u001b[0m\u001b[97m(-100, 13)\u001b[0m \u001b[31m<|eot_id|>\u001b[0m\u001b[97m(-100, 128009)\u001b[0m \u001b[31m<|start_header_id|>\u001b[0m\u001b[97m(-100, 128006)\u001b[0m \u001b[31massistant\u001b[0m\u001b[97m(-100, 78191)\u001b[0m \u001b[31m<|end_header_id|>\u001b[0m\u001b[97m(-100, 128007)\u001b[0m \u001b[32m\n",
            "\n",
            "\u001b[0m\u001b[97m(271, 271)\u001b[0m \u001b[32mThought\u001b[0m\u001b[97m(85269, 85269)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m I\u001b[0m\u001b[97m(358, 358)\u001b[0m \u001b[32m can\u001b[0m\u001b[97m(649, 649)\u001b[0m \u001b[32m answer\u001b[0m\u001b[97m(4320, 4320)\u001b[0m \u001b[32m without\u001b[0m\u001b[97m(2085, 2085)\u001b[0m \u001b[32m using\u001b[0m\u001b[97m(1701, 1701)\u001b[0m \u001b[32m any\u001b[0m\u001b[97m(904, 904)\u001b[0m \u001b[32m more\u001b[0m\u001b[97m(810, 810)\u001b[0m \u001b[32m tools\u001b[0m\u001b[97m(7526, 7526)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m I\u001b[0m\u001b[97m(358, 358)\u001b[0m \u001b[32m'll\u001b[0m\u001b[97m(3358, 3358)\u001b[0m \u001b[32m use\u001b[0m\u001b[97m(1005, 1005)\u001b[0m \u001b[32m the\u001b[0m\u001b[97m(279, 279)\u001b[0m \u001b[32m user\u001b[0m\u001b[97m(1217, 1217)\u001b[0m \u001b[32m's\u001b[0m\u001b[97m(596, 596)\u001b[0m \u001b[32m language\u001b[0m\u001b[97m(4221, 4221)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m answer\u001b[0m\u001b[97m(4320, 4320)\u001b[0m \u001b[32m.\n",
            "\u001b[0m\u001b[97m(627, 627)\u001b[0m \u001b[32mAnswer\u001b[0m\u001b[97m(16533, 16533)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m The\u001b[0m\u001b[97m(578, 578)\u001b[0m \u001b[32m shipping\u001b[0m\u001b[97m(11862, 11862)\u001b[0m \u001b[32m address\u001b[0m\u001b[97m(2686, 2686)\u001b[0m \u001b[32m for\u001b[0m\u001b[97m(369, 369)\u001b[0m \u001b[32m your\u001b[0m\u001b[97m(701, 701)\u001b[0m \u001b[32m **\u001b[0m\u001b[97m(3146, 3146)\u001b[0m \u001b[32mSmart\u001b[0m\u001b[97m(34917, 34917)\u001b[0m \u001b[32m Refriger\u001b[0m\u001b[97m(75258, 75258)\u001b[0m \u001b[32mator\u001b[0m\u001b[97m(859, 859)\u001b[0m \u001b[32m**\u001b[0m\u001b[97m(334, 334)\u001b[0m \u001b[32m (\u001b[0m\u001b[97m(320, 320)\u001b[0m \u001b[32mOrder\u001b[0m\u001b[97m(4531, 4531)\u001b[0m \u001b[32m ID\u001b[0m\u001b[97m(3110, 3110)\u001b[0m \u001b[32m:\u001b[0m\u001b[97m(25, 25)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m58\u001b[0m\u001b[97m(2970, 2970)\u001b[0m \u001b[32m)\u001b[0m\u001b[97m(8, 8)\u001b[0m \u001b[32m has\u001b[0m\u001b[97m(706, 706)\u001b[0m \u001b[32m been\u001b[0m\u001b[97m(1027, 1027)\u001b[0m \u001b[32m updated\u001b[0m\u001b[97m(6177, 6177)\u001b[0m \u001b[32m successfully\u001b[0m\u001b[97m(7946, 7946)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m456\u001b[0m\u001b[97m(10961, 10961)\u001b[0m \u001b[32m Elm\u001b[0m\u001b[97m(65329, 65329)\u001b[0m \u001b[32m St\u001b[0m\u001b[97m(800, 800)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m City\u001b[0m\u001b[97m(4409, 4409)\u001b[0m \u001b[32m B\u001b[0m\u001b[97m(426, 426)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m FL\u001b[0m\u001b[97m(13062, 13062)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m \u001b[0m\u001b[97m(220, 220)\u001b[0m \u001b[32m328\u001b[0m\u001b[97m(16884, 16884)\u001b[0m \u001b[32m02\u001b[0m\u001b[97m(2437, 2437)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m US\u001b[0m\u001b[97m(2326, 2326)\u001b[0m \u001b[32m.\u001b[0m\u001b[97m(13, 13)\u001b[0m \u001b[32m If\u001b[0m\u001b[97m(1442, 1442)\u001b[0m \u001b[32m you\u001b[0m\u001b[97m(499, 499)\u001b[0m \u001b[32m need\u001b[0m\u001b[97m(1205, 1205)\u001b[0m \u001b[32m any\u001b[0m\u001b[97m(904, 904)\u001b[0m \u001b[32m further\u001b[0m\u001b[97m(4726, 4726)\u001b[0m \u001b[32m assistance\u001b[0m\u001b[97m(13291, 13291)\u001b[0m \u001b[32m,\u001b[0m\u001b[97m(11, 11)\u001b[0m \u001b[32m feel\u001b[0m\u001b[97m(2733, 2733)\u001b[0m \u001b[32m free\u001b[0m\u001b[97m(1949, 1949)\u001b[0m \u001b[32m to\u001b[0m\u001b[97m(311, 311)\u001b[0m \u001b[32m ask\u001b[0m\u001b[97m(2610, 2610)\u001b[0m \u001b[33m!\u001b[0m\u001b[97m(0, 0)\u001b[0m \u001b[32m<|eot_id|>\u001b[0m\u001b[97m(128009, 128009)\u001b[0m\u001b[39m\n",
            "[2024-10-23 21:04:51,544] [INFO] [axolotl.check_example_labels:46] [PID:9597] [RANK:0] \n",
            "\n",
            "\n",
            "\u001b[39m\n",
            "[2024-10-23 21:04:51,545] [INFO] [axolotl.scripts.load_datasets:484] [PID:9597] [RANK:0] printing prompters...\u001b[39m\n",
            "[2024-10-23 21:04:51,545] [INFO] [axolotl.scripts.load_datasets:486] [PID:9597] [RANK:0] Pre-tokenized or custom dataset types are unsupported for logging\u001b[39m\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 77.0MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<01:56, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.97G [00:00<01:55, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<01:54, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<01:53, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.97G [00:01<01:53, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.97G [00:01<01:53, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:01<01:53, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.97G [00:01<01:53, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.97G [00:02<01:53, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.97G [00:02<01:53, 43.0MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.97G [00:02<01:52, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.97G [00:02<01:52, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.97G [00:03<01:52, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.97G [00:03<01:52, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.97G [00:03<01:51, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.97G [00:03<01:51, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.97G [00:04<01:51, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.97G [00:04<01:50, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.97G [00:04<01:50, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.97G [00:04<01:50, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.97G [00:05<01:50, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.97G [00:05<01:50, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.97G [00:05<01:50, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.97G [00:05<01:50, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.97G [00:06<01:50, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.97G [00:06<01:49, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.97G [00:06<01:49, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.97G [00:06<01:48, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.97G [00:07<01:48, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.97G [00:07<01:48, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.97G [00:07<01:47, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.97G [00:07<01:47, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.97G [00:08<01:47, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:08<01:54, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.97G [00:08<01:53, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:08<01:59, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.97G [00:09<02:13, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:09<02:08, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.97G [00:09<02:02, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:10<02:01, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.97G [00:10<01:58, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.97G [00:10<01:55, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.97G [00:10<01:53, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.97G [00:11<01:51, 40.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.97G [00:11<01:49, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:11<01:48, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.97G [00:11<01:46, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:12<01:46, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.97G [00:12<01:49, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:12<01:47, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.97G [00:12<01:45, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.97G [00:13<01:45, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.97G [00:13<01:44, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.97G [00:13<01:43, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.97G [00:13<01:43, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.97G [00:14<01:43, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.97G [00:14<01:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.97G [00:14<01:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.97G [00:14<01:41, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:15<01:42, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.97G [00:15<01:42, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:15<01:42, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.97G [00:15<01:41, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.97G [00:16<01:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.97G [00:16<01:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:16<01:40, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.97G [00:16<01:40, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.97G [00:17<01:40, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.97G [00:17<01:39, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:17<01:39, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.97G [00:17<01:39, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:18<01:39, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.97G [00:18<01:39, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:18<01:38, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.97G [00:18<01:37, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:19<01:37, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.97G [00:19<01:38, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:19<01:37, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.97G [00:19<01:36, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:19<01:36, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.97G [00:20<01:35, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:20<01:35, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.97G [00:20<01:35, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:20<01:35, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.97G [00:21<01:35, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:21<01:35, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.97G [00:21<01:34, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:21<01:34, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.97G [00:22<01:34, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:22<01:34, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.97G [00:22<01:34, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:22<01:33, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.97G [00:23<01:33, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:23<01:33, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.97G [00:23<01:33, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:23<01:32, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.97G [00:24<01:32, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:24<01:32, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.97G [00:24<01:31, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:24<01:31, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.97G [00:25<01:30, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:25<01:30, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:25<01:30, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:25<01:30, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.97G [00:26<01:30, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:26<01:30, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:26<01:29, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:26<01:29, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.97G [00:27<01:29, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.97G [00:27<01:32, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:27<01:31, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:27<01:29, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.97G [00:28<01:29, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.97G [00:28<01:28, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:28<01:27, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:28<01:27, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.97G [00:29<01:27, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:29<01:27, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.97G [00:29<01:26, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:29<01:26, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:30<01:26, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:30<01:25, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.97G [00:30<01:26, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:30<01:25, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.97G [00:31<01:25, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.97G [00:31<01:25, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.97G [00:31<01:24, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:31<01:24, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.97G [00:32<01:24, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:32<01:24, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.97G [00:32<01:24, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.97G [00:32<01:23, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:33<01:23, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.97G [00:33<01:22, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.97G [00:33<01:22, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.97G [00:33<01:22, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:33<01:21, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.97G [00:34<01:21, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:34<01:21, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.97G [00:34<01:21, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.97G [00:34<01:21, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:35<01:21, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.97G [00:35<01:20, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:35<01:20, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:35<01:20, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.97G [00:36<01:19, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.97G [00:36<01:19, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:36<01:19, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.97G [00:36<01:19, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:37<01:18, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:37<01:18, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:37<01:18, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:37<01:18, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.97G [00:38<01:18, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:38<01:18, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.97G [00:38<01:18, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:38<01:17, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.97G [00:39<01:17, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:39<01:17, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:39<01:18, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.97G [00:39<01:17, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.97G [00:40<01:17, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:40<01:16, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.97G [00:40<01:18, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.97G [00:40<01:17, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:41<01:16, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.97G [00:41<01:15, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.97G [00:41<01:17, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:41<01:16, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.97G [00:42<01:15, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.97G [00:42<01:14, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:42<01:16, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.97G [00:42<01:14, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.97G [00:43<01:14, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:43<01:13, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.97G [00:43<01:15, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.97G [00:43<01:14, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:44<01:13, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:44<01:12, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/4.97G [00:44<01:14, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:44<01:13, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.97G [00:45<01:12, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:45<01:11, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.97G [00:45<01:13, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:45<01:12, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.97G [00:46<01:11, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:46<01:10, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.97G [00:46<01:12, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.97G [00:46<01:11, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:47<01:09, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.97G [00:47<01:09, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.97G [00:47<01:11, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:47<01:10, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.97G [00:48<01:09, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:48<01:09, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.97G [00:48<01:10, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:48<01:09, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.97G [00:49<01:08, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:49<01:07, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.97G [00:49<01:09, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.97G [00:49<01:08, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:50<01:07, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.97G [00:50<01:07, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.97G [00:50<01:08, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:50<01:07, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.97G [00:51<01:06, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.97G [00:51<01:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.97G [00:51<01:07, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:51<01:06, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.97G [00:52<01:05, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.97G [00:52<01:05, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.97G [00:52<01:06, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:52<01:04, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.97G [00:53<01:04, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:53<01:03, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.26G/4.97G [00:53<01:05, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:53<01:04, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.97G [00:54<01:03, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.97G [00:54<01:02, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:54<01:04, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:54<01:04, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.97G [00:55<01:09, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:55<01:09, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.97G [00:55<01:13, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.97G [00:56<01:16, 33.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:56<01:23, 31.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.97G [00:57<01:30, 28.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.97G [00:57<01:29, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:57<01:21, 31.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.97G [00:57<01:14, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.97G [00:58<01:09, 36.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.97G [00:58<01:06, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:58<01:03, 39.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.97G [00:58<01:02, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.97G [00:59<01:00, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.97G [00:59<00:59, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [00:59<00:58, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.97G [00:59<00:58, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.97G [01:00<00:57, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.97G [01:00<00:57, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.97G [01:00<00:56, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [01:00<00:56, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.97G [01:01<00:56, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.97G [01:01<00:55, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [01:01<00:55, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.97G [01:01<00:55, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.97G [01:02<00:55, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.97G [01:02<00:54, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [01:02<00:54, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.97G [01:02<00:54, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.97G [01:02<00:54, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.97G [01:03<00:54, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.97G [01:03<00:54, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.97G [01:03<00:53, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.97G [01:03<00:53, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.97G [01:04<00:53, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.97G [01:04<00:53, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.97G [01:04<00:52, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.97G [01:04<00:52, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.97G [01:05<00:51, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.97G [01:05<00:51, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.97G [01:05<00:51, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.97G [01:05<00:51, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.97G [01:06<00:51, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [01:06<00:50, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.97G [01:06<00:50, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [01:06<00:50, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.97G [01:07<00:50, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.97G [01:07<00:49, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.97G [01:07<00:49, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.97G [01:07<00:49, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.97G [01:08<00:49, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.97G [01:08<00:48, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.97G [01:08<00:48, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.97G [01:09<00:58, 35.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.97G [01:09<00:55, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [01:09<00:52, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.97G [01:09<00:50, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.97G [01:09<00:49, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.97G [01:10<00:48, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [01:10<00:48, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.96G/4.97G [01:10<00:47, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.97G [01:10<00:46, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [01:11<00:46, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.97G [01:11<00:45, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.97G [01:11<00:45, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.97G [01:11<00:45, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.97G [01:12<00:45, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.97G [01:12<00:44, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.97G [01:12<00:44, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.97G [01:12<00:44, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.97G [01:13<00:44, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [01:13<00:44, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.97G [01:13<00:43, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.97G [01:13<00:43, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.97G [01:14<00:43, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.97G [01:14<00:43, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.97G [01:14<00:43, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.97G [01:14<00:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.97G [01:15<00:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.97G [01:15<00:42, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.97G [01:15<00:41, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.97G [01:15<00:41, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.97G [01:16<00:41, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [01:16<00:41, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.97G [01:16<00:40, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.97G [01:16<00:40, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [01:17<00:40, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.97G [01:17<00:40, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [01:17<00:39, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.97G [01:17<00:39, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.97G [01:18<00:39, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.97G [01:18<00:39, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [01:18<00:38, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.97G [01:18<00:38, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [01:19<00:38, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.97G [01:19<00:38, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.97G [01:19<00:37, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.97G [01:19<00:37, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.97G [01:20<00:37, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.97G [01:20<00:37, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.97G [01:20<00:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.97G [01:20<00:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.97G [01:20<00:36, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.97G [01:21<00:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.97G [01:21<00:35, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.97G [01:21<00:35, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.97G [01:21<00:35, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [01:22<00:35, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.97G [01:22<00:34, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.97G [01:22<00:34, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [01:22<00:34, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.97G [01:23<00:34, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.97G [01:23<00:34, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.97G [01:23<00:33, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.97G [01:23<00:33, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.97G [01:24<00:33, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.97G [01:24<00:33, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.97G [01:24<00:32, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.97G [01:24<00:32, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.97G [01:25<00:32, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.97G [01:25<00:32, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [01:25<00:31, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.61G/4.97G [01:25<00:31, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.97G [01:26<00:31, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.97G [01:26<00:31, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.97G [01:26<00:30, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.97G [01:26<00:30, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.97G [01:27<00:30, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.97G [01:27<00:30, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.97G [01:27<00:30, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.97G [01:27<00:29, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.97G [01:28<00:29, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.97G [01:28<00:29, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.97G [01:28<00:28, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.97G [01:28<00:28, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.97G [01:29<00:28, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.97G [01:29<00:28, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.97G [01:29<00:27, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.97G [01:29<00:27, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.97G [01:29<00:27, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/4.97G [01:30<00:27, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [01:30<00:26, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.97G [01:30<00:26, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.97G [01:30<00:26, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.97G [01:31<00:26, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.97G [01:31<00:26, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.86G/4.97G [01:31<00:25, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.97G [01:31<00:25, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [01:32<00:25, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.97G [01:32<00:25, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.90G/4.97G [01:32<00:24, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [01:32<00:24, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.97G [01:33<00:24, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [01:33<00:24, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.97G [01:33<00:23, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.97G [01:33<00:23, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.97G [01:34<00:23, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [01:34<00:23, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.97G [01:34<00:23, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.97G [01:34<00:22, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.97G [01:35<00:22, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.97G [01:35<00:22, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.97G [01:35<00:22, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [01:35<00:22, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.05G/4.97G [01:36<00:21, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.97G [01:36<00:21, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.97G [01:36<00:21, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [01:36<00:21, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.97G [01:37<00:20, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.97G [01:37<00:20, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.97G [01:37<00:20, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.97G [01:37<00:20, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.97G [01:38<00:19, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [01:38<00:19, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.97G [01:38<00:19, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.97G [01:38<00:19, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.97G [01:39<00:18, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.97G [01:39<00:18, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/4.97G [01:39<00:18, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.97G [01:39<00:18, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.97G [01:40<00:17, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.97G [01:40<00:17, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.97G [01:40<00:17, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.25G/4.97G [01:40<00:17, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.26G/4.97G [01:41<00:16, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.97G [01:41<00:16, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.97G [01:41<00:16, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.97G [01:41<00:16, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.30G/4.97G [01:42<00:15, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [01:42<00:15, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.97G [01:42<00:15, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.97G [01:42<00:15, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.97G [01:43<00:14, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.97G [01:43<00:14, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.97G [01:43<00:14, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [01:43<00:14, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.97G [01:44<00:13, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/4.97G [01:44<00:13, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.97G [01:44<00:13, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.97G [01:44<00:13, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/4.97G [01:45<00:12, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [01:45<00:12, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.97G [01:45<00:12, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.97G [01:45<00:13, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.97G [01:46<00:12, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.97G [01:46<00:12, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.97G [01:46<00:11, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.97G [01:46<00:11, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [01:47<00:10, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.97G [01:47<00:10, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.97G [01:47<00:10, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.97G [01:47<00:09, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.97G [01:48<00:09, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.97G [01:48<00:09, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.97G [01:48<00:09, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [01:48<00:08, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.97G [01:49<00:08, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.97G [01:49<00:08, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.97G [01:49<00:08, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [01:49<00:07, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.97G [01:50<00:07, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.97G [01:50<00:07, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.66G/4.97G [01:50<00:07, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.97G [01:50<00:07, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.97G [01:51<00:06, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.97G [01:51<00:06, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.70G/4.97G [01:51<00:06, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.97G [01:51<00:06, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.97G [01:52<00:05, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.97G [01:52<00:05, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/4.97G [01:52<00:05, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [01:52<00:05, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.97G [01:53<00:05, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.97G [01:53<00:05, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.97G [01:53<00:04, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.97G [01:53<00:04, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.80G/4.97G [01:54<00:03, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [01:54<00:03, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.97G [01:54<00:03, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.97G [01:54<00:03, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.84G/4.97G [01:55<00:02, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [01:55<00:02, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.97G [01:55<00:02, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.97G [01:55<00:02, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.97G [01:56<00:01, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.97G [01:56<00:01, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.97G [01:56<00:01, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.97G [01:56<00:01, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.97G [01:57<00:00, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.97G [01:57<00:00, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.97G [01:57<00:00, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.97G [01:57<00:00, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [01:58<00:00, 42.1MB/s]\n",
            "Downloading shards:  50% 1/2 [01:58<01:58, 118.58s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/1.46G [00:00<00:33, 43.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/1.46G [00:00<00:33, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 31.5M/1.46G [00:00<00:33, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 41.9M/1.46G [00:00<00:32, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 52.4M/1.46G [00:01<00:32, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 62.9M/1.46G [00:01<00:32, 43.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 73.4M/1.46G [00:01<00:34, 39.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 83.9M/1.46G [00:01<00:32, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 94.4M/1.46G [00:02<00:31, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 105M/1.46G [00:02<00:31, 42.6MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 115M/1.46G [00:02<00:31, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 126M/1.46G [00:02<00:31, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 136M/1.46G [00:03<00:30, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 147M/1.46G [00:03<00:30, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 157M/1.46G [00:03<00:30, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 168M/1.46G [00:03<00:30, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 178M/1.46G [00:04<00:29, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 189M/1.46G [00:04<00:29, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 199M/1.46G [00:04<00:29, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 210M/1.46G [00:04<00:29, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 220M/1.46G [00:05<00:28, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 231M/1.46G [00:05<00:28, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 241M/1.46G [00:05<00:28, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 252M/1.46G [00:05<00:28, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 262M/1.46G [00:06<00:27, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 273M/1.46G [00:06<00:27, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 283M/1.46G [00:06<00:27, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 294M/1.46G [00:06<00:27, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 304M/1.46G [00:07<00:27, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 315M/1.46G [00:07<00:26, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 325M/1.46G [00:07<00:26, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 336M/1.46G [00:07<00:26, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 346M/1.46G [00:08<00:26, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 357M/1.46G [00:08<00:25, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 367M/1.46G [00:08<00:25, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 377M/1.46G [00:08<00:25, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 388M/1.46G [00:09<00:24, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 398M/1.46G [00:09<00:24, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 409M/1.46G [00:09<00:24, 43.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 419M/1.46G [00:09<00:24, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 430M/1.46G [00:10<00:23, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 440M/1.46G [00:10<00:23, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 451M/1.46G [00:10<00:23, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 461M/1.46G [00:10<00:23, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 472M/1.46G [00:11<00:23, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 482M/1.46G [00:11<00:22, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 493M/1.46G [00:11<00:22, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 503M/1.46G [00:11<00:22, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 514M/1.46G [00:12<00:21, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 524M/1.46G [00:12<00:21, 43.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 535M/1.46G [00:12<00:21, 43.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 545M/1.46G [00:12<00:21, 43.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 556M/1.46G [00:12<00:20, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 566M/1.46G [00:13<00:20, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 577M/1.46G [00:13<00:20, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 587M/1.46G [00:13<00:20, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 598M/1.46G [00:13<00:20, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 608M/1.46G [00:14<00:19, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 619M/1.46G [00:14<00:19, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 629M/1.46G [00:14<00:19, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 640M/1.46G [00:14<00:19, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 650M/1.46G [00:15<00:18, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 661M/1.46G [00:15<00:18, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 671M/1.46G [00:15<00:18, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 682M/1.46G [00:15<00:18, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 692M/1.46G [00:16<00:17, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 703M/1.46G [00:16<00:17, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 713M/1.46G [00:16<00:17, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 724M/1.46G [00:16<00:17, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 734M/1.46G [00:17<00:17, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 744M/1.46G [00:17<00:17, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 755M/1.46G [00:17<00:16, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 765M/1.46G [00:17<00:16, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 776M/1.46G [00:18<00:17, 39.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 786M/1.46G [00:18<00:16, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 797M/1.46G [00:18<00:16, 41.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 807M/1.46G [00:18<00:15, 40.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 818M/1.46G [00:19<00:15, 41.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 828M/1.46G [00:19<00:15, 41.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 839M/1.46G [00:19<00:14, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 849M/1.46G [00:20<00:15, 38.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 860M/1.46G [00:20<00:16, 36.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 870M/1.46G [00:20<00:15, 38.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 881M/1.46G [00:20<00:14, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 891M/1.46G [00:21<00:14, 38.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 902M/1.46G [00:21<00:14, 39.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 912M/1.46G [00:21<00:13, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 923M/1.46G [00:21<00:12, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 933M/1.46G [00:22<00:13, 40.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 944M/1.46G [00:22<00:12, 41.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 954M/1.46G [00:22<00:12, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 965M/1.46G [00:22<00:11, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 975M/1.46G [00:23<00:11, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 986M/1.46G [00:23<00:11, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 996M/1.46G [00:23<00:10, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.01G/1.46G [00:23<00:10, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.02G/1.46G [00:24<00:10, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.03G/1.46G [00:24<00:10, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 1.04G/1.46G [00:24<00:09, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 1.05G/1.46G [00:24<00:09, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.06G/1.46G [00:25<00:10, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.07G/1.46G [00:25<00:09, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.08G/1.46G [00:25<00:09, 41.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.09G/1.46G [00:25<00:08, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.10G/1.46G [00:26<00:08, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 1.11G/1.46G [00:26<00:08, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 1.12G/1.46G [00:26<00:07, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.13G/1.46G [00:26<00:07, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.14G/1.46G [00:27<00:07, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 1.15G/1.46G [00:27<00:07, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.16G/1.46G [00:27<00:06, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.17G/1.46G [00:27<00:06, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 1.18G/1.46G [00:28<00:06, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 1.20G/1.46G [00:28<00:06, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 1.21G/1.46G [00:28<00:05, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 1.22G/1.46G [00:28<00:05, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 1.23G/1.46G [00:29<00:05, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.24G/1.46G [00:29<00:05, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.25G/1.46G [00:29<00:04, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 1.26G/1.46G [00:29<00:04, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 1.27G/1.46G [00:29<00:04, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.28G/1.46G [00:30<00:04, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.29G/1.46G [00:30<00:03, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 1.30G/1.46G [00:30<00:03, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 1.31G/1.46G [00:30<00:03, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.32G/1.46G [00:31<00:03, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.33G/1.46G [00:31<00:02, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 1.34G/1.46G [00:31<00:02, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.35G/1.46G [00:31<00:02, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.36G/1.46G [00:32<00:02, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 1.37G/1.46G [00:32<00:01, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 1.38G/1.46G [00:32<00:01, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.39G/1.46G [00:32<00:01, 41.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.41G/1.46G [00:33<00:01, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 1.42G/1.46G [00:33<00:01, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.43G/1.46G [00:33<00:00, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.44G/1.46G [00:33<00:00, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 1.45G/1.46G [00:34<00:00, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:34<00:00, 42.3MB/s]\n",
            "Downloading shards: 100% 2/2 [02:33<00:00, 76.76s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  2.33it/s]\n",
            "generation_config.json: 100% 185/185 [00:00<00:00, 1.47MB/s]\n",
            "[2024-10-23 21:07:27,880] [INFO] [axolotl.cli.preprocess.do_cli:96] [PID:9597] [RANK:0] \u001b[32mSuccess! Preprocessed data path: `dataset_prepared_path: data`\u001b[39m\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning\n",
        "\n",
        "Wow, that was tough!\n",
        "Now let's do another hard thing, fine tune the model.\n",
        "The following command will launch our fine tuning run.\n",
        "It will save the LoRA adapters in the output folder."
      ],
      "metadata": {
        "id": "N7PnQChITtHs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hYHoF8rtdlCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9286735a-6dee-46d7-b98d-710958f89283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-10-23 21:12:21.278007: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-23 21:12:21.297112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-23 21:12:21.317962: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-23 21:12:21.324343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-23 21:12:21.339790: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-23 21:12:22.385649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, forward_function, hidden_states, *args):\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:40: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dY):\n",
            "[2024-10-23 21:12:25,126] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-10-23 21:12:25,205] [INFO] [root.spawn:60] [PID:12555] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpd2qmuvfx/test.c -o /tmp/tmpd2qmuvfx/test.o\n",
            "[2024-10-23 21:12:25,223] [INFO] [root.spawn:60] [PID:12555] x86_64-linux-gnu-gcc /tmp/tmpd2qmuvfx/test.o -laio -o /tmp/tmpd2qmuvfx/a.out\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "[2024-10-23 21:12:28,132] [DEBUG] [axolotl.normalize_config:83] [PID:12555] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "[2024-10-23 21:12:28,385] [INFO] [axolotl.normalize_config:207] [PID:12555] [RANK:0] GPU memory usage baseline: 0.000GB (+0.331GB misc)\u001b[39m\n",
            "[2024-10-23 21:12:28,385] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:12555] [RANK:0] updating dataset data/train.jsonl with `conversation: llama3` to match your chat_template\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "\u001b[33m[2024-10-23 21:12:28,403] [WARNING] [axolotl.scripts.check_user_token:550] [PID:12555] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "[2024-10-23 21:12:29,356] [DEBUG] [axolotl.load_tokenizer:290] [PID:12555] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-23 21:12:29,356] [DEBUG] [axolotl.load_tokenizer:291] [PID:12555] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-23 21:12:29,356] [DEBUG] [axolotl.load_tokenizer:292] [PID:12555] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-23 21:12:29,356] [DEBUG] [axolotl.load_tokenizer:293] [PID:12555] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-23 21:12:29,356] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:12555] [RANK:0] Loading prepared dataset from disk at data/1a30e7233b3444192cecdbec92ab7aeb...\u001b[39m\n",
            "[2024-10-23 21:12:29,361] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:12555] [RANK:0] Prepared dataset loaded from disk...\u001b[39m\n",
            "[2024-10-23 21:12:29,362] [INFO] [axolotl.load_tokenized_prepared_datasets:199] [PID:12555] [RANK:0] Loading prepared dataset from disk at data/7881ad52902f690d2de1df7a65e475e3...\u001b[39m\n",
            "[2024-10-23 21:12:29,364] [INFO] [axolotl.load_tokenized_prepared_datasets:201] [PID:12555] [RANK:0] Prepared dataset loaded from disk...\u001b[39m\n",
            "[2024-10-23 21:12:29,368] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:12555] [RANK:0] total_num_tokens: 281_304\u001b[39m\n",
            "[2024-10-23 21:12:29,371] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:12555] [RANK:0] `total_supervised_tokens: 37_701`\u001b[39m\n",
            "[2024-10-23 21:12:35,361] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "[2024-10-23 21:12:35,361] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:12555] [RANK:0] data_loader_len: 4\u001b[39m\n",
            "[2024-10-23 21:12:35,361] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:12555] [RANK:0] sample_packing_eff_est across ranks: [0.8804837740384616]\u001b[39m\n",
            "[2024-10-23 21:12:35,361] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:12555] [RANK:0] sample_packing_eff_est: None\u001b[39m\n",
            "[2024-10-23 21:12:35,361] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:12555] [RANK:0] total_num_steps: 8\u001b[39m\n",
            "[2024-10-23 21:12:35,362] [DEBUG] [axolotl.calculate_total_num_steps:320] [PID:12555] [RANK:0] total_num_tokens: 825_623\u001b[39m\n",
            "[2024-10-23 21:12:35,369] [DEBUG] [axolotl.calculate_total_num_steps:338] [PID:12555] [RANK:0] `total_supervised_tokens: 106_188`\u001b[39m\n",
            "[2024-10-23 21:12:35,371] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [113]\u001b[39m\n",
            "[2024-10-23 21:12:35,371] [DEBUG] [axolotl.calculate_total_num_steps:390] [PID:12555] [RANK:0] data_loader_len: 14\u001b[39m\n",
            "[2024-10-23 21:12:35,371] [INFO] [axolotl.calc_sample_packing_eff_est:396] [PID:12555] [RANK:0] sample_packing_eff_est across ranks: [0.8918943151963495]\u001b[39m\n",
            "[2024-10-23 21:12:35,372] [DEBUG] [axolotl.calculate_total_num_steps:408] [PID:12555] [RANK:0] sample_packing_eff_est: 0.9\u001b[39m\n",
            "[2024-10-23 21:12:35,372] [DEBUG] [axolotl.calculate_total_num_steps:416] [PID:12555] [RANK:0] total_num_steps: 28\u001b[39m\n",
            "[2024-10-23 21:12:35,403] [DEBUG] [axolotl.train.train:66] [PID:12555] [RANK:0] loading tokenizer... meta-llama/Llama-3.2-3B\u001b[39m\n",
            "[2024-10-23 21:12:36,336] [DEBUG] [axolotl.load_tokenizer:290] [PID:12555] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-23 21:12:36,336] [DEBUG] [axolotl.load_tokenizer:291] [PID:12555] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-23 21:12:36,336] [DEBUG] [axolotl.load_tokenizer:292] [PID:12555] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-23 21:12:36,336] [DEBUG] [axolotl.load_tokenizer:293] [PID:12555] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-23 21:12:36,336] [DEBUG] [axolotl.train.train:98] [PID:12555] [RANK:0] loading model and peft_config...\u001b[39m\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.53s/it]\n",
            "[2024-10-23 21:12:40,397] [INFO] [axolotl.load_model:855] [PID:12555] [RANK:0] GPU memory usage after model load: 2.102GB (+0.011GB cache, +0.542GB misc)\u001b[39m\n",
            "[2024-10-23 21:12:40,412] [INFO] [axolotl.load_model:913] [PID:12555] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2024-10-23 21:12:40,416] [INFO] [axolotl.load_model:922] [PID:12555] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
            "[2024-10-23 21:12:40,420] [INFO] [axolotl.load_lora:1087] [PID:12555] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "trainable params: 48,627,712 || all params: 3,261,377,536 || trainable%: 1.4910\n",
            "[2024-10-23 21:12:41,227] [INFO] [axolotl.load_model:970] [PID:12555] [RANK:0] GPU memory usage after adapters: 2.283GB (+1.489GB cache, +0.542GB misc)\u001b[39m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "[2024-10-23 21:12:42,477] [INFO] [axolotl.train.train:141] [PID:12555] [RANK:0] Pre-saving adapter config to ./model-out\u001b[39m\n",
            "[2024-10-23 21:12:42,699] [INFO] [axolotl.train.train:178] [PID:12555] [RANK:0] Starting trainer...\u001b[39m\n",
            "[2024-10-23 21:12:43,101] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [116]\u001b[39m\n",
            "  0% 0/28 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "{'loss': 0.9615, 'grad_norm': 0.24870926141738892, 'learning_rate': 2e-05, 'epoch': 0.07}\n",
            "  4% 1/28 [00:52<23:33, 52.34s/it][2024-10-23 21:13:35,513] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.06it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:47,  1.34s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:52,  1.55s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:55,  1.67s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:55,  1.75s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:55,  1.80s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:54,  1.83s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:54,  1.89s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:52,  1.89s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.89s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.89s/it]\u001b[A\n",
            " 34% 13/38 [00:22<00:47,  1.90s/it]\u001b[A\n",
            " 37% 14/38 [00:24<00:45,  1.90s/it]\u001b[A\n",
            " 39% 15/38 [00:26<00:43,  1.91s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.91s/it]\u001b[A\n",
            " 45% 17/38 [00:30<00:40,  1.93s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.92s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.92s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.92s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:47<00:23,  1.93s/it]\u001b[A\n",
            " 71% 27/38 [00:49<00:21,  1.92s/it]\u001b[A\n",
            " 74% 28/38 [00:51<00:19,  1.92s/it]\u001b[A\n",
            " 76% 29/38 [00:53<00:17,  1.92s/it]\u001b[A\n",
            " 79% 30/38 [00:55<00:15,  1.92s/it]\u001b[A\n",
            " 82% 31/38 [00:57<00:13,  1.92s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.92s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.93s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.92s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.92s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.91s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.91s/it]\u001b[A\n",
            "100% 38/38 [01:10<00:00,  1.91s/it]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.9210608005523682, 'eval_runtime': 74.7303, 'eval_samples_per_second': 2.088, 'eval_steps_per_second': 1.044, 'epoch': 0.07}\n",
            "  4% 1/28 [02:07<23:33, 52.34s/it]\n",
            "39it [01:13,  1.90s/it]\u001b[A\n",
            "                       \u001b[A[2024-10-23 21:15:42,804] [INFO] [axolotl.callbacks.on_step_end:128] [PID:12555] [RANK:0] GPU memory usage while training: 2.392GB (+14.932GB cache, +0.566GB misc)\u001b[39m\n",
            "{'loss': 0.7833, 'grad_norm': 0.2108100801706314, 'learning_rate': 4e-05, 'epoch': 0.14}\n",
            "{'loss': 0.7999, 'grad_norm': 0.1993255764245987, 'learning_rate': 6e-05, 'epoch': 0.21}\n",
            "{'loss': 0.8231, 'grad_norm': 0.28567054867744446, 'learning_rate': 8e-05, 'epoch': 0.28}\n",
            " 14% 4/28 [04:45<26:55, 67.32s/it][2024-10-23 21:17:28,925] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:48,  1.38s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.59s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:56,  1.70s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.78s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.83s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.86s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.93s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.92s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.92s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.92s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.91s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.92s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:29<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:31<00:40,  1.94s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.93s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.93s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.94s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.93s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.94s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.93s/it]\u001b[A\n",
            " 79% 30/38 [00:56<00:15,  1.93s/it]\u001b[A\n",
            " 82% 31/38 [00:58<00:13,  1.94s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.94s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.95s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.94s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.94s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.94s/it]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.9139525294303894, 'eval_runtime': 75.4634, 'eval_samples_per_second': 2.067, 'eval_steps_per_second': 1.034, 'epoch': 0.28}\n",
            " 14% 4/28 [06:01<26:55, 67.32s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "{'loss': 0.6855, 'grad_norm': 0.2238488644361496, 'learning_rate': 0.0001, 'epoch': 0.35}\n",
            "{'loss': 0.9259, 'grad_norm': 0.248153418302536, 'learning_rate': 0.00012, 'epoch': 0.42}\n",
            "{'loss': 0.7668, 'grad_norm': 0.252511590719223, 'learning_rate': 0.00014, 'epoch': 0.49}\n",
            "{'loss': 0.779, 'grad_norm': 0.25402677059173584, 'learning_rate': 0.00016, 'epoch': 0.56}\n",
            " 29% 8/28 [09:33<21:22, 64.13s/it][2024-10-23 21:22:17,004] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:48,  1.37s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.58s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:56,  1.70s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.78s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.82s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.86s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.92s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.92s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.92s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.92s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.91s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.91s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:30<00:40,  1.94s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.93s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.92s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.94s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.93s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.94s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.93s/it]\u001b[A\n",
            " 79% 30/38 [00:56<00:15,  1.93s/it]\u001b[A\n",
            " 82% 31/38 [00:58<00:13,  1.94s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.94s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.96s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.94s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.94s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.94s/it]\u001b[A\n",
            "                                  \n",
            "\u001b[A{'eval_loss': 0.8034127354621887, 'eval_runtime': 75.4244, 'eval_samples_per_second': 2.068, 'eval_steps_per_second': 1.034, 'epoch': 0.56}\n",
            " 29% 8/28 [10:49<21:22, 64.13s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "{'loss': 0.5345, 'grad_norm': 0.1748448610305786, 'learning_rate': 0.00018, 'epoch': 0.63}\n",
            "{'loss': 0.5699, 'grad_norm': 0.18634748458862305, 'learning_rate': 0.0002, 'epoch': 0.7}\n",
            "{'loss': 0.5804, 'grad_norm': 0.21753615140914917, 'learning_rate': 0.00019848077530122083, 'epoch': 0.77}\n",
            "{'loss': 0.545, 'grad_norm': 0.23333732783794403, 'learning_rate': 0.00019396926207859084, 'epoch': 0.83}\n",
            " 43% 12/28 [14:21<16:53, 63.36s/it][2024-10-23 21:27:04,225] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:48,  1.37s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.58s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:55,  1.70s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.77s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.82s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.85s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.92s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.92s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.92s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.92s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.92s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.91s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:30<00:40,  1.94s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.93s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.92s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.94s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.93s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.93s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.92s/it]\u001b[A\n",
            " 79% 30/38 [00:55<00:15,  1.92s/it]\u001b[A\n",
            " 82% 31/38 [00:57<00:13,  1.93s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.93s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.95s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.93s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.93s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.93s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.648797869682312, 'eval_runtime': 75.308, 'eval_samples_per_second': 2.071, 'eval_steps_per_second': 1.036, 'epoch': 0.83}\n",
            " 43% 12/28 [15:36<16:53, 63.36s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "{'loss': 0.4392, 'grad_norm': 0.20313376188278198, 'learning_rate': 0.00018660254037844388, 'epoch': 0.9}\n",
            "{'loss': 0.38, 'grad_norm': 0.20026056468486786, 'learning_rate': 0.0001766044443118978, 'epoch': 0.97}\n",
            " 50% 14/28 [17:22<17:16, 74.00s/it]/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:689: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-67196add-58b43eb92950508b2663bf0f;5d4031f3-15de-4f6f-9bd6-ce031558de7c)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-3B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:243: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "{'loss': 0.3177, 'grad_norm': 0.153587207198143, 'learning_rate': 0.00016427876096865394, 'epoch': 1.03}\n",
            "{'loss': 0.3712, 'grad_norm': 0.16564497351646423, 'learning_rate': 0.00015000000000000001, 'epoch': 1.1}\n",
            " 57% 16/28 [19:06<12:34, 62.91s/it][2024-10-23 21:31:49,880] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:47,  1.37s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.58s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:55,  1.69s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.77s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.82s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.86s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.92s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.92s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.92s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.92s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.92s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.91s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:31<00:41,  1.96s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.94s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.93s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.93s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.93s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.93s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.93s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:27,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.97s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.95s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.94s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.94s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.93s/it]\u001b[A\n",
            " 79% 30/38 [00:56<00:15,  1.93s/it]\u001b[A\n",
            " 82% 31/38 [00:58<00:13,  1.93s/it]\u001b[A\n",
            " 84% 32/38 [01:00<00:11,  1.94s/it]\u001b[A\n",
            " 87% 33/38 [01:02<00:09,  1.95s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.93s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.93s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.93s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5825337767601013, 'eval_runtime': 75.4662, 'eval_samples_per_second': 2.067, 'eval_steps_per_second': 1.034, 'epoch': 1.1}\n",
            " 57% 16/28 [20:22<12:34, 62.91s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "{'loss': 0.3357, 'grad_norm': 0.1881798803806305, 'learning_rate': 0.00013420201433256689, 'epoch': 1.17}\n",
            "{'loss': 0.3875, 'grad_norm': 0.21584919095039368, 'learning_rate': 0.00011736481776669306, 'epoch': 1.24}\n",
            "{'loss': 0.287, 'grad_norm': 0.1652679145336151, 'learning_rate': 0.0001, 'epoch': 1.31}\n",
            "{'loss': 0.336, 'grad_norm': 0.1664346307516098, 'learning_rate': 8.263518223330697e-05, 'epoch': 1.38}\n",
            " 71% 20/28 [23:54<08:25, 63.22s/it][2024-10-23 21:36:37,756] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:47,  1.37s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.58s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:55,  1.69s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.77s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.82s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.85s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.92s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.91s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.91s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.92s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.91s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.91s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:30<00:40,  1.94s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.93s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.92s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.94s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.93s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.93s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.93s/it]\u001b[A\n",
            " 79% 30/38 [00:56<00:15,  1.93s/it]\u001b[A\n",
            " 82% 31/38 [00:57<00:13,  1.94s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.94s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.95s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.93s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.93s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.93s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5491526126861572, 'eval_runtime': 75.3653, 'eval_samples_per_second': 2.07, 'eval_steps_per_second': 1.035, 'epoch': 1.38}\n",
            " 71% 20/28 [25:09<08:25, 63.22s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "{'loss': 0.2959, 'grad_norm': 0.15922914445400238, 'learning_rate': 6.579798566743314e-05, 'epoch': 1.45}\n",
            "{'loss': 0.2983, 'grad_norm': 0.14202940464019775, 'learning_rate': 5.000000000000002e-05, 'epoch': 1.52}\n",
            "{'loss': 0.247, 'grad_norm': 0.1265108287334442, 'learning_rate': 3.5721239031346066e-05, 'epoch': 1.59}\n",
            "{'loss': 0.3231, 'grad_norm': 0.15941433608531952, 'learning_rate': 2.339555568810221e-05, 'epoch': 1.66}\n",
            " 86% 24/28 [28:42<04:13, 63.30s/it][2024-10-23 21:41:25,732] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:48,  1.37s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.58s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:55,  1.69s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.77s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.82s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.85s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.92s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.91s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.92s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.91s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.91s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.91s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:30<00:40,  1.94s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.93s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.93s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.94s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.93s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.93s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.93s/it]\u001b[A\n",
            " 79% 30/38 [00:55<00:15,  1.93s/it]\u001b[A\n",
            " 82% 31/38 [00:57<00:13,  1.93s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.93s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.95s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.93s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.93s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.93s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.537909984588623, 'eval_runtime': 75.2911, 'eval_samples_per_second': 2.072, 'eval_steps_per_second': 1.036, 'epoch': 1.66}\n",
            " 86% 24/28 [29:57<04:13, 63.30s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "{'loss': 0.311, 'grad_norm': 0.1614454984664917, 'learning_rate': 1.339745962155613e-05, 'epoch': 1.73}\n",
            "{'loss': 0.2731, 'grad_norm': 0.13931332528591156, 'learning_rate': 6.030737921409169e-06, 'epoch': 1.8}\n",
            "{'loss': 0.2874, 'grad_norm': 0.15171031653881073, 'learning_rate': 1.5192246987791981e-06, 'epoch': 1.87}\n",
            "{'loss': 0.2729, 'grad_norm': 0.14994187653064728, 'learning_rate': 0.0, 'epoch': 1.94}\n",
            "100% 28/28 [33:30<00:00, 63.39s/it][2024-10-23 21:46:13,942] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:197] [PID:12555] [RANK:0] gather_len_batches: [39]\u001b[39m\n",
            "\n",
            "  0% 0/38 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/38 [00:01<00:34,  1.03it/s]\u001b[A\n",
            "  8% 3/38 [00:03<00:48,  1.37s/it]\u001b[A\n",
            " 11% 4/38 [00:05<00:53,  1.58s/it]\u001b[A\n",
            " 13% 5/38 [00:07<00:55,  1.70s/it]\u001b[A\n",
            " 16% 6/38 [00:09<00:56,  1.77s/it]\u001b[A\n",
            " 18% 7/38 [00:11<00:56,  1.82s/it]\u001b[A\n",
            " 21% 8/38 [00:13<00:55,  1.86s/it]\u001b[A\n",
            " 24% 9/38 [00:15<00:55,  1.92s/it]\u001b[A\n",
            " 26% 10/38 [00:17<00:53,  1.92s/it]\u001b[A\n",
            " 29% 11/38 [00:19<00:51,  1.92s/it]\u001b[A\n",
            " 32% 12/38 [00:21<00:49,  1.92s/it]\u001b[A\n",
            " 34% 13/38 [00:23<00:47,  1.91s/it]\u001b[A\n",
            " 37% 14/38 [00:25<00:45,  1.91s/it]\u001b[A\n",
            " 39% 15/38 [00:27<00:44,  1.92s/it]\u001b[A\n",
            " 42% 16/38 [00:28<00:42,  1.92s/it]\u001b[A\n",
            " 45% 17/38 [00:30<00:40,  1.94s/it]\u001b[A\n",
            " 47% 18/38 [00:32<00:38,  1.93s/it]\u001b[A\n",
            " 50% 19/38 [00:34<00:36,  1.92s/it]\u001b[A\n",
            " 53% 20/38 [00:36<00:34,  1.93s/it]\u001b[A\n",
            " 55% 21/38 [00:38<00:32,  1.92s/it]\u001b[A\n",
            " 58% 22/38 [00:40<00:30,  1.92s/it]\u001b[A\n",
            " 61% 23/38 [00:42<00:28,  1.92s/it]\u001b[A\n",
            " 63% 24/38 [00:44<00:26,  1.93s/it]\u001b[A\n",
            " 66% 25/38 [00:46<00:25,  1.95s/it]\u001b[A\n",
            " 68% 26/38 [00:48<00:23,  1.94s/it]\u001b[A\n",
            " 71% 27/38 [00:50<00:21,  1.93s/it]\u001b[A\n",
            " 74% 28/38 [00:52<00:19,  1.93s/it]\u001b[A\n",
            " 76% 29/38 [00:54<00:17,  1.93s/it]\u001b[A\n",
            " 79% 30/38 [00:56<00:15,  1.93s/it]\u001b[A\n",
            " 82% 31/38 [00:57<00:13,  1.93s/it]\u001b[A\n",
            " 84% 32/38 [00:59<00:11,  1.93s/it]\u001b[A\n",
            " 87% 33/38 [01:01<00:09,  1.95s/it]\u001b[A\n",
            " 89% 34/38 [01:03<00:07,  1.94s/it]\u001b[A\n",
            " 92% 35/38 [01:05<00:05,  1.93s/it]\u001b[A\n",
            " 95% 36/38 [01:07<00:03,  1.93s/it]\u001b[A\n",
            " 97% 37/38 [01:09<00:01,  1.93s/it]\u001b[A\n",
            "100% 38/38 [01:11<00:00,  1.93s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5353411436080933, 'eval_runtime': 75.3284, 'eval_samples_per_second': 2.071, 'eval_steps_per_second': 1.035, 'epoch': 1.94}\n",
            "100% 28/28 [34:46<00:00, 63.39s/it]\n",
            "39it [01:13,  1.92s/it]\u001b[A\n",
            "                       \u001b[A/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:689: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-67196ef1-69304ca401df651e7d69123e;3b1a6cf7-2c2d-4578-8292-da4df9e1a69f)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-3B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:243: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "{'train_runtime': 2087.3794, 'train_samples_per_second': 0.439, 'train_steps_per_second': 0.013, 'train_loss': 0.4970744305423328, 'epoch': 1.94}\n",
            "100% 28/28 [34:47<00:00, 74.55s/it]\n",
            "[2024-10-23 21:47:30,541] [INFO] [axolotl.train.train:195] [PID:12555] [RANK:0] Training Completed!!! Saving pre-trained model to ./model-out\u001b[39m\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:689: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-67196ef2-22663e9814e08d2b55889782;b5c2b7e8-2884-48e4-949b-a564bebeec0b)\n",
            "\n",
            "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-3B/resolve/main/config.json.\n",
            "Access to model meta-llama/Llama-3.2-3B is restricted. You must have access to it and be authenticated to access it. Please log in. - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:243: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B - will assume that the vocabulary was not modified.\n",
            "  warnings.warn(\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# By using the ! the comand will be executed as a bash command\n",
        "!accelerate launch -m axolotl.cli.train /content/axolotl.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge weights\n",
        "\n",
        "In this cell, we will merge the LoRA weights with the original model."
      ],
      "metadata": {
        "id": "ERoc4N_oUA4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m axolotl.cli.merge_lora axolotl.yaml"
      ],
      "metadata": {
        "id": "wHlICPMmPzs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972d9d11-1cd9-46a6-b33b-57ff5d0b82fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-23 21:52:08.416630: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-23 21:52:08.436161: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-23 21:52:08.457415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-23 21:52:08.463888: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-23 21:52:08.479464: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-23 21:52:09.520985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:29: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, forward_function, hidden_states, *args):\n",
            "/content/axolotl/src/axolotl/utils/gradient_checkpointing/unsloth.py:40: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dY):\n",
            "[2024-10-23 21:52:12,332] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-10-23 21:52:12,411] [INFO] [root.spawn:60] [PID:22825] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpzye1jzot/test.c -o /tmp/tmpzye1jzot/test.o\n",
            "[2024-10-23 21:52:12,430] [INFO] [root.spawn:60] [PID:22825] x86_64-linux-gnu-gcc /tmp/tmpzye1jzot/test.o -laio -o /tmp/tmpzye1jzot/a.out\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.4\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (3.0.0), only 1.0.0 is known to be compatible\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, weight, bias=None):\n",
            "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/content/axolotl/src/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "\u001b[33m[2024-10-23 21:52:15,379] [WARNING] [axolotl.utils.config.models.input.check_sample_packing_wo_flash:838] [PID:22825] [RANK:0] sample_packing without flash_attention or sdp_attention does not handle cross-attention.\u001b[39m\n",
            "[2024-10-23 21:52:15,381] [DEBUG] [axolotl.normalize_config:83] [PID:22825] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "[2024-10-23 21:52:15,620] [INFO] [axolotl.normalize_config:207] [PID:22825] [RANK:0] GPU memory usage baseline: 0.000GB (+0.331GB misc)\u001b[39m\n",
            "[2024-10-23 21:52:15,621] [INFO] [axolotl.normalize_cfg_datasets:219] [PID:22825] [RANK:0] updating dataset data/train.jsonl with `conversation: llama3` to match your chat_template\u001b[39m\n",
            "[2024-10-23 21:52:15,621] [INFO] [axolotl.common.cli.load_model_and_tokenizer:51] [PID:22825] [RANK:0] loading tokenizer... meta-llama/Llama-3.2-3B\u001b[39m\n",
            "[2024-10-23 21:52:16,578] [DEBUG] [axolotl.load_tokenizer:290] [PID:22825] [RANK:0] EOS: 128009 / <|eot_id|>\u001b[39m\n",
            "[2024-10-23 21:52:16,578] [DEBUG] [axolotl.load_tokenizer:291] [PID:22825] [RANK:0] BOS: 128000 / <|begin_of_text|>\u001b[39m\n",
            "[2024-10-23 21:52:16,578] [DEBUG] [axolotl.load_tokenizer:292] [PID:22825] [RANK:0] PAD: 128004 / <|finetune_right_pad_id|>\u001b[39m\n",
            "[2024-10-23 21:52:16,578] [DEBUG] [axolotl.load_tokenizer:293] [PID:22825] [RANK:0] UNK: None / None\u001b[39m\n",
            "[2024-10-23 21:52:16,578] [INFO] [axolotl.common.cli.load_model_and_tokenizer:53] [PID:22825] [RANK:0] loading model and (optionally) peft_config...\u001b[39m\n",
            "[2024-10-23 21:52:16,807] [INFO] [axolotl.load_model:469] [PID:22825] [RANK:0] patching llama _prepare_4d_causal_attention_mask*\u001b[39m\n",
            "[2024-10-23 21:52:16,968] [INFO] [accelerate.utils.modeling.get_balanced_memory:1014] [PID:22825] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.34s/it]\n",
            "[2024-10-23 21:52:19,970] [INFO] [axolotl.load_model:855] [PID:22825] [RANK:0] GPU memory usage after model load: 5.985GB (+0.045GB cache, +0.513GB misc)\u001b[39m\n",
            "[2024-10-23 21:52:19,989] [INFO] [axolotl.load_model:922] [PID:22825] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
            "[2024-10-23 21:52:19,993] [INFO] [axolotl.load_lora:1087] [PID:22825] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
            "[2024-10-23 21:52:19,993] [DEBUG] [axolotl.load_lora:1135] [PID:22825] [RANK:0] Loading pretrained PEFT - LoRA\u001b[39m\n",
            "trainable params: 48,627,712 || all params: 3,261,377,536 || trainable%: 1.4910\n",
            "[2024-10-23 21:52:21,103] [INFO] [axolotl.load_model:970] [PID:22825] [RANK:0] GPU memory usage after adapters: 6.166GB (+1.709GB cache, +0.542GB misc)\u001b[39m\n",
            "[2024-10-23 21:52:22,271] [INFO] [axolotl.scripts.do_merge_lora:168] [PID:22825] [RANK:0] running merge of LoRA with base model\u001b[39m\n",
            "Unloading and merging model: 100% 595/595 [00:00<00:00, 4202.68it/s]\n",
            "[2024-10-23 21:52:22,420] [INFO] [axolotl.scripts.do_merge_lora:177] [PID:22825] [RANK:0] saving merged model to: model-out/merged\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export to .gguf\n",
        "\n",
        "We have decided we want to run this model with `ollama`, so we need to export to `.gguf`.\n",
        "Thankfully, `llama.cpp` comes with a handy script that helps us export our ðŸ¤— `transformers` - style model to `.gguf`."
      ],
      "metadata": {
        "id": "LDPWrxZlUFFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to .gguf\n",
        "!python llama.cpp/convert_hf_to_gguf.py /content/model-out/merged \\\n",
        "  --outfile /content/model-out/customer-service-agent-merged.gguf \\\n",
        "  --outtype q8_0"
      ],
      "metadata": {
        "id": "b2epaeMpuD67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca9d64f-9573-4a72-8a3a-d488d8dda605"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:hf-to-gguf:Loading model: merged\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> Q8_0, shape = {3072, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> Q8_0, shape = {3072, 128256}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> Q8_0, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> Q8_0, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> Q8_0, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 24\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 7\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128004\n",
            "INFO:gguf.vocab:Setting chat_template to {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}{% endif %}\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/model-out/customer-service-agent-merged.gguf: n_tensors = 256, total_size = 3.8G\n",
            "Writing: 100% 3.83G/3.83G [00:47<00:00, 80.1Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/model-out/customer-service-agent-merged.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload to ðŸ¤—\n",
        "\n",
        "Our final step is to upload the model to Huggingface.\n",
        "Make sure you have the `HF_TOKEN` environment variable set, then run the next several cells.\n",
        "Make sure to populate your hf.co username and the name of the repo you want to upload to.\n",
        "This will upload the merged file and the `.gguf` file."
      ],
      "metadata": {
        "id": "eKMILeuZUJWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token $HF_TOKEN --add-to-git-credential"
      ],
      "metadata": {
        "id": "VFwW8nIDWjS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edbf243-e907-460d-b009-6b64e0798f12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "username = 'mgfrantz'\n",
        "repo_name = 'cmte-demo'\n",
        "if not username or not repo_name:\n",
        "    username = input(\"Username: \")\n",
        "    repo_name = input(\"Repo name: \")\n",
        "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
        "!huggingface-cli upload {username}/{repo_name} /content/model-out/ ."
      ],
      "metadata": {
        "id": "eBROYTQ2V98K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daae004-1c05-44b5-da62-15ed7c2f0d55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/18 [00:00<?, ?it/s]\n",
            "adapter_model.bin:   0% 0.00/195M [00:00<?, ?B/s]\u001b[A\n",
            "adapter_model.bin:   8% 16.0M/195M [00:00<00:10, 17.4MB/s]\u001b[A\n",
            "adapter_model.bin:  16% 32.0M/195M [00:01<00:07, 20.8MB/s]\u001b[A\n",
            "adapter_model.bin:  25% 48.0M/195M [00:02<00:06, 23.3MB/s]\u001b[A\n",
            "adapter_model.bin:  66% 128M/195M [00:02<00:00, 85.6MB/s] \u001b[A\n",
            "adapter_model.bin:  90% 176M/195M [00:02<00:00, 127MB/s] \u001b[A\n",
            "adapter_model.bin: 208MB [00:07, 29.3MB/s]\n",
            "  6% 1/18 [00:07<02:06,  7.44s/it]\n",
            "checkpoint-14/adapter_model.safetensors:   0% 0.00/195M [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-14/adapter_model.safetensors:   8% 16.0M/195M [00:01<00:18, 9.83MB/s]\u001b[A\n",
            "checkpoint-14/adapter_model.safetensors:  16% 32.0M/195M [00:02<00:10, 15.3MB/s]\u001b[A\n",
            "checkpoint-14/adapter_model.safetensors:  33% 64.0M/195M [00:02<00:03, 36.4MB/s]\u001b[A\n",
            "checkpoint-14/adapter_model.safetensors: 208MB [00:02, 70.9MB/s]              \n",
            " 11% 2/18 [00:10<01:20,  5.05s/it]\n",
            "checkpoint-14/optimizer.pt:   0% 0.00/99.2M [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-14/optimizer.pt:  16% 16.0M/99.2M [00:01<00:09, 8.74MB/s]\u001b[A\n",
            "checkpoint-14/optimizer.pt:  32% 32.0M/99.2M [00:01<00:03, 19.7MB/s]\u001b[A\n",
            "checkpoint-14/optimizer.pt:  48% 48.0M/99.2M [00:02<00:01, 30.4MB/s]\u001b[A\n",
            "checkpoint-14/optimizer.pt:  81% 80.0M/99.2M [00:02<00:00, 48.4MB/s]\u001b[A\n",
            "checkpoint-14/optimizer.pt: 112MB [00:02, 38.2MB/s]                 \n",
            " 17% 3/18 [00:14<01:03,  4.23s/it]\n",
            "checkpoint-14/rng_state.pth:   0% 0.00/14.2k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-14/rng_state.pth: 16.0MB [00:00, 41.9MB/s]\n",
            " 22% 4/18 [00:14<00:39,  2.85s/it]\n",
            "checkpoint-14/scheduler.pt:   0% 0.00/1.06k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-14/scheduler.pt: 16.0MB [00:00, 54.5MB/s]\n",
            " 28% 5/18 [00:15<00:27,  2.09s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:02<00:00, 7.62MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:02, 11.0MB/s]\n",
            " 33% 6/18 [00:18<00:29,  2.49s/it]\n",
            "checkpoint-28/training_args.bin:   0% 0.00/6.65k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-28/training_args.bin: 16.0MB [00:00, 53.3MB/s]\n",
            " 39% 7/18 [00:19<00:20,  1.89s/it]\n",
            "checkpoint-28/adapter_model.safetensors:   0% 0.00/195M [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-28/adapter_model.safetensors:   8% 16.0M/195M [00:01<00:17, 10.3MB/s]\u001b[A\n",
            "checkpoint-28/adapter_model.safetensors:  16% 32.0M/195M [00:02<00:09, 17.0MB/s]\u001b[A\n",
            "checkpoint-28/adapter_model.safetensors:  41% 80.0M/195M [00:02<00:02, 53.5MB/s]\u001b[A\n",
            "checkpoint-28/adapter_model.safetensors:  58% 112M/195M [00:02<00:01, 78.7MB/s] \u001b[A\n",
            "checkpoint-28/adapter_model.safetensors: 208MB [00:02, 72.5MB/s]\n",
            " 44% 8/18 [00:22<00:23,  2.32s/it]\n",
            "checkpoint-28/optimizer.pt:   0% 0.00/99.2M [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-28/optimizer.pt:  16% 16.0M/99.2M [00:01<00:09, 9.17MB/s]\u001b[A\n",
            "checkpoint-28/optimizer.pt:  32% 32.0M/99.2M [00:02<00:03, 18.1MB/s]\u001b[A\n",
            "checkpoint-28/optimizer.pt: 112MB [00:02, 51.1MB/s]\n",
            " 50% 9/18 [00:25<00:21,  2.39s/it]\n",
            "checkpoint-28/rng_state.pth:   0% 0.00/14.2k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-28/rng_state.pth: 16.0MB [00:00, 51.2MB/s]\n",
            " 56% 10/18 [00:26<00:15,  1.88s/it]\n",
            "checkpoint-28/scheduler.pt:   0% 0.00/1.06k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-28/scheduler.pt: 16.0MB [00:00, 55.8MB/s]\n",
            " 61% 11/18 [00:26<00:10,  1.51s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:01<00:00, 11.1MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:02, 14.6MB/s]\n",
            " 67% 12/18 [00:29<00:10,  1.82s/it]\n",
            "checkpoint-28/training_args.bin:   0% 0.00/6.65k [00:00<?, ?B/s]\u001b[A\n",
            "checkpoint-28/training_args.bin: 16.0MB [00:00, 46.8MB/s]\n",
            " 72% 13/18 [00:29<00:07,  1.48s/it]\n",
            "customer-service-agent-merged.gguf:   0% 0.00/3.84G [00:00<?, ?B/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   0% 16.0M/3.84G [00:06<24:32, 2.60MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   1% 32.0M/3.84G [00:08<16:16, 3.90MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   1% 48.0M/3.84G [00:09<09:29, 6.66MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   2% 80.0M/3.84G [00:10<05:40, 11.1MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   2% 96.0M/3.84G [00:11<04:31, 13.8MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   3% 112M/3.84G [00:11<03:46, 16.5MB/s] \u001b[A\n",
            "customer-service-agent-merged.gguf:   4% 144M/3.84G [00:11<02:15, 27.3MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   4% 160M/3.84G [00:11<01:47, 34.1MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   5% 176M/3.84G [00:12<01:57, 31.1MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   5% 208M/3.84G [00:13<01:35, 38.0MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   6% 224M/3.84G [00:13<01:44, 34.6MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   6% 240M/3.84G [00:13<01:28, 40.9MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   7% 256M/3.84G [00:14<01:18, 45.5MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   7% 272M/3.84G [00:14<01:11, 50.2MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   7% 288M/3.84G [00:14<00:57, 62.0MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   8% 304M/3.84G [00:14<00:50, 69.6MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   8% 320M/3.84G [00:15<01:01, 57.3MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   9% 336M/3.84G [00:15<00:56, 62.2MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:   9% 352M/3.84G [00:15<00:46, 75.6MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  10% 368M/3.84G [00:15<00:56, 61.7MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  10% 400M/3.84G [00:15<00:39, 86.4MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  11% 432M/3.84G [00:16<00:28, 118MB/s] \u001b[A\n",
            "customer-service-agent-merged.gguf:  13% 496M/3.84G [00:16<00:19, 175MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  14% 528M/3.84G [00:16<00:20, 163MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  15% 560M/3.84G [00:16<00:21, 151MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  15% 592M/3.84G [00:16<00:20, 157MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  17% 640M/3.84G [00:17<00:16, 197MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  17% 672M/3.84G [00:17<00:16, 193MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  18% 704M/3.84G [00:17<00:19, 158MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  19% 736M/3.84G [00:17<00:21, 141MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  20% 768M/3.84G [00:17<00:18, 166MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  21% 800M/3.84G [00:18<00:19, 158MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  22% 832M/3.84G [00:18<00:17, 176MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  23% 880M/3.84G [00:18<00:13, 222MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  24% 928M/3.84G [00:18<00:11, 260MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  25% 960M/3.84G [00:18<00:11, 253MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  27% 1.04G/3.84G [00:18<00:07, 351MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  29% 1.12G/3.84G [00:18<00:06, 438MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  30% 1.17G/3.84G [00:19<00:06, 432MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  32% 1.23G/3.84G [00:19<00:06, 402MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  35% 1.34G/3.84G [00:19<00:04, 504MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  37% 1.41G/3.84G [00:19<00:04, 524MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  38% 1.47G/3.84G [00:19<00:05, 417MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  40% 1.52G/3.84G [00:20<00:06, 336MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  41% 1.57G/3.84G [00:20<00:06, 353MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  42% 1.62G/3.84G [00:20<00:06, 370MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  43% 1.66G/3.84G [00:20<00:07, 303MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  45% 1.71G/3.84G [00:20<00:08, 263MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  45% 1.74G/3.84G [00:20<00:08, 244MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  47% 1.79G/3.84G [00:21<00:07, 258MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  48% 1.84G/3.84G [00:21<00:07, 275MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  49% 1.87G/3.84G [00:21<00:12, 153MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  50% 1.90G/3.84G [00:21<00:12, 158MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  50% 1.94G/3.84G [00:22<00:14, 135MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  52% 1.98G/3.84G [00:22<00:10, 169MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  52% 2.02G/3.84G [00:22<00:09, 184MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  53% 2.05G/3.84G [00:22<00:11, 162MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  55% 2.10G/3.84G [00:22<00:08, 199MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  55% 2.13G/3.84G [00:23<00:12, 142MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  56% 2.16G/3.84G [00:23<00:10, 161MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  57% 2.19G/3.84G [00:23<00:14, 114MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  58% 2.22G/3.84G [00:24<00:12, 127MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  59% 2.26G/3.84G [00:24<00:18, 85.5MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  60% 2.29G/3.84G [00:25<00:16, 96.9MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  60% 2.30G/3.84G [00:26<00:43, 35.0MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  60% 2.32G/3.84G [00:27<00:39, 38.4MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  61% 2.34G/3.84G [00:27<00:38, 38.6MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  62% 2.37G/3.84G [00:27<00:28, 51.8MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  62% 2.38G/3.84G [00:27<00:24, 60.2MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  62% 2.40G/3.84G [00:28<00:30, 47.3MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  63% 2.42G/3.84G [00:28<00:27, 51.0MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  63% 2.43G/3.84G [00:29<00:31, 44.2MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  64% 2.45G/3.84G [00:29<00:26, 51.6MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  64% 2.46G/3.84G [00:29<00:23, 59.6MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  65% 2.51G/3.84G [00:29<00:14, 92.7MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  67% 2.58G/3.84G [00:30<00:09, 134MB/s] \u001b[A\n",
            "customer-service-agent-merged.gguf:  67% 2.59G/3.84G [00:30<00:12, 98.3MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  68% 2.62G/3.84G [00:30<00:13, 91.2MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  70% 2.67G/3.84G [00:31<00:08, 133MB/s] \u001b[A\n",
            "customer-service-agent-merged.gguf:  71% 2.72G/3.84G [00:31<00:06, 164MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  72% 2.75G/3.84G [00:31<00:06, 157MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  73% 2.82G/3.84G [00:31<00:04, 225MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  74% 2.85G/3.84G [00:31<00:04, 222MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  75% 2.90G/3.84G [00:31<00:03, 252MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  76% 2.93G/3.84G [00:32<00:03, 240MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  78% 3.01G/3.84G [00:32<00:02, 327MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  81% 3.12G/3.84G [00:32<00:01, 443MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  84% 3.23G/3.84G [00:32<00:01, 578MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  86% 3.31G/3.84G [00:32<00:01, 522MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  90% 3.47G/3.84G [00:32<00:00, 670MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  92% 3.55G/3.84G [00:32<00:00, 682MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf:  97% 3.74G/3.84G [00:33<00:00, 929MB/s]\u001b[A\n",
            "customer-service-agent-merged.gguf: 3.86GB [00:33, 116MB/s]\n",
            " 78% 14/18 [01:03<00:44, 11.20s/it]\n",
            "merged/pytorch_model-00001-of-00002.bin:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   0% 16.0M/4.97G [00:05<30:06, 2.74MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   1% 32.0M/4.97G [00:08<21:25, 3.84MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   1% 48.0M/4.97G [00:09<13:10, 6.22MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   1% 64.0M/4.97G [00:09<08:20, 9.79MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   2% 80.0M/4.97G [00:10<06:17, 12.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   2% 96.0M/4.97G [00:10<04:38, 17.5MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   2% 112M/4.97G [00:10<03:17, 24.6MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   3% 128M/4.97G [00:10<02:27, 32.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   3% 144M/4.97G [00:11<02:41, 29.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   3% 160M/4.97G [00:12<02:47, 28.6MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   4% 176M/4.97G [00:12<02:13, 35.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   4% 192M/4.97G [00:12<02:38, 30.1MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   4% 208M/4.97G [00:13<02:44, 29.0MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   5% 224M/4.97G [00:13<02:15, 35.0MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   5% 256M/4.97G [00:13<01:21, 57.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   5% 272M/4.97G [00:14<01:13, 63.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   6% 288M/4.97G [00:14<01:08, 67.8MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   6% 320M/4.97G [00:14<00:52, 87.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   7% 352M/4.97G [00:14<00:38, 121MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   8% 400M/4.97G [00:14<00:28, 158MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:   9% 464M/4.97G [00:15<00:25, 175MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  11% 528M/4.97G [00:15<00:19, 228MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  11% 560M/4.97G [00:15<00:19, 225MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  12% 592M/4.97G [00:15<00:20, 217MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  13% 656M/4.97G [00:15<00:19, 222MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  14% 688M/4.97G [00:15<00:18, 233MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  14% 720M/4.97G [00:16<00:19, 216MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  15% 752M/4.97G [00:16<00:18, 230MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  16% 784M/4.97G [00:16<00:25, 167MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  17% 832M/4.97G [00:16<00:19, 214MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  17% 864M/4.97G [00:16<00:23, 176MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  18% 896M/4.97G [00:17<00:26, 153MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  20% 992M/4.97G [00:17<00:15, 262MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  21% 1.04G/4.97G [00:17<00:17, 229MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  22% 1.09G/4.97G [00:17<00:15, 243MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  23% 1.12G/4.97G [00:17<00:15, 250MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  23% 1.15G/4.97G [00:18<00:14, 256MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  24% 1.18G/4.97G [00:18<00:17, 216MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  25% 1.23G/4.97G [00:18<00:21, 174MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  26% 1.28G/4.97G [00:19<00:23, 156MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  26% 1.31G/4.97G [00:19<00:21, 168MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  27% 1.34G/4.97G [00:19<00:27, 130MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  28% 1.38G/4.97G [00:19<00:24, 146MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  28% 1.41G/4.97G [00:20<00:36, 97.2MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  29% 1.42G/4.97G [00:20<00:36, 98.2MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  29% 1.46G/4.97G [00:20<00:32, 109MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  30% 1.47G/4.97G [00:21<00:36, 94.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  30% 1.50G/4.97G [00:21<00:29, 119MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  31% 1.55G/4.97G [00:21<00:22, 151MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  32% 1.60G/4.97G [00:21<00:17, 194MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  33% 1.65G/4.97G [00:21<00:15, 212MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  34% 1.70G/4.97G [00:21<00:12, 253MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  35% 1.73G/4.97G [00:22<00:17, 181MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  35% 1.76G/4.97G [00:22<00:19, 164MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  37% 1.82G/4.97G [00:22<00:15, 205MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  37% 1.86G/4.97G [00:22<00:16, 194MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  38% 1.89G/4.97G [00:22<00:14, 214MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  39% 1.92G/4.97G [00:23<00:17, 173MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  39% 1.95G/4.97G [00:23<00:18, 166MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  40% 1.98G/4.97G [00:24<00:40, 73.4MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  41% 2.02G/4.97G [00:24<00:40, 72.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  41% 2.05G/4.97G [00:25<00:36, 79.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  42% 2.06G/4.97G [00:25<00:40, 71.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  42% 2.08G/4.97G [00:25<00:46, 61.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  43% 2.11G/4.97G [00:26<00:40, 70.9MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  43% 2.13G/4.97G [00:26<00:37, 76.2MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  43% 2.14G/4.97G [00:27<00:54, 51.5MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  43% 2.16G/4.97G [00:27<00:50, 55.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  44% 2.21G/4.97G [00:27<00:28, 97.3MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  45% 2.24G/4.97G [00:27<00:24, 110MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  45% 2.26G/4.97G [00:28<00:45, 60.0MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  46% 2.27G/4.97G [00:28<00:44, 60.1MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  46% 2.30G/4.97G [00:28<00:32, 81.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  47% 2.34G/4.97G [00:29<00:25, 101MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  48% 2.38G/4.97G [00:29<00:20, 125MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  48% 2.40G/4.97G [00:29<00:20, 127MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  49% 2.45G/4.97G [00:29<00:13, 183MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  50% 2.48G/4.97G [00:30<00:22, 110MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  51% 2.51G/4.97G [00:30<00:32, 75.1MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  51% 2.53G/4.97G [00:31<00:33, 72.2MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  51% 2.54G/4.97G [00:31<00:32, 75.5MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  52% 2.56G/4.97G [00:31<00:32, 74.6MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  52% 2.58G/4.97G [00:31<00:39, 60.2MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  53% 2.61G/4.97G [00:32<00:31, 74.4MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  53% 2.62G/4.97G [00:32<00:33, 69.7MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  54% 2.67G/4.97G [00:32<00:20, 114MB/s] \u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  54% 2.70G/4.97G [00:32<00:16, 137MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  55% 2.74G/4.97G [00:32<00:13, 162MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  56% 2.80G/4.97G [00:33<00:15, 140MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  57% 2.83G/4.97G [00:33<00:13, 155MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  58% 2.86G/4.97G [00:33<00:12, 172MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  59% 2.91G/4.97G [00:33<00:10, 196MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  60% 2.96G/4.97G [00:34<00:09, 210MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  60% 2.99G/4.97G [00:34<00:11, 168MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  61% 3.02G/4.97G [00:34<00:13, 146MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  62% 3.06G/4.97G [00:34<00:13, 142MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  63% 3.10G/4.97G [00:35<00:10, 184MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  63% 3.15G/4.97G [00:35<00:10, 179MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  64% 3.18G/4.97G [00:35<00:09, 194MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  65% 3.22G/4.97G [00:35<00:11, 154MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  65% 3.25G/4.97G [00:36<00:11, 143MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  67% 3.31G/4.97G [00:36<00:08, 199MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  67% 3.34G/4.97G [00:36<00:09, 170MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  68% 3.38G/4.97G [00:36<00:12, 123MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  69% 3.42G/4.97G [00:37<00:09, 158MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  70% 3.47G/4.97G [00:37<00:08, 183MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  71% 3.50G/4.97G [00:37<00:07, 198MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  72% 3.55G/4.97G [00:37<00:06, 230MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  72% 3.58G/4.97G [00:37<00:07, 178MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  73% 3.63G/4.97G [00:37<00:06, 215MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  74% 3.66G/4.97G [00:38<00:07, 180MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  75% 3.71G/4.97G [00:38<00:06, 200MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  75% 3.74G/4.97G [00:38<00:05, 214MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  76% 3.78G/4.97G [00:38<00:05, 221MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  77% 3.81G/4.97G [00:38<00:05, 203MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  77% 3.84G/4.97G [00:39<00:07, 153MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  78% 3.87G/4.97G [00:39<00:07, 149MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  79% 3.90G/4.97G [00:39<00:08, 124MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  79% 3.94G/4.97G [00:39<00:07, 139MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  81% 4.00G/4.97G [00:40<00:04, 203MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  81% 4.03G/4.97G [00:40<00:04, 202MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  82% 4.08G/4.97G [00:40<00:03, 247MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  83% 4.11G/4.97G [00:40<00:03, 249MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  84% 4.16G/4.97G [00:40<00:03, 268MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  84% 4.19G/4.97G [00:40<00:03, 230MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  85% 4.22G/4.97G [00:41<00:03, 207MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  86% 4.29G/4.97G [00:41<00:02, 276MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  87% 4.32G/4.97G [00:41<00:02, 246MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  89% 4.40G/4.97G [00:41<00:01, 322MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  90% 4.45G/4.97G [00:41<00:01, 285MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  92% 4.54G/4.97G [00:41<00:01, 400MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  93% 4.62G/4.97G [00:42<00:00, 414MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  95% 4.70G/4.97G [00:42<00:00, 454MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  96% 4.77G/4.97G [00:42<00:00, 479MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin:  98% 4.88G/4.97G [00:42<00:00, 621MB/s]\u001b[A\n",
            "merged/pytorch_model-00001-of-00002.bin: 4.98GB [00:42, 117MB/s]                \n",
            " 83% 15/18 [01:46<01:02, 20.82s/it]\n",
            "merged/pytorch_model-00002-of-00002.bin:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   1% 16.0M/1.46G [00:03<05:13, 4.61MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   2% 32.0M/1.46G [00:04<03:03, 7.80MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   3% 48.0M/1.46G [00:05<02:32, 9.24MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   4% 64.0M/1.46G [00:06<01:38, 14.1MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   5% 80.0M/1.46G [00:07<01:45, 13.1MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   7% 96.0M/1.46G [00:07<01:19, 17.1MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   8% 112M/1.46G [00:08<01:00, 22.1MB/s] \u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:   9% 128M/1.46G [00:08<00:59, 22.3MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  11% 160M/1.46G [00:09<00:33, 38.5MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  13% 192M/1.46G [00:09<00:22, 57.4MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  14% 208M/1.46G [00:09<00:22, 56.8MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  16% 240M/1.46G [00:09<00:14, 81.4MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  19% 272M/1.46G [00:09<00:10, 111MB/s] \u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  21% 304M/1.46G [00:09<00:08, 136MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  23% 336M/1.46G [00:10<00:08, 134MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  25% 368M/1.46G [00:10<00:06, 161MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  30% 432M/1.46G [00:10<00:04, 248MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  33% 480M/1.46G [00:10<00:04, 208MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  38% 560M/1.46G [00:10<00:03, 244MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  43% 624M/1.46G [00:10<00:02, 303MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  47% 688M/1.46G [00:11<00:02, 331MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  50% 736M/1.46G [00:11<00:02, 333MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  55% 800M/1.46G [00:11<00:01, 380MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  58% 848M/1.46G [00:11<00:01, 365MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  61% 896M/1.46G [00:11<00:01, 341MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  66% 960M/1.46G [00:11<00:01, 357MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  69% 1.01G/1.46G [00:12<00:01, 339MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  72% 1.06G/1.46G [00:12<00:01, 332MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  76% 1.10G/1.46G [00:12<00:01, 349MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  80% 1.17G/1.46G [00:12<00:00, 404MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  83% 1.22G/1.46G [00:12<00:00, 358MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin:  92% 1.34G/1.46G [00:12<00:00, 552MB/s]\u001b[A\n",
            "merged/pytorch_model-00002-of-00002.bin: 1.47GB [00:12, 115MB/s]                \n",
            " 89% 16/18 [01:59<00:37, 18.54s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:01<00:00, 11.9MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:02, 14.4MB/s]\n",
            " 94% 17/18 [02:02<00:13, 13.74s/it]\n",
            "tokenizer.json:   0% 0.00/17.2M [00:00<?, ?B/s]\u001b[A\n",
            "tokenizer.json:  93% 16.0M/17.2M [00:01<00:00, 12.6MB/s]\u001b[A\n",
            "tokenizer.json: 32.0MB [00:02, 15.3MB/s]\n",
            "100% 18/18 [02:04<00:00,  6.94s/it]\n",
            "https://huggingface.co/mgfrantz/cmte-demo/tree/main/.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use your fine tune\n",
        "\n",
        "Ok! Finally, you have your fine tuned model.\n",
        "Let's go back up to the top of the notebook and use it instead of our original model and see if there was any improvement.\n",
        "When you instantiate the `Ollama` LLM class, replace the model we originally used with `\"hf.co/{your_username}/{your_repo_name}\"`.\n",
        "Then, run the agent normally as we did before!"
      ],
      "metadata": {
        "id": "AMos9-3KE7fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion: Next steps\n",
        "\n",
        "If you were to try and improve on this solution, what steps would you take?\n",
        "\n",
        "- Get more training data\n",
        "- Try a more powerful base model (maybe a 7b)\n",
        "- Train for more epochs\n",
        "- Fine tune on ChatML-formatted data to learn the format, then further fine tune on this specific data"
      ],
      "metadata": {
        "id": "m7cZQK6QFY6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading in `transformers`"
      ],
      "metadata": {
        "id": "OIhi6DRVHddb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "9Dk3MGurbhIb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('model-out/merged/')\n",
        "model = AutoModelForCausalLM.from_pretrained('model-out/merged/', device_map='auto')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f47a5096d5bb48daad97fddb06401e2c",
            "253f829cbca0467d8c25f7b1059d89a9",
            "d80939edaee1462cac494a55a4e7da1d",
            "b6f88fc462c14b08a3056bda7bbaf54c",
            "8d5d1fc7a93045068768c98f48ccdd38",
            "a6fb555795a6404299dfc5a8ae1c7efc",
            "f7993be546b64f5fb7cfbb1c652e616d",
            "86be02ead92d437faa3bd16e9e8117ba",
            "fac3d94ce76f4916bb9449b829b30e70",
            "5e502b5c8aa74c4da21371c1f00ba38c",
            "25f839f1201b4d8ea5590f2f370e330c"
          ]
        },
        "id": "-iE0sbmebl6v",
        "outputId": "0f08d9fb-a596-4c24-bec0-9dcf03d7d369"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f47a5096d5bb48daad97fddb06401e2c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
        "]"
      ],
      "metadata": {
        "id": "Rf_MPns8bztW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "m6jtwUBlcB-J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUIMw3LkcXC4",
        "outputId": "cb6c2f0f-ce33-4e8c-e807-2ac10566deeb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,    279,   6864,\n",
              "            315,   9822,     30, 128009]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(inputs.to('cuda'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq2pnRi2cFd5",
        "outputId": "fc3a31ab-1f1f-4133-a752-a164f420ab0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.batch_decode(outputs)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "BpgSKEBxcGZk",
        "outputId": "d3a99c1e-6f22-422c-909a-8514eef86a67"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m<\u001b[0m\u001b[1;95m|begin_of_text|\u001b[0m\u001b[39m><|start_header_id|>user<|end_header_id|>\u001b[0m\n",
              "\n",
              "\u001b[39mWhat is the capital of France?<|eot_id|\u001b[0m\u001b[1m>\u001b[0m\n",
              "\n",
              "What is the capital of France\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">|begin_of_text|</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span>\n",
              "\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">What is the capital of France?&lt;|eot_id|</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "\n",
              "What is the capital of France\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhzJdyELcNe4",
        "outputId": "863176a3-9a56-446b-8419-000b60dd579b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[128000, 128006,    882, 128007,    271,   3923,    374,    279,   6864,\n",
              "            315,   9822,     30, 128009,    271,   3923,    374,    279,   6864,\n",
              "            315,   9822]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4R9uAgxcUY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Nnjlha4NSwDN",
        "Eet-v8uMdQuD",
        "UPDY2usLePC7",
        "jVsiwscL0Dn8",
        "YSBVexvhTeoZ",
        "s7BQ-DosToZW",
        "KudCtoIsYngV",
        "N7PnQChITtHs",
        "ERoc4N_oUA4H",
        "LDPWrxZlUFFw",
        "eKMILeuZUJWO",
        "m7cZQK6QFY6J"
      ],
      "mount_file_id": "1PRrY3qfKwipvU1bXWLGBWw1u_WXQsLoy",
      "authorship_tag": "ABX9TyPB2M9Fi+x9PpbARhf34QwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "722f1cc4b4484b23aa85f650366bb4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a90936afbc8146f88d023f733cddc787",
              "IPY_MODEL_60535ee429be46e0b847466e549c1f5f",
              "IPY_MODEL_dd00a145fee54b6b89dc588ce45501c6"
            ],
            "layout": "IPY_MODEL_03962cafd4ce48be970bc16a77074489"
          }
        },
        "a90936afbc8146f88d023f733cddc787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8221fb2f0fd4517a7ebca4f004af489",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6e36771a377a4435af25f36b6c17e60c",
            "value": "Fetchingâ€‡5â€‡files:â€‡100%"
          }
        },
        "60535ee429be46e0b847466e549c1f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4468a395dab446ad85e7ad9ea57c8f40",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d6cc91cff9747789837a93c1c2f3f02",
            "value": 5
          }
        },
        "dd00a145fee54b6b89dc588ce45501c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4b5811a6944ac889c025117061c799",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_88abaac18fa743b68c11570d3e3e028b",
            "value": "â€‡5/5â€‡[00:00&lt;00:00,â€‡389.86it/s]"
          }
        },
        "03962cafd4ce48be970bc16a77074489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8221fb2f0fd4517a7ebca4f004af489": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e36771a377a4435af25f36b6c17e60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4468a395dab446ad85e7ad9ea57c8f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6cc91cff9747789837a93c1c2f3f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d4b5811a6944ac889c025117061c799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88abaac18fa743b68c11570d3e3e028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c35ec348c1a4b06a31567cfa185334a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c08fa4438acf4b7ab86c3982f7a2e5f9",
              "IPY_MODEL_9a8e895650654a1eb0cdc068acb081c6",
              "IPY_MODEL_254f373c2617412195247d891a214ace"
            ],
            "layout": "IPY_MODEL_80bb527a06ab4dc49767acb270d6b930"
          }
        },
        "c08fa4438acf4b7ab86c3982f7a2e5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2722280362ba428a8f8b93e2da29aee2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_176265abb4e749209a9ff4e6d1923bd3",
            "value": "Parsingâ€‡nodes:â€‡100%"
          }
        },
        "9a8e895650654a1eb0cdc068acb081c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee76e2fc87445e5a29088c07e67017d",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_551265655e6e4196ba9ddd1607fc1d67",
            "value": 50
          }
        },
        "254f373c2617412195247d891a214ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bab2082f94e48f49a116abf5fb5a39a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c9069c85682c4adc913fa8a8c440d591",
            "value": "â€‡50/50â€‡[00:00&lt;00:00,â€‡1665.87it/s]"
          }
        },
        "80bb527a06ab4dc49767acb270d6b930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2722280362ba428a8f8b93e2da29aee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176265abb4e749209a9ff4e6d1923bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee76e2fc87445e5a29088c07e67017d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551265655e6e4196ba9ddd1607fc1d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bab2082f94e48f49a116abf5fb5a39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9069c85682c4adc913fa8a8c440d591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aef4e12ad124023aba8bcdcd2c3f18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a4ddf72e62497c9162459d9fbb7682",
              "IPY_MODEL_55fcf36f6fc94cbd9ec8c47db5d28319",
              "IPY_MODEL_810f4672f179403c90109395bb6466a9"
            ],
            "layout": "IPY_MODEL_1a3aef246d424db994ee9eb552961d9d"
          }
        },
        "03a4ddf72e62497c9162459d9fbb7682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a6b69a23744f6d8690bc4049016346",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_44e69bd2b0e641298cc96a969178773b",
            "value": "Generatingâ€‡embeddings:â€‡100%"
          }
        },
        "55fcf36f6fc94cbd9ec8c47db5d28319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af17ea30ded4faba47dbac2338847e3",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d94220d42079473db4817b6fc4f0a3fe",
            "value": 50
          }
        },
        "810f4672f179403c90109395bb6466a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f6d7e29ca94e7db689c4c31095d71f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a7713957755642bca5ca3535c1f05642",
            "value": "â€‡50/50â€‡[00:09&lt;00:00,â€‡â€‡5.51it/s]"
          }
        },
        "1a3aef246d424db994ee9eb552961d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a6b69a23744f6d8690bc4049016346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44e69bd2b0e641298cc96a969178773b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af17ea30ded4faba47dbac2338847e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94220d42079473db4817b6fc4f0a3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3f6d7e29ca94e7db689c4c31095d71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7713957755642bca5ca3535c1f05642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47a5096d5bb48daad97fddb06401e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_253f829cbca0467d8c25f7b1059d89a9",
              "IPY_MODEL_d80939edaee1462cac494a55a4e7da1d",
              "IPY_MODEL_b6f88fc462c14b08a3056bda7bbaf54c"
            ],
            "layout": "IPY_MODEL_8d5d1fc7a93045068768c98f48ccdd38"
          }
        },
        "253f829cbca0467d8c25f7b1059d89a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6fb555795a6404299dfc5a8ae1c7efc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f7993be546b64f5fb7cfbb1c652e616d",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "d80939edaee1462cac494a55a4e7da1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86be02ead92d437faa3bd16e9e8117ba",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fac3d94ce76f4916bb9449b829b30e70",
            "value": 2
          }
        },
        "b6f88fc462c14b08a3056bda7bbaf54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e502b5c8aa74c4da21371c1f00ba38c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_25f839f1201b4d8ea5590f2f370e330c",
            "value": "â€‡2/2â€‡[00:07&lt;00:00,â€‡â€‡3.23s/it]"
          }
        },
        "8d5d1fc7a93045068768c98f48ccdd38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fb555795a6404299dfc5a8ae1c7efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7993be546b64f5fb7cfbb1c652e616d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86be02ead92d437faa3bd16e9e8117ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac3d94ce76f4916bb9449b829b30e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e502b5c8aa74c4da21371c1f00ba38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f839f1201b4d8ea5590f2f370e330c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}